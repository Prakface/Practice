{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Appending_training_wts_data_Loader_Actual_Labels2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prakface/Practice/blob/master/Appending_training_wts_data_Loader_Actual_Labels2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hrekx7KW0RE",
        "colab_type": "code",
        "outputId": "6b93b18f-51a0-4ebb-8af3-fb4744f439c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "url='https://raw.githubusercontent.com/Prakface/Practice/master/One_mon_present_full.csv'\n",
        "\n",
        "url2='https://raw.githubusercontent.com/Prakface/Practice/master/Final_one_month_prev_features.csv'\n",
        "\n",
        "url_h='https://raw.githubusercontent.com/Prakface/Practice/master/heuristic_labels.csv'\n",
        "\n",
        "data = pd.read_csv(url) \n",
        "\n",
        "data2= pd.read_csv(url2)\n",
        "\n",
        "print(\"Data Shape:\", data.shape) \n",
        "\n",
        "#data=pd.read_csv(url)\n",
        "\n",
        "df=pd.DataFrame(data)\n",
        "print(data.head()) \n",
        "\n",
        "\n",
        "data_modified= data.dropna()\n",
        "\n",
        "data_modified.to_csv(\"modifiedData.csv\", index=False)\n",
        "\n",
        "\n",
        "df2=pd.read_csv(\"modifiedData.csv\")\n",
        "\n",
        "print(df2[0:6])\n",
        "\n",
        "print(df2['result'])\n",
        "\n",
        "df_main=df2[df2.columns[~df2.columns.isin(['text', 'user_name'])]]\n",
        "\n",
        "print(df_main.columns)\n",
        "\n",
        "print(len(df_main.columns))\n",
        "\n",
        "  \n",
        "# X_1, y_1 means rpesent tweets' data\n",
        "X_1=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]] #removing result attribute as it is class label, hence we get 34 attributes\n",
        "X_1=X_1.iloc[:,1:len(X_1.columns)].values   #removing the unnamed attribute\n",
        "x_1=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]]\n",
        "x_1=x_1.iloc[:,1:len(x_1.columns)].values \n",
        "y_1=df_main.loc[:, ['result']].values\n",
        "\n",
        "\n",
        "print(type(X_1), type(y_1), type(x_1), type(y_1))\n",
        "\n",
        "print(X_1.shape)\n",
        "print(y_1.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Shape: (1908, 40)\n",
            "  Unnamed: 0 cat1  cat10  ...      tweet_id  url      user_name\n",
            "0          0    0      0  ...  8.323790e+17  0.0  THEJEROMEOWEN\n",
            "1          1    0      0  ...  8.323786e+17  0.0       Acejinjo\n",
            "2          2    0      0  ...  8.323780e+17  0.0     RabRakha21\n",
            "3          3    0      0  ...  8.323777e+17  0.0       RS_Aloha\n",
            "4          4    0      0  ...  8.323767e+17  0.0  preciselyizzy\n",
            "\n",
            "[5 rows x 40 columns]\n",
            "   Unnamed: 0  cat1  cat10  ...      tweet_id  url        user_name\n",
            "0           0     0      0  ...  8.323790e+17  0.0    THEJEROMEOWEN\n",
            "1           1     0      0  ...  8.323786e+17  0.0         Acejinjo\n",
            "2           2     0      0  ...  8.323780e+17  0.0       RabRakha21\n",
            "3           3     0      0  ...  8.323777e+17  0.0         RS_Aloha\n",
            "4           4     0      0  ...  8.323767e+17  0.0    preciselyizzy\n",
            "5           5     0      0  ...  8.323759e+17  0.0  thefireistarted\n",
            "\n",
            "[6 rows x 40 columns]\n",
            "0       1.0\n",
            "1       1.0\n",
            "2       1.0\n",
            "3       1.0\n",
            "4       1.0\n",
            "5       1.0\n",
            "6       1.0\n",
            "7       1.0\n",
            "8       1.0\n",
            "9       1.0\n",
            "10      1.0\n",
            "11      1.0\n",
            "12      1.0\n",
            "13      1.0\n",
            "14      1.0\n",
            "15      1.0\n",
            "16      1.0\n",
            "17      1.0\n",
            "18      1.0\n",
            "19      1.0\n",
            "20      1.0\n",
            "21      1.0\n",
            "22      1.0\n",
            "23      1.0\n",
            "24      1.0\n",
            "25      1.0\n",
            "26      1.0\n",
            "27      1.0\n",
            "28      1.0\n",
            "29      1.0\n",
            "       ... \n",
            "1876    0.0\n",
            "1877    0.0\n",
            "1878    0.0\n",
            "1879    0.0\n",
            "1880    0.0\n",
            "1881    0.0\n",
            "1882    0.0\n",
            "1883    0.0\n",
            "1884    0.0\n",
            "1885    0.0\n",
            "1886    0.0\n",
            "1887    0.0\n",
            "1888    0.0\n",
            "1889    0.0\n",
            "1890    0.0\n",
            "1891    0.0\n",
            "1892    0.0\n",
            "1893    0.0\n",
            "1894    0.0\n",
            "1895    0.0\n",
            "1896    0.0\n",
            "1897    0.0\n",
            "1898    0.0\n",
            "1899    0.0\n",
            "1900    0.0\n",
            "1901    0.0\n",
            "1902    0.0\n",
            "1903    0.0\n",
            "1904    0.0\n",
            "1905    0.0\n",
            "Name: result, Length: 1906, dtype: float64\n",
            "Index(['Unnamed: 0', 'cat1', 'cat10', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6',\n",
            "       'cat7', 'cat8', 'cat9', 'favorite_count', 'hour', 'image', 'level',\n",
            "       'nadj', 'nadv', 'nemoji', 'nlevel', 'nword', 'orginal', 'padj', 'padv',\n",
            "       'pemoji', 'plevel', 'pnoun', 'punc1', 'punc2', 'punc3', 'pword',\n",
            "       'question', 'result', 'retweets_count', 'sarcasm', 'sentiment', 'time',\n",
            "       'tweet_id', 'url'],\n",
            "      dtype='object')\n",
            "38\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(1906, 34)\n",
            "(1906, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbl6XjvAXC9A",
        "colab_type": "code",
        "outputId": "aaedb36a-50bb-4a24-d76b-81aacdaa0723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data2= pd.read_csv(url2)\n",
        "\n",
        "print(\"Data Shape:\", data2.shape) \n",
        "\n",
        "#data=pd.read_csv(url)\n",
        "\n",
        "df_prev=pd.DataFrame(data2)\n",
        "print(data2.head()) \n",
        "\n",
        "\n",
        "data2_modified= data2.dropna()\n",
        "\n",
        "data2_modified.to_csv(\"modifiedData2.csv\", index=False)\n",
        "\n",
        "\n",
        "df_2=pd.read_csv(\"modifiedData2.csv\")\n",
        "\n",
        "print(df_2[0:6])\n",
        "\n",
        "print(df_2['result'])\n",
        "\n",
        "df_main2=df_2[df_2.columns[~df_2.columns.isin(['text', 'user_name'])]]\n",
        "\n",
        "print(df_main2.columns)\n",
        "\n",
        "print(len(df_main2.columns))\n",
        "\n",
        "  \n",
        "\n",
        "X_2=df_main2[df_main2.columns[~df_main2.columns.isin(['time', 'tweet_id','result'])]] #removing result attribute as it is class label, hence we get 34 attributes\n",
        "X_2=X_2.iloc[:,1:len(X_2.columns)].values   #removing the unnamed attribute\n",
        "x_2=df_main2[df_main2.columns[~df_main2.columns.isin(['time', 'tweet_id','result'])]]\n",
        "x_2=x_2.iloc[:,1:len(x_2.columns)].values \n",
        "y_2=df_main2.loc[:, ['result']].values\n",
        "\n",
        "\n",
        "print(type(X_2), type(y_2), type(x_2), type(y_2))\n",
        "\n",
        "print(X_2.shape)\n",
        "print(y_2.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Shape: (3004, 38)\n",
            "   Unnamed: 0  cat1  cat10  ...             tweet_id  url      user_name\n",
            "0           0     0      0  ...  1155575657402961920    1  THEJEROMEOWEN\n",
            "1           1     0      0  ...  1155459426243043328    0  THEJEROMEOWEN\n",
            "2           2     0      0  ...  1126969730307448832    0     rabrakha14\n",
            "3           3     0      0  ...  1155277550794338304    0       RS_Aloha\n",
            "4           4     0      0  ...  1155188179395207168    0       RS_Aloha\n",
            "\n",
            "[5 rows x 38 columns]\n",
            "   Unnamed: 0  cat1  cat10  ...             tweet_id  url      user_name\n",
            "0           0     0      0  ...  1155575657402961920    1  THEJEROMEOWEN\n",
            "1           1     0      0  ...  1155459426243043328    0  THEJEROMEOWEN\n",
            "2           2     0      0  ...  1126969730307448832    0     rabrakha14\n",
            "3           3     0      0  ...  1155277550794338304    0       RS_Aloha\n",
            "4           4     0      0  ...  1155188179395207168    0       RS_Aloha\n",
            "5           5     0      0  ...  1154962871765393408    0  preciselyizzy\n",
            "\n",
            "[6 rows x 38 columns]\n",
            "0       0\n",
            "1       0\n",
            "2       0\n",
            "3       0\n",
            "4       0\n",
            "5       0\n",
            "6       0\n",
            "7       0\n",
            "8       0\n",
            "9       0\n",
            "10      0\n",
            "11      0\n",
            "12      0\n",
            "13      0\n",
            "14      0\n",
            "15      0\n",
            "16      0\n",
            "17      0\n",
            "18      0\n",
            "19      0\n",
            "20      0\n",
            "21      0\n",
            "22      0\n",
            "23      0\n",
            "24      0\n",
            "25      0\n",
            "26      0\n",
            "27      0\n",
            "28      0\n",
            "29      0\n",
            "       ..\n",
            "2974    0\n",
            "2975    0\n",
            "2976    0\n",
            "2977    0\n",
            "2978    0\n",
            "2979    0\n",
            "2980    0\n",
            "2981    0\n",
            "2982    0\n",
            "2983    0\n",
            "2984    0\n",
            "2985    0\n",
            "2986    0\n",
            "2987    0\n",
            "2988    0\n",
            "2989    0\n",
            "2990    0\n",
            "2991    0\n",
            "2992    0\n",
            "2993    0\n",
            "2994    0\n",
            "2995    0\n",
            "2996    0\n",
            "2997    0\n",
            "2998    0\n",
            "2999    0\n",
            "3000    0\n",
            "3001    0\n",
            "3002    0\n",
            "3003    0\n",
            "Name: result, Length: 3004, dtype: int64\n",
            "Index(['Unnamed: 0', 'cat1', 'cat10', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6',\n",
            "       'cat7', 'cat8', 'cat9', 'favorite_count', 'hour', 'image', 'level',\n",
            "       'nadj', 'nadv', 'nemoji', 'nlevel', 'nword', 'orginal', 'padj', 'padv',\n",
            "       'pemoji', 'plevel', 'pnoun', 'punc1', 'punc2', 'punc3', 'pword',\n",
            "       'question', 'result', 'retweets_count', 'sarcasm', 'sentiment',\n",
            "       'tweet_id', 'url'],\n",
            "      dtype='object')\n",
            "37\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(3004, 34)\n",
            "(3004, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Na97V-59XETA",
        "colab_type": "code",
        "outputId": "f1532f27-c50d-4059-d69f-f715956a6e55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df_h=pd.read_csv(url_h)\n",
        "\n",
        "print(df_h.columns)\n",
        "\n",
        "\n",
        "'''\n",
        "the following way is wrong\n",
        "label1=df_h.heuristic1.values\n",
        "label_1=df_h.heuristic1_1.values\n",
        "label2=df_h.heuristic2.values\n",
        "label3=df_h.heuristic3.values\n",
        "\n",
        "print(type(label1), type(label2), type(label3))\n",
        "\n",
        "\n",
        "\n",
        "print(type(label1), type(label2), type(label3))\n",
        "\n",
        "print(y_1.shape, label1.shape, label2.shape, label3.shape)\n",
        "\n",
        "#print(len(label1),len(label2),len(label3), len(label_1))\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "label1=df_h.loc[:, ['heuristic1']].values\n",
        "label_1=df_h.loc[:,['heuristic1_1']].values\n",
        "label2=df_h.loc[:, ['heuristic2']].values\n",
        "label3=df_h.loc[:, ['heuristic3']].values\n",
        "\n",
        "print(type(label1), type(label2), type(label3))\n",
        "\n",
        "\n",
        "\n",
        "print(type(label1), type(label2), type(label3))\n",
        "\n",
        "print(y_1.shape, label1.shape, label2.shape, label3.shape)\n",
        "\n",
        "\n",
        "tem1y=np.append(y_1, label1, axis=0)\n",
        "tem2y=np.append(y_1, label2, axis=0)\n",
        "tem3y=np.append(y_1, label3, axis=0)\n",
        "\n",
        "tem_1y=np.append(y_1, label_1, axis=0)\n",
        "\n",
        "T_h1=torch.from_numpy(tem1y)\n",
        "T_h2=torch.from_numpy(tem2y)\n",
        "T_h3=torch.from_numpy(tem3y)\n",
        "T_h_1=torch.from_numpy(tem_1y)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Unnamed: 0', 'heuristic1', 'heuristic1_1', 'heuristic2', 'heuristic3'], dtype='object')\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(1906, 1) (3273, 1) (3273, 1) (3273, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vn_xmdUXd_A",
        "colab_type": "code",
        "outputId": "8047750e-a638-4b03-b7d7-403e452d5e7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#Appending present and previosu data with actual label data...\n",
        "\n",
        "tem=np.append(X_1, X_2, axis=0)\n",
        "tem_y=np.append(y_1,label1,axis=0)\n",
        "print(X_1.shape, X_2.shape, tem.shape)\n",
        "print(y_1.shape, y_2.shape, tem_y.shape)\n",
        "\n",
        "X=tem\n",
        "T=tem_y\n",
        "\n",
        "print(X.shape, T.shape)\n",
        "\n",
        "print(type(X_1))\n",
        "#convert to tensor\n",
        "X = torch.from_numpy(X)\n",
        "T = torch.from_numpy(T)\n",
        "\n",
        "X_1 = torch.from_numpy(X_1)\n",
        "T_1 = torch.from_numpy(y_1)\n",
        "\n",
        "X_2 = torch.from_numpy(X_2)\n",
        "T_2 = torch.from_numpy(y_2)\n",
        "\n",
        "print(type(X), type(T))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1906, 34) (3004, 34) (4910, 34)\n",
            "(1906, 1) (3004, 1) (5179, 1)\n",
            "(4910, 34) (5179, 1)\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dJov9ERXflo",
        "colab_type": "code",
        "outputId": "b9b6e679-b6cf-4ab9-c3de-a2e636087872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.nn.functional as F\n",
        "\n",
        "## create training and validation split \n",
        "split_size = int(0.8 * len(X_1))\n",
        "index_list = list(range(len(X_1)))\n",
        "train_idx, valid_idx = index_list[:split_size], index_list[split_size:]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "x_tr = torch.tensor(X[train_idx], dtype=torch.long)\n",
        "y_tr = torch.tensor(T[train_idx], dtype=torch.float32)\n",
        "train = TensorDataset(x_tr, y_tr)\n",
        "trainloader = DataLoader(train, batch_size=128)\n",
        "'''\n",
        "\n",
        "x_tr = torch.tensor(X_1[train_idx], dtype=torch.long)\n",
        "y_tr = torch.tensor(T_1[train_idx], dtype=torch.float32)\n",
        "train = TensorDataset(x_tr, y_tr)\n",
        "trainloader = DataLoader(train, batch_size=128)\n",
        "\n",
        "x_valid = torch.tensor(X_1[valid_idx], dtype=torch.long)\n",
        "y_valid = torch.tensor(T_1[valid_idx], dtype=torch.float32)\n",
        "valid = TensorDataset(x_valid, y_valid)\n",
        "validloader = DataLoader(valid, batch_size=128)\n",
        "\n",
        "x_tr2 = torch.tensor(X_2[train_idx], dtype=torch.long)\n",
        "y_tr2 = torch.tensor(T_2[train_idx], dtype=torch.float32)\n",
        "train2 = TensorDataset(x_tr2, y_tr2)\n",
        "trainloader2 = DataLoader(train2, batch_size=128)\n",
        "\n",
        "\n",
        "\n",
        "##Following is Auxiliary data set\n",
        "\n",
        "\n",
        "split_size = int(0.8 * len(X_2))\n",
        "index_list = list(range(len(X_2)))\n",
        "train_idx, valid_idx = index_list[:split_size], index_list[split_size:]\n",
        "\n",
        "\n",
        "x_tr2 = torch.tensor(X_2[train_idx], dtype=torch.long)\n",
        "y_tr2 = torch.tensor(T_2[train_idx], dtype=torch.float32)\n",
        "train2 = TensorDataset(x_tr2, y_tr2)\n",
        "trainloader2 = DataLoader(train2, batch_size=128)\n",
        "\n",
        "x_valid2 = torch.tensor(X_2[valid_idx], dtype=torch.long)\n",
        "y_valid2 = torch.tensor(T_2[valid_idx], dtype=torch.float32)\n",
        "valid2 = TensorDataset(x_valid2, y_valid2)\n",
        "validloader = DataLoader(valid2, batch_size=128)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZO3US-dXi7h",
        "colab_type": "code",
        "outputId": "ee2709b4-372d-4522-e502-0f05d6ebd0c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "##Concatenating the tensors\n",
        "\n",
        "import torch as pytorch\n",
        "\n",
        "pytorch.set_default_tensor_type('torch.DoubleTensor')\n",
        "\n",
        "X_1=X_1.type(torch.DoubleTensor)\n",
        "T_1=T_1.type(torch.DoubleTensor)\n",
        "\n",
        "X_2=X_2.type(torch.DoubleTensor)\n",
        "T_2=T_2.type(torch.DoubleTensor)\n",
        "\n",
        "\n",
        "X=torch.cat((X_1,X_2), 0)\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "X_tr=torch.cat((x_tr,x_tr2),0)\n",
        "\n",
        "print(X_tr.shape)\n",
        "\n",
        "Y_tr=torch.cat((y_tr,y_tr2),0)  ##y_tr2 doesn't have values, we should calculate using heuristics\n",
        "\n",
        "X_valid=torch.cat((x_valid,x_valid2),0)\n",
        "\n",
        "Y_valid=torch.cat((y_valid,y_valid2),0)\n",
        "\n",
        "Train=TensorDataset(X_tr, Y_tr)\n",
        "TrainLoader=DataLoader(Train, batch_size=128)\n",
        "\n",
        "\n",
        "Valid=TensorDataset(X_valid, Y_valid)\n",
        "ValidLoader=DataLoader(Valid, batch_size=128)\n",
        "\n",
        "\n",
        "print(X_tr.type())\n",
        "\n",
        "X_tr=torch.tensor(X_tr, dtype=torch.double)\n",
        "\n",
        "X_valid=torch.tensor(X_valid, dtype=torch.double)\n",
        "\n",
        "print(X_tr.type(), X_valid.type())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4910, 34])\n",
            "torch.Size([3927, 34])\n",
            "torch.LongTensor\n",
            "torch.DoubleTensor torch.DoubleTensor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouCpAZEiXngI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clRKBVyjXpkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 50\n",
        "n_iters = 3000\n",
        "epochs = n_iters / (len(X_1) / batch_size)\n",
        "epochs2= n_iters / (len(X_2) / batch_size)\n",
        "#epochs= n_iters/((len(X_1)+len(X_2))/batch_size)\n",
        "input_dim = 34\n",
        "output_dim = 2\n",
        "lr_rate = 0.001\n",
        "\n",
        "class LogisticRegression(torch.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "        #self.linear = torch.nn.Linear(2*input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = self.linear(x)\n",
        "        return outputs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQgy7EyBXqdx",
        "colab_type": "code",
        "outputId": "dc9885fa-de7b-4ecb-c3ee-ec2ce14315a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model=LogisticRegression(input_dim, output_dim)\n",
        "print(type(model.parameters()))\n",
        "print(model.parameters())\n",
        "#a=model.parameters()\n",
        "#len(a)\n",
        "\n",
        "model.parameters"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'generator'>\n",
            "<generator object Module.parameters at 0x7eff1cd101a8>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of LogisticRegression(\n",
              "  (linear): Linear(in_features=34, out_features=2, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbisTM5rXuzi",
        "colab_type": "code",
        "outputId": "966e4c23-c8ec-4c03-d3e7-e6f1d26741c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "model = LogisticRegression(input_dim, output_dim)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss() # computes softmax and then the cross entropy\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n initialized_weights = \\n\")\n",
        "for param in model.parameters():\n",
        "  print(param.data)\n",
        "\n",
        "##Training the data\n",
        "iterations = 0\n",
        "for epoch in range(int(epochs)):\n",
        "    for i, (data_X, labels) in enumerate(trainloader):\n",
        "        data_X = Variable(data_X.view(-1,34))\n",
        "        labels = Variable(labels)\n",
        "        labels=torch.tensor(labels, dtype=torch.long)\n",
        "        #print(labels.__class__)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        data_X=torch.tensor(data_X, dtype=torch.double)\n",
        "        #print(data_X.shape, data_X.type())\n",
        "        \n",
        "        outputs = model(data_X)\n",
        "        labels = labels.squeeze_()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        iterations+=1\n",
        "        if iterations%100==0:\n",
        "            # calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for data_X, labels in validloader:\n",
        "                data_X = Variable(data_X.view(-1, 34))\n",
        "                \n",
        "                data_X=torch.tensor(data_X, dtype=torch.double)\n",
        "                labels=torch.tensor(labels, dtype=torch.long)\n",
        "                \n",
        "                outputs = model(data_X)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total+= labels.size(0)\n",
        "                # for gpu, bring the predicted and labels back to cpu fro python operations to work\n",
        "                pr=predicted.numpy()\n",
        "                lb=labels.numpy()\n",
        "                for i in range(len(pr)):\n",
        "                  if(pr[i]==lb[i]):\n",
        "                    correct = correct+ 1\n",
        "                    \n",
        "                #correct+= (predicted == labels).sum()\n",
        "            accuracy = 100 * correct/total\n",
        "            print(\"Iteration: {}. Loss: {}.Correct:{}. total:{}. Accuracy: {}.\".format(iterations, loss.item(), correct, total,  accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " initialized_weights = \n",
            "\n",
            "tensor([[-0.0676, -0.1260,  0.0526,  0.1464,  0.1325, -0.0564, -0.1504, -0.1577,\n",
            "         -0.0495,  0.0622,  0.0943, -0.0065,  0.0794, -0.0835, -0.0358,  0.1701,\n",
            "          0.0465,  0.0534,  0.1311, -0.1391,  0.0465,  0.0162, -0.0891, -0.1459,\n",
            "          0.1162, -0.0299,  0.0167, -0.1588, -0.0775,  0.0043, -0.1480, -0.0437,\n",
            "         -0.1109, -0.0924],\n",
            "        [ 0.1554, -0.0416,  0.1660,  0.0476,  0.1376,  0.0724,  0.0585, -0.1386,\n",
            "          0.0809, -0.1118,  0.1696,  0.0470, -0.0844, -0.0120, -0.0332,  0.1185,\n",
            "          0.1045,  0.1550,  0.1071, -0.0093, -0.0762, -0.1704,  0.0292, -0.0303,\n",
            "          0.1682, -0.1494,  0.0132,  0.0129, -0.1192, -0.1583, -0.1067,  0.0011,\n",
            "         -0.1330,  0.1458]])\n",
            "tensor([ 0.0963, -0.1502])\n",
            "Iteration: 100. Loss: 0.6606340579818804.Correct:60. total:601. Accuracy: 9.983361064891847.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 200. Loss: 1.0300618264382555.Correct:49. total:601. Accuracy: 8.153078202995008.\n",
            "Iteration: 300. Loss: 0.7037779200863574.Correct:256. total:601. Accuracy: 42.59567387687188.\n",
            "Iteration: 400. Loss: 0.6043031077201624.Correct:60. total:601. Accuracy: 9.983361064891847.\n",
            "Iteration: 500. Loss: 1.0021704215832103.Correct:49. total:601. Accuracy: 8.153078202995008.\n",
            "Iteration: 600. Loss: 0.7060358867314738.Correct:248. total:601. Accuracy: 41.26455906821963.\n",
            "Iteration: 700. Loss: 0.5690994990825968.Correct:64. total:601. Accuracy: 10.64891846921797.\n",
            "Iteration: 800. Loss: 0.9819999864546076.Correct:51. total:601. Accuracy: 8.48585690515807.\n",
            "Iteration: 900. Loss: 0.7037637028924731.Correct:260. total:601. Accuracy: 43.261231281198.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpRzN4m3QZbX",
        "colab_type": "code",
        "outputId": "c9b57a55-6fd7-4ba8-f7cb-883b5f365646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "## For output dim=1 of above model\n",
        "\n",
        "batch_size = 50\n",
        "n_iters = 3000\n",
        "epochs = n_iters / (len(X_1) / batch_size)\n",
        "epochs2= n_iters / (len(X_2) / batch_size)\n",
        "#epochs= n_iters/((len(X_1)+len(X_2))/batch_size)\n",
        "input_dim = 34\n",
        "output_dim = 1\n",
        "lr_rate = 0.001\n",
        "\n",
        "class LogisticRegression(torch.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "        #self.linear = torch.nn.Linear(2*input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = self.linear(x)\n",
        "        return outputs\n",
        "\n",
        "      \n",
        "      \n",
        "model=LogisticRegression(input_dim, output_dim)\n",
        "print(type(model.parameters()))\n",
        "print(model.parameters())\n",
        "#a=model.parameters()\n",
        "#len(a)\n",
        "\n",
        "model.parameters\n",
        "\n",
        "\n",
        "model = LogisticRegression(input_dim, output_dim)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss() # computes softmax and then the cross entropy\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n initialized_weights = \\n\")\n",
        "for param in model.parameters():\n",
        "  print(param.data)\n",
        "\n",
        "##Training the data\n",
        "iterations = 0\n",
        "for epoch in range(int(epochs)):\n",
        "    for i, (data_X, labels) in enumerate(trainloader):\n",
        "        data_X = Variable(data_X.view(-1,34))\n",
        "        labels = Variable(labels)\n",
        "        labels=torch.tensor(labels, dtype=torch.long)\n",
        "        #print(labels.__class__)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        data_X=torch.tensor(data_X, dtype=torch.double)\n",
        "        #print(data_X.shape, data_X.type())\n",
        "        \n",
        "        outputs = model(data_X)\n",
        "        labels = labels.squeeze_()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        iterations+=1\n",
        "        if iterations%100==0:\n",
        "            # calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for data_X, labels in validloader:\n",
        "                data_X = Variable(data_X.view(-1, 34))\n",
        "                \n",
        "                data_X=torch.tensor(data_X, dtype=torch.double)\n",
        "                labels=torch.tensor(labels, dtype=torch.long)\n",
        "                \n",
        "                outputs = model(data_X)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total+= labels.size(0)\n",
        "                # for gpu, bring the predicted and labels back to cpu fro python operations to work\n",
        "                pr=predicted.numpy()\n",
        "                lb=labels.numpy()\n",
        "                for i in range(len(pr)):\n",
        "                  if(pr[i]==lb[i]):\n",
        "                    correct = correct+ 1\n",
        "                    \n",
        "                #correct+= (predicted == labels).sum()\n",
        "            accuracy = 100 * correct/total\n",
        "            print(\"Iteration: {}. Loss: {}.Correct:{}. total:{}. Accuracy: {}.\".format(iterations, loss.item(), correct, total,  accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'generator'>\n",
            "<generator object Module.parameters at 0x7eff1ccf2bf8>\n",
            "\n",
            " initialized_weights = \n",
            "\n",
            "tensor([[ 0.1079, -0.0839, -0.1499, -0.0033, -0.1619,  0.1377,  0.1373,  0.0874,\n",
            "         -0.0007,  0.1163,  0.1513, -0.0178, -0.0520,  0.0970, -0.1445,  0.0428,\n",
            "         -0.1599,  0.0243,  0.1554,  0.0763, -0.0721,  0.0701, -0.1652, -0.1081,\n",
            "         -0.0221,  0.1663, -0.1363, -0.0385, -0.0802,  0.1448, -0.1238,  0.0817,\n",
            "          0.0213, -0.0944]])\n",
            "tensor([0.0998])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-e76b6f72946b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 916\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1822\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1823\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1824\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1825\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1826\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /pytorch/aten/src/THNN/generic/ClassNLLCriterion.c:94"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AkgB2yIXz0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#####Using different weights for previous tweets and defining loss via adding different forward function\n",
        "\n",
        "batch_size = 50\n",
        "n_iters = 3000\n",
        "epochs = n_iters / (len(X_1) / batch_size)\n",
        "epochs2= n_iters / (len(X_2) / batch_size)\n",
        "#epochs= n_iters/((len(X_1)+len(X_2))/batch_size)\n",
        "input_dim = 34\n",
        "output_dim = 2\n",
        "lr_rate = 0.001\n",
        "\n",
        "class LogisticRegression(torch.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "        #self.linear = torch.nn.Linear(2*input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        out1 = self.linear(x1)\n",
        "        out2 = self.linear(x2)\n",
        "        outputs=(out1+out2)/2\n",
        "        return outputs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxu2gtY6X06j",
        "colab_type": "code",
        "outputId": "c8d40320-6b09-4fbc-b68c-867fe29d76f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch as pytorch\n",
        "import numpy as np\n",
        "\n",
        "pytorch.set_default_tensor_type('torch.DoubleTensor')\n",
        "\n",
        "X_1=X_1.type(torch.DoubleTensor)\n",
        "T_1=T_1.type(torch.DoubleTensor)\n",
        "\n",
        "\n",
        "X_2=X_2.type(torch.DoubleTensor)\n",
        "T_2=T_2.type(torch.DoubleTensor)\n",
        "\n",
        "W = Variable(torch.randn(1, 34, dtype=torch.double), requires_grad=True)\n",
        "b = Variable(torch.randn(1, 1, dtype=torch.double), requires_grad=True)\n",
        "print(W.size())\n",
        "\n",
        "#Weights for Previoes tweets\n",
        "#W1 = Variable(torch.randn(1, 34, dtype=torch.double), requires_grad=True)\n",
        "#W_p = Variable(torch.randn(1, 34, dtype=torch.double), requires_grad=True)\n",
        "#W_p=W_p.type(torch.LongTensor)\n",
        "#b_p = Variable(torch.randn(1, 1, dtype=torch.double), requires_grad=True)\n",
        "#print(W_p.size(), torch.Tensor(W_p).dtype)\n",
        "#print(W.size(), torch.Tensor(W_p).dtype)\n",
        "\n",
        "\n",
        "#sigmoid\n",
        "def sigmoid(x):\n",
        "    return 1/(1+torch.exp(-x))\n",
        "\n",
        "#out = sigmoid(torch.mm(X, W.view(34,1))+b)\n",
        "\n",
        "out_present= sigmoid(torch.mm(X_1, W.view(34,1))+b)\n",
        "\n",
        "#out_prev= sigmoid(torch.mm(X_2, W_p.view(34,1))+b_p)\n",
        "out_prev_same_weight=sigmoid(torch.mm(X_2,W.view(34,1))+b)\n",
        "\n",
        "'''\n",
        "\n",
        "def my_loss(out1, target1, out2, target2,cnt):\n",
        "  print(out1.type(),len(out1), target1.type() ,out2.type(),len(out2), target2.type())\n",
        "  target1=target1.numpy()\n",
        "  target2=target2.numpy()\n",
        "  #out1=out1.numpy(), we can't call numpy on out1 and out2 because we can't call numpy on var that require grad\n",
        "  #out2=out2.numpy()\n",
        "  print(\"\\n After numpy conversion \\n\", len(target1), len(target2))\n",
        "  \n",
        "  l1=-target1 * torch.log(out1) - (1-target1) * torch.log(1-out1)\n",
        "  \n",
        "  #print(target1.type(), out1.type())\n",
        "  l2=-target2 * torch.log(out2) - (1-target2) * torch.log(1-out2)\n",
        "  \n",
        "  return torch.tensor(np.mean(l1+l2))\n",
        "  \n",
        "'''\n",
        "  \n",
        "  \n",
        "def my_loss(out1, target1, out2, target2):\n",
        "  target1=torch.tensor(target1, dtype=torch.double)\n",
        "  target2=torch.tensor(target2, dtype=torch.double)\n",
        "\n",
        "  \n",
        "  #print(out1.type(),len(out1), target1.type(),len(target1) ,out2.type(),len(out2), target2.type(),len(target2))\n",
        "  l1=-target1 * torch.log(out1) - (1-target1) * torch.log(1-out1)\n",
        "  \n",
        "  #print(target1.type(), out1.type())\n",
        "  l2=-target2 * torch.log(out2) - (1-target2) * torch.log(1-out2)\n",
        "  return torch.mean(l1+l2)\n",
        "  return l1+l2\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 34])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk1SAHBCX4um",
        "colab_type": "code",
        "outputId": "ff4d7d14-27ad-435e-896d-dadef91a23c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "model = LogisticRegression(input_dim, output_dim)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss() # computes softmax and then the cross entropy\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)\n",
        "\n",
        "\n",
        "for param in model.parameters():\n",
        "  print(\"\\n\", param.data)\n",
        "\n",
        "##Training the data\n",
        "iterations = 0\n",
        "for epoch in range(int(epochs)):\n",
        "    cnt=0\n",
        "    print_cnt=1\n",
        "    for  (data_X, labels,x2,y2) in zip(x_tr,y_tr,x_tr2,y_tr2):\n",
        "        data_X = Variable(data_X.view(-1,34))\n",
        "        labels = Variable(labels)\n",
        "        \n",
        "        x2 = Variable(data_X.view(-1,34))\n",
        "        y2 = Variable(y2)\n",
        "        \n",
        "        data_X=torch.tensor(data_X, dtype=torch.double)\n",
        "        labels=torch.tensor(labels, dtype=torch.long)\n",
        "        \n",
        "        x2=torch.tensor(x2,dtype=torch.double)\n",
        "        y2=torch.tensor(y2,dtype=torch.long)\n",
        "        \n",
        "       \n",
        "        #print(labels.__class__)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        #print(data_X.shape, data_X.type())\n",
        "        \n",
        "        outputs = model(data_X)\n",
        "        labels = labels.squeeze_()\n",
        "        \n",
        "        out1=model(data_X)\n",
        "        out2=model(x2)\n",
        "        \n",
        "        #label_val=torch.tensor(labels[cnt])\n",
        "        #y2_val=torch.tensor(y2[cnt])\n",
        "        \n",
        "        y2=y2.squeeze_()\n",
        "        #loss = criterion(outputs, labels)\n",
        "        #loss=my_loss(out1,label_val,out2,y2_val)\n",
        "        #loss=my_loss(out1,labels,out2,y2,cnt)\n",
        "        loss=my_loss(out1,labels,out2,y2)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        cnt+=1\n",
        "\n",
        "        #iterations+=1\n",
        "        \n",
        "        if iterations%10==0 and print_cnt==1:\n",
        "            print_cnt=0\n",
        "            # calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for data_X, labels,x2,y2 in zip(x_valid,y_valid, x_valid2,y_valid2):\n",
        "                data_X = Variable(data_X.view(-1, 34))\n",
        "                \n",
        "                data_X=torch.tensor(data_X, dtype=torch.double)\n",
        "                labels=torch.tensor(labels, dtype=torch.long)\n",
        "                \n",
        "                x2 = Variable(data_X.view(-1,34))\n",
        "                y2 = Variable(y2)\n",
        "                \n",
        "                x2=torch.tensor(x2,dtype=torch.double)\n",
        "                y2=torch.tensor(y2, dtype=torch.long)\n",
        "                \n",
        "                outputs = model(data_X)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total+= labels.size(0)\n",
        "                # for gpu, bring the predicted and labels back to cpu fro python operations to work\n",
        "                pr=predicted.numpy()\n",
        "                lb=labels.numpy()\n",
        "                for i in range(len(pr)):\n",
        "                  if(pr[i]==lb[i]):\n",
        "                    correct = correct+ 1\n",
        "                    \n",
        "                #correct+= (predicted == labels).sum()\n",
        "                \n",
        "            #iterations+=1\n",
        "            accuracy = 100 * correct/total\n",
        "            print(\"Iteration: {}. Loss: {}.Correct:{}. total:{}. Accuracy: {}.\".format(iterations, loss.item(), correct, total,  accuracy))\n",
        "       \n",
        "    iterations+=1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " tensor([[-0.0967, -0.1131,  0.1547, -0.1049,  0.0389, -0.0262,  0.0479,  0.0782,\n",
            "          0.0131, -0.1127, -0.0521,  0.0997, -0.0067,  0.0571,  0.0448, -0.0665,\n",
            "          0.1008, -0.0876,  0.1350,  0.0513,  0.0555, -0.1171, -0.0818, -0.1276,\n",
            "         -0.0125, -0.0328,  0.0354, -0.0660, -0.1319,  0.0002,  0.0743,  0.1331,\n",
            "          0.0225,  0.0970],\n",
            "        [ 0.0827, -0.1100,  0.1147, -0.0378, -0.1213, -0.0037,  0.0196, -0.1361,\n",
            "          0.1561, -0.0331,  0.0005, -0.0352,  0.0591,  0.1045,  0.0053,  0.0299,\n",
            "          0.1678, -0.0411, -0.0481, -0.0484,  0.1273,  0.1627,  0.0127,  0.0643,\n",
            "          0.0254, -0.1005,  0.0228, -0.0644, -0.1644, -0.0429, -0.1133,  0.0151,\n",
            "          0.0835,  0.1594]])\n",
            "\n",
            " tensor([-0.1383, -0.1448])\n",
            "Iteration: 0. Loss: nan.Correct:361. total:382. Accuracy: 94.50261780104712.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 10. Loss: nan.Correct:382. total:382. Accuracy: 100.0.\n",
            "Iteration: 20. Loss: nan.Correct:382. total:382. Accuracy: 100.0.\n",
            "Iteration: 30. Loss: nan.Correct:382. total:382. Accuracy: 100.0.\n",
            "Iteration: 40. Loss: nan.Correct:382. total:382. Accuracy: 100.0.\n",
            "Iteration: 50. Loss: nan.Correct:382. total:382. Accuracy: 100.0.\n",
            "Iteration: 60. Loss: nan.Correct:382. total:382. Accuracy: 100.0.\n",
            "Iteration: 70. Loss: nan.Correct:382. total:382. Accuracy: 100.0.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Dz7iSBfYCQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(int(epochs/5)):\n",
        "  print(epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}