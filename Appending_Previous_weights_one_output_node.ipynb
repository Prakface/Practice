{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Appending Previous weights_one_output_node.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prakface/Practice/blob/master/Appending_Previous_weights_one_output_node.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyuuKsCtSRaB",
        "colab_type": "code",
        "outputId": "64cd4f7e-62d7-4929-af0a-e5c39f7cd64a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "url='https://raw.githubusercontent.com/Prakface/Practice/master/One_mon_present_full.csv'\n",
        "\n",
        "url2='https://raw.githubusercontent.com/Prakface/Practice/master/Final_one_month_prev_features.csv'\n",
        "\n",
        "url_h='https://raw.githubusercontent.com/Prakface/Practice/master/heuristic_labels.csv'\n",
        "\n",
        "data = pd.read_csv(url) \n",
        "\n",
        "data2= pd.read_csv(url2)\n",
        "\n",
        "print(\"Data Shape:\", data.shape) \n",
        "\n",
        "#data=pd.read_csv(url)\n",
        "\n",
        "df=pd.DataFrame(data)\n",
        "print(data.head()) \n",
        "\n",
        "\n",
        "data_modified= data.dropna()\n",
        "\n",
        "data_modified.to_csv(\"modifiedData.csv\", index=False)\n",
        "\n",
        "\n",
        "df2=pd.read_csv(\"modifiedData.csv\")\n",
        "\n",
        "print(df2[0:6])\n",
        "\n",
        "print(df2['result'])\n",
        "\n",
        "df_main=df2[df2.columns[~df2.columns.isin(['text', 'user_name'])]]\n",
        "\n",
        "print(df_main.columns)\n",
        "\n",
        "print(len(df_main.columns))\n",
        "\n",
        "  \n",
        "# X_1, y_1 means rpesent tweets' data\n",
        "X_1=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]] #removing result attribute as it is class label, hence we get 34 attributes\n",
        "X_1=X_1.iloc[:,1:len(X_1.columns)].values   #removing the unnamed attribute\n",
        "x_1=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]]\n",
        "x_1=x_1.iloc[:,1:len(x_1.columns)].values \n",
        "y_1=df_main.loc[:, ['result']].values\n",
        "\n",
        "\n",
        "print(type(X_1), type(y_1), type(x_1), type(y_1))\n",
        "\n",
        "print(X_1.shape)\n",
        "print(y_1.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Shape: (1908, 40)\n",
            "  Unnamed: 0 cat1  cat10  ...      tweet_id  url      user_name\n",
            "0          0    0      0  ...  8.323790e+17  0.0  THEJEROMEOWEN\n",
            "1          1    0      0  ...  8.323786e+17  0.0       Acejinjo\n",
            "2          2    0      0  ...  8.323780e+17  0.0     RabRakha21\n",
            "3          3    0      0  ...  8.323777e+17  0.0       RS_Aloha\n",
            "4          4    0      0  ...  8.323767e+17  0.0  preciselyizzy\n",
            "\n",
            "[5 rows x 40 columns]\n",
            "   Unnamed: 0  cat1  cat10  ...      tweet_id  url        user_name\n",
            "0           0     0      0  ...  8.323790e+17  0.0    THEJEROMEOWEN\n",
            "1           1     0      0  ...  8.323786e+17  0.0         Acejinjo\n",
            "2           2     0      0  ...  8.323780e+17  0.0       RabRakha21\n",
            "3           3     0      0  ...  8.323777e+17  0.0         RS_Aloha\n",
            "4           4     0      0  ...  8.323767e+17  0.0    preciselyizzy\n",
            "5           5     0      0  ...  8.323759e+17  0.0  thefireistarted\n",
            "\n",
            "[6 rows x 40 columns]\n",
            "0       1.0\n",
            "1       1.0\n",
            "2       1.0\n",
            "3       1.0\n",
            "4       1.0\n",
            "       ... \n",
            "1901    0.0\n",
            "1902    0.0\n",
            "1903    0.0\n",
            "1904    0.0\n",
            "1905    0.0\n",
            "Name: result, Length: 1906, dtype: float64\n",
            "Index(['Unnamed: 0', 'cat1', 'cat10', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6',\n",
            "       'cat7', 'cat8', 'cat9', 'favorite_count', 'hour', 'image', 'level',\n",
            "       'nadj', 'nadv', 'nemoji', 'nlevel', 'nword', 'orginal', 'padj', 'padv',\n",
            "       'pemoji', 'plevel', 'pnoun', 'punc1', 'punc2', 'punc3', 'pword',\n",
            "       'question', 'result', 'retweets_count', 'sarcasm', 'sentiment', 'time',\n",
            "       'tweet_id', 'url'],\n",
            "      dtype='object')\n",
            "38\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(1906, 34)\n",
            "(1906, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdo99HcxTGL2",
        "colab_type": "code",
        "outputId": "72be78c0-5b67-4f18-804d-582ed942f15f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "data2= pd.read_csv(url2)\n",
        "\n",
        "print(\"Data Shape:\", data2.shape) \n",
        "\n",
        "#data=pd.read_csv(url)\n",
        "\n",
        "df_prev=pd.DataFrame(data2)\n",
        "print(data2.head()) \n",
        "\n",
        "\n",
        "data2_modified= data2.dropna()\n",
        "\n",
        "data2_modified.to_csv(\"modifiedData2.csv\", index=False)\n",
        "\n",
        "\n",
        "df_2=pd.read_csv(\"modifiedData2.csv\")\n",
        "\n",
        "print(df_2[0:6])\n",
        "\n",
        "print(df_2['result'])\n",
        "\n",
        "df_main2=df_2[df_2.columns[~df_2.columns.isin(['text', 'user_name'])]]\n",
        "\n",
        "print(df_main2.columns)\n",
        "\n",
        "print(len(df_main2.columns))\n",
        "\n",
        "  \n",
        "\n",
        "X_2=df_main2[df_main2.columns[~df_main2.columns.isin(['time', 'tweet_id','result'])]] #removing result attribute as it is class label, hence we get 34 attributes\n",
        "X_2=X_2.iloc[:,1:len(X_2.columns)].values   #removing the unnamed attribute\n",
        "x_2=df_main2[df_main2.columns[~df_main2.columns.isin(['time', 'tweet_id','result'])]]\n",
        "x_2=x_2.iloc[:,1:len(x_2.columns)].values \n",
        "y_2=df_main2.loc[:, ['result']].values\n",
        "\n",
        "\n",
        "print(type(X_2), type(y_2), type(x_2), type(y_2))\n",
        "\n",
        "print(X_2.shape)\n",
        "print(y_2.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Shape: (3004, 38)\n",
            "   Unnamed: 0  cat1  cat10  ...             tweet_id  url      user_name\n",
            "0           0     0      0  ...  1155575657402961920    1  THEJEROMEOWEN\n",
            "1           1     0      0  ...  1155459426243043328    0  THEJEROMEOWEN\n",
            "2           2     0      0  ...  1126969730307448832    0     rabrakha14\n",
            "3           3     0      0  ...  1155277550794338304    0       RS_Aloha\n",
            "4           4     0      0  ...  1155188179395207168    0       RS_Aloha\n",
            "\n",
            "[5 rows x 38 columns]\n",
            "   Unnamed: 0  cat1  cat10  ...             tweet_id  url      user_name\n",
            "0           0     0      0  ...  1155575657402961920    1  THEJEROMEOWEN\n",
            "1           1     0      0  ...  1155459426243043328    0  THEJEROMEOWEN\n",
            "2           2     0      0  ...  1126969730307448832    0     rabrakha14\n",
            "3           3     0      0  ...  1155277550794338304    0       RS_Aloha\n",
            "4           4     0      0  ...  1155188179395207168    0       RS_Aloha\n",
            "5           5     0      0  ...  1154962871765393408    0  preciselyizzy\n",
            "\n",
            "[6 rows x 38 columns]\n",
            "0       0\n",
            "1       0\n",
            "2       0\n",
            "3       0\n",
            "4       0\n",
            "       ..\n",
            "2999    0\n",
            "3000    0\n",
            "3001    0\n",
            "3002    0\n",
            "3003    0\n",
            "Name: result, Length: 3004, dtype: int64\n",
            "Index(['Unnamed: 0', 'cat1', 'cat10', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6',\n",
            "       'cat7', 'cat8', 'cat9', 'favorite_count', 'hour', 'image', 'level',\n",
            "       'nadj', 'nadv', 'nemoji', 'nlevel', 'nword', 'orginal', 'padj', 'padv',\n",
            "       'pemoji', 'plevel', 'pnoun', 'punc1', 'punc2', 'punc3', 'pword',\n",
            "       'question', 'result', 'retweets_count', 'sarcasm', 'sentiment',\n",
            "       'tweet_id', 'url'],\n",
            "      dtype='object')\n",
            "37\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(3004, 34)\n",
            "(3004, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ekN67DFTN9K",
        "colab_type": "code",
        "outputId": "5b25e6a7-d05e-4f6b-e586-5b06168f6004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df_h=pd.read_csv(url_h)\n",
        "\n",
        "print(df_h.columns)\n",
        "\n",
        "\n",
        "'''\n",
        "the following way is wrong\n",
        "label1=df_h.heuristic1.values\n",
        "label_1=df_h.heuristic1_1.values\n",
        "label2=df_h.heuristic2.values\n",
        "label3=df_h.heuristic3.values\n",
        "\n",
        "print(type(label1), type(label2), type(label3))\n",
        "\n",
        "\n",
        "\n",
        "print(type(label1), type(label2), type(label3))\n",
        "\n",
        "print(y_1.shape, label1.shape, label2.shape, label3.shape)\n",
        "\n",
        "#print(len(label1),len(label2),len(label3), len(label_1))\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "label1=df_h.loc[:, ['heuristic1']].values\n",
        "label_1=df_h.loc[:,['heuristic1_1']].values\n",
        "label2=df_h.loc[:, ['heuristic2']].values\n",
        "label3=df_h.loc[:, ['heuristic3']].values\n",
        "\n",
        "print(type(label1), type(label2), type(label3))\n",
        "\n",
        "\n",
        "\n",
        "print(type(label1), type(label2), type(label3))\n",
        "\n",
        "print(y_1.shape, label1.shape, label2.shape, label3.shape)\n",
        "\n",
        "\n",
        "tem1y=np.append(y_1, label1, axis=0)\n",
        "tem2y=np.append(y_1, label2, axis=0)\n",
        "tem3y=np.append(y_1, label3, axis=0)\n",
        "\n",
        "tem_1y=np.append(y_1, label_1, axis=0)\n",
        "\n",
        "T_h1=torch.from_numpy(tem1y)\n",
        "T_h2=torch.from_numpy(tem2y)\n",
        "T_h3=torch.from_numpy(tem3y)\n",
        "T_h_1=torch.from_numpy(tem_1y)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Unnamed: 0', 'heuristic1', 'heuristic1_1', 'heuristic2', 'heuristic3'], dtype='object')\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(1906, 1) (3273, 1) (3273, 1) (3273, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26g-UYJ5TTDL",
        "colab_type": "code",
        "outputId": "7cca21de-f1c2-40a9-97cf-c586fee43376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#Appending present and previosu data with actual label data...\n",
        "\n",
        "tem=np.append(X_1, X_2, axis=0)\n",
        "tem_y=np.append(y_1,label1,axis=0)\n",
        "print(X_1.shape, X_2.shape, tem.shape)\n",
        "#print(y_1.shape, y_2.shape, tem_y.shape)\n",
        "print(y_1.shape, label1.shape, tem_y.shape)\n",
        "X=tem\n",
        "T=tem_y\n",
        "\n",
        "print(X.shape, T.shape)\n",
        "\n",
        "print(type(X_1))\n",
        "#convert to tensor\n",
        "X = torch.from_numpy(X)\n",
        "T = torch.from_numpy(T)\n",
        "\n",
        "X_1 = torch.from_numpy(X_1)\n",
        "T_1 = torch.from_numpy(y_1)\n",
        "\n",
        "X_2 = torch.from_numpy(X_2)\n",
        "T_2 = torch.from_numpy(y_2)\n",
        "\n",
        "print(type(X), type(T))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1906, 34) (3004, 34) (4910, 34)\n",
            "(1906, 1) (3273, 1) (5179, 1)\n",
            "(4910, 34) (5179, 1)\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKW9sbzoeCgV",
        "colab_type": "code",
        "outputId": "3c769216-e05c-4999-9f93-cf984aad5550",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "####Applying PCA\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.decomposition import PCA \n",
        "\n",
        "n=3\n",
        "\n",
        "data1=X\n",
        "\n",
        "scaler = StandardScaler()\n",
        "print(scaler.fit(data1))\n",
        "print(scaler.transform(data1))\n",
        "\n",
        "new_data1=scaler.transform(data1)\n",
        "\n",
        "pca = PCA(n_components =n) \n",
        "PCA_Data1=pca.fit_transform(new_data1)\n",
        "\n",
        "#X_1=torch.from_numpy(new_data1)\n",
        "X=torch.from_numpy(PCA_Data1)\n",
        "T= torch.from_numpy(tem_y)\n",
        "\n",
        "\n",
        "data1=X_1\n",
        "\n",
        "scaler = StandardScaler()\n",
        "print(scaler.fit(data1))\n",
        "print(scaler.transform(data1))\n",
        "\n",
        "new_data1=scaler.transform(data1)\n",
        "\n",
        "pca = PCA(n_components =n) \n",
        "PCA_Data1=pca.fit_transform(new_data1)\n",
        "\n",
        "#X_1=torch.from_numpy(new_data1)\n",
        "X_1=torch.from_numpy(PCA_Data1)\n",
        "T_1= torch.from_numpy(y_1)\n",
        "\n",
        "\n",
        "\n",
        "data2=X_2\n",
        "\n",
        "scaler = StandardScaler()\n",
        "print(scaler.fit(data2))\n",
        "print(scaler.transform(data2))\n",
        "new_data2=scaler.transform(data2)\n",
        "\n",
        "pca = PCA(n_components =n) \n",
        "PCA_Data2=pca.fit_transform(new_data2)\n",
        "\n",
        "\n",
        "#X_2=torch.from_numpy(new_data2)\n",
        "X_2=torch.from_numpy(PCA_Data2)\n",
        "T_2= torch.from_numpy(y_2)\n",
        "\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
            "[[-0.12454675 -0.20523312 -0.1887928  ...  0.         -0.34669442\n",
            "  -0.50254455]\n",
            " [-0.12454675 -0.20523312 -0.1887928  ...  0.         -1.6902379\n",
            "  -0.50254455]\n",
            " [-0.12454675 -0.20523312 -0.1887928  ...  0.          0.99684906\n",
            "  -0.50254455]\n",
            " ...\n",
            " [-0.12454675 -0.20523312 -0.1887928  ...  0.         -1.6902379\n",
            "   1.98987335]\n",
            " [-0.12454675  8.0545589  -0.1887928  ...  0.          0.99684906\n",
            "  -0.50254455]\n",
            " [-0.12454675  3.92466289 -0.1887928  ...  0.          0.99684906\n",
            "  -0.50254455]]\n",
            "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
            "[[-0.13476792 -0.19493167 -0.19200937 ...  0.         -0.36993901\n",
            "  -0.33372183]\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.         -1.60479674\n",
            "  -0.33372183]\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.          0.86491871\n",
            "  -0.33372183]\n",
            " ...\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.          0.86491871\n",
            "   2.99650757]\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.         -1.60479674\n",
            "  -0.33372183]\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.          0.86491871\n",
            "  -0.33372183]]\n",
            "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
            "[[-0.11763217 -0.21155006 -0.18703747 ...  0.         -0.33180166\n",
            "   1.66123437]\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.         -0.33180166\n",
            "  -0.60196202]\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]\n",
            " ...\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.         -1.76388815\n",
            "   1.66123437]\n",
            " [-0.11763217  7.83270806 -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]\n",
            " [-0.11763217  3.810579   -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEBSyy3oTWfA",
        "colab_type": "code",
        "outputId": "627da858-265a-4cdf-eea2-e1493aa94b77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.nn.functional as F\n",
        "\n",
        "## create training and validation split \n",
        "split_size = int(0.8 * len(X_1))\n",
        "index_list = list(range(len(X_1)))\n",
        "train_idx, valid_idx = index_list[:split_size], index_list[split_size:]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "x_tr = torch.tensor(X[train_idx], dtype=torch.long)\n",
        "y_tr = torch.tensor(T[train_idx], dtype=torch.float32)\n",
        "train = TensorDataset(x_tr, y_tr)\n",
        "trainloader = DataLoader(train, batch_size=128)\n",
        "'''\n",
        "\n",
        "x_tr = torch.tensor(X_1[train_idx], dtype=torch.long)\n",
        "y_tr = torch.tensor(T_1[train_idx], dtype=torch.float32)\n",
        "train = TensorDataset(x_tr, y_tr)\n",
        "trainloader = DataLoader(train, batch_size=128)\n",
        "\n",
        "x_valid = torch.tensor(X_1[valid_idx], dtype=torch.long)\n",
        "y_valid = torch.tensor(T_1[valid_idx], dtype=torch.float32)\n",
        "valid = TensorDataset(x_valid, y_valid)\n",
        "validloader = DataLoader(valid, batch_size=128)\n",
        "\n",
        "x_tr2 = torch.tensor(X_2[train_idx], dtype=torch.long)\n",
        "y_tr2 = torch.tensor(T_2[train_idx], dtype=torch.float32)\n",
        "train2 = TensorDataset(x_tr2, y_tr2)\n",
        "trainloader2 = DataLoader(train2, batch_size=128)\n",
        "\n",
        "\n",
        "\n",
        "##Following is Auxiliary data set\n",
        "\n",
        "\n",
        "split_size = int(0.8 * len(X_2))\n",
        "index_list = list(range(len(X_2)))\n",
        "train_idx, valid_idx = index_list[:split_size], index_list[split_size:]\n",
        "\n",
        "\n",
        "x_tr2 = torch.tensor(X_2[train_idx], dtype=torch.long)\n",
        "y_tr2 = torch.tensor(T_2[train_idx], dtype=torch.float32)\n",
        "train2 = TensorDataset(x_tr2, y_tr2)\n",
        "trainloader2 = DataLoader(train2, batch_size=128)\n",
        "\n",
        "x_valid2 = torch.tensor(X_2[valid_idx], dtype=torch.long)\n",
        "y_valid2 = torch.tensor(T_2[valid_idx], dtype=torch.float32)\n",
        "valid2 = TensorDataset(x_valid2, y_valid2)\n",
        "validloader = DataLoader(valid2, batch_size=128)\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCnwK-MPTamG",
        "colab_type": "code",
        "outputId": "7ac9de61-d5cd-4ea5-dc3a-e25fe25129a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "##Concatenating the tensors\n",
        "\n",
        "import torch as pytorch\n",
        "\n",
        "pytorch.set_default_tensor_type('torch.DoubleTensor')\n",
        "\n",
        "X_1=X_1.type(torch.DoubleTensor)\n",
        "T_1=T_1.type(torch.DoubleTensor)\n",
        "\n",
        "X_2=X_2.type(torch.DoubleTensor)\n",
        "T_2=T_2.type(torch.DoubleTensor)\n",
        "\n",
        "\n",
        "X=torch.cat((X_1,X_2), 0)\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "X_tr=torch.cat((x_tr,x_tr2),0)\n",
        "\n",
        "print(X_tr.shape)\n",
        "\n",
        "Y_tr=torch.cat((y_tr,y_tr2),0)  ##y_tr2 doesn't have values, we should calculate using heuristics\n",
        "\n",
        "print(\"\\n target shape =\", Y_tr.shape)\n",
        "\n",
        "X_valid=torch.cat((x_valid,x_valid2),0)\n",
        "\n",
        "Y_valid=torch.cat((y_valid,y_valid2),0)\n",
        "\n",
        "Train=TensorDataset(X_tr, Y_tr)\n",
        "TrainLoader=DataLoader(Train, batch_size=128)\n",
        "\n",
        "\n",
        "Valid=TensorDataset(X_valid, Y_valid)\n",
        "ValidLoader=DataLoader(Valid, batch_size=128)\n",
        "\n",
        "\n",
        "print(X_tr.type())\n",
        "\n",
        "X_tr=torch.tensor(X_tr, dtype=torch.double)\n",
        "\n",
        "X_valid=torch.tensor(X_valid, dtype=torch.double)\n",
        "\n",
        "print(X_tr.type(), X_valid.type())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4910, 3])\n",
            "torch.Size([3927, 3])\n",
            "\n",
            " target shape = torch.Size([3927, 1])\n",
            "torch.LongTensor\n",
            "torch.DoubleTensor torch.DoubleTensor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ4KumUcTpvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 50\n",
        "n_iters = 3000\n",
        "epochs = n_iters / (len(X_1) / batch_size)\n",
        "epochs2= n_iters / (len(X_2) / batch_size)\n",
        "#epochs= n_iters/((len(X_1)+len(X_2))/batch_size)\n",
        "#input_dim = 34\n",
        "input_dim=3\n",
        "output_dim = 1\n",
        "lr_rate = 0.001\n",
        "\n",
        "class LogisticRegression(torch.nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = torch.nn.Linear(input_dim,1)\n",
        "        self.sigmoid=nn.Sigmoid()\n",
        "        #self.linear = torch.nn.Linear(2*input_dim, output_dim)\n",
        "        #raise NotImplementedError()\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = self.linear(x)\n",
        "        #outputs = torch.sigmoid(outputs)\n",
        "        #outputs=self.sigmoid(outputs)\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdlElVKtDh1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXFQ0kdjUWor",
        "colab_type": "code",
        "outputId": "1eaadea5-a9bd-4fd7-dd2e-0e17f7426ccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "model = LogisticRegression(input_dim)\n",
        "\n",
        "#criterion = torch.nn.CrossEntropyLoss() # computes softmax and then the cross entropy\n",
        "\n",
        "criterion= torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)\n",
        "\n",
        "print(\"\\n epochs = \", epochs)\n",
        "\n",
        "print(\"\\n initialized_weights = \\n\")\n",
        "for param in model.parameters():\n",
        "  print(param.data,\"Hi\\n\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " epochs =  78.69884575026234\n",
            "\n",
            " initialized_weights = \n",
            "\n",
            "tensor([[-0.1951,  0.0048, -0.3969]]) Hi\n",
            "\n",
            "tensor([0.2445]) Hi\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMms8psnZsRJ",
        "colab_type": "code",
        "outputId": "af7f2d9f-dd55-4704-a63f-5f667340709c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "temp=Y_tr.numpy()\n",
        "len(temp)\n",
        "cnt=0\n",
        "cnt2=0\n",
        "for i in temp:\n",
        "  if (i==1):\n",
        "    cnt+=1\n",
        "  else:\n",
        "    cnt2+=1\n",
        "    \n",
        "    \n",
        "print(cnt,cnt2)\n",
        "\n",
        "for epoch in range(int(epochs)):\n",
        "  print(\" \", epoch)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "947 2980\n",
            "  0\n",
            "  1\n",
            "  2\n",
            "  3\n",
            "  4\n",
            "  5\n",
            "  6\n",
            "  7\n",
            "  8\n",
            "  9\n",
            "  10\n",
            "  11\n",
            "  12\n",
            "  13\n",
            "  14\n",
            "  15\n",
            "  16\n",
            "  17\n",
            "  18\n",
            "  19\n",
            "  20\n",
            "  21\n",
            "  22\n",
            "  23\n",
            "  24\n",
            "  25\n",
            "  26\n",
            "  27\n",
            "  28\n",
            "  29\n",
            "  30\n",
            "  31\n",
            "  32\n",
            "  33\n",
            "  34\n",
            "  35\n",
            "  36\n",
            "  37\n",
            "  38\n",
            "  39\n",
            "  40\n",
            "  41\n",
            "  42\n",
            "  43\n",
            "  44\n",
            "  45\n",
            "  46\n",
            "  47\n",
            "  48\n",
            "  49\n",
            "  50\n",
            "  51\n",
            "  52\n",
            "  53\n",
            "  54\n",
            "  55\n",
            "  56\n",
            "  57\n",
            "  58\n",
            "  59\n",
            "  60\n",
            "  61\n",
            "  62\n",
            "  63\n",
            "  64\n",
            "  65\n",
            "  66\n",
            "  67\n",
            "  68\n",
            "  69\n",
            "  70\n",
            "  71\n",
            "  72\n",
            "  73\n",
            "  74\n",
            "  75\n",
            "  76\n",
            "  77\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkogPiluPgLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDOk5iTjU492",
        "colab_type": "code",
        "outputId": "08cf5479-36e0-492d-e6f8-9e367b8db45f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "##Training the data\n",
        "iterations = 0\n",
        "for epoch in range(int(epochs)):\n",
        "    #iterations=int(epoch)\n",
        "    for i, (data_X, labels) in enumerate(TrainLoader):\n",
        "      for j in range(len(labels)):\n",
        "                     assert 0 <= labels[j].data  < 2\n",
        "      if(min(labels.data)>=0 and max(labels.data)<2):\n",
        "        #data_X = Variable(data_X.view(-1,34))\n",
        "        data_X = Variable(data_X.view(-1,3))\n",
        "        \n",
        "        #print(\"\\n target class\", labels[0].data,labels[1].data, labels.shape,\"\\n\")\n",
        "        #print(\"\\n length of data_X = \", len(data_X), data_X.shape)\n",
        "        labels = Variable(labels)\n",
        "        labels=torch.tensor(labels, dtype=torch.long)\n",
        "        #labels=labels.view([128])\n",
        "        #temp1=labels\n",
        "        #temp1.resize([128])\n",
        "        #print(\"\\n temp1 type and shape =\", type(temp1), temp1.shape)\n",
        "        #print(labels.__class__)\n",
        "        #print(labels.shape)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        data_X=torch.tensor(data_X, dtype=torch.double)\n",
        "        #print(data_X.shape, data_X.type())\n",
        "        \n",
        "        outputs = model(data_X)\n",
        "        #print(\"\\n outputs shape= \", outputs.shape, \"\\n target shape = \", labels.shape)\n",
        "        labels=torch.tensor(labels, dtype=torch.double)\n",
        "        #print(\"\\n output type =\", outputs.type())\n",
        "        #outputs=model()\n",
        "        #labels = labels.squeeze_()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "      \n",
        "\n",
        "        #iterations+=1\n",
        "        \n",
        "        if iterations%100==0:\n",
        "            # calculate Training Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for data_X, labels in TrainLoader:\n",
        "                #data_X = Variable(data_X.view(-1, 34))\n",
        "                data_X = Variable(data_X.view(-1,3))\n",
        "                data_X=torch.tensor(data_X, dtype=torch.double)\n",
        "                labels=torch.tensor(labels, dtype=torch.long)\n",
        "                \n",
        "                outputs = model(data_X)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total+= labels.size(0)\n",
        "                # for gpu, bring the predicted and labels back to cpu fro python operations to work\n",
        "                pr=predicted.numpy()\n",
        "                lb=labels.numpy()\n",
        "                for i in range(len(pr)):\n",
        "                  if(pr[i]==lb[i]):\n",
        "                    correct = correct+ 1\n",
        "                    \n",
        "                #correct+= (predicted == labels).sum()\n",
        "            accuracy = 100 * correct/total\n",
        "            print(\"Iteration: {}. Loss: {}.Correct:{}. total:{}. Training Accuracy: {}.\".format(iterations, loss.item(), correct, total,  accuracy))\n",
        "        \n",
        "        #if iterations%100==0:\n",
        "            # calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for data_X, labels in ValidLoader:\n",
        "                #data_X = Variable(data_X.view(-1, 34))\n",
        "                data_X = Variable(data_X.view(-1,3))\n",
        "                data_X=torch.tensor(data_X, dtype=torch.double)\n",
        "                labels=torch.tensor(labels, dtype=torch.long)\n",
        "                \n",
        "                outputs = model(data_X)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total+= labels.size(0)\n",
        "                # for gpu, bring the predicted and labels back to cpu fro python operations to work\n",
        "                pr=predicted.numpy()\n",
        "                lb=labels.numpy()\n",
        "                for i in range(len(pr)):\n",
        "                  if(pr[i]==lb[i]):\n",
        "                    correct = correct+ 1\n",
        "                    \n",
        "                #correct+= (predicted == labels).sum()\n",
        "            accuracy = 100 * correct/total\n",
        "            print(\"Iteration: {}. Loss: {}.Correct:{}. total:{}. Testing Accuracy: {}.\".format(iterations, loss.item(), correct, total,  accuracy))\n",
        "        iterations+=1\n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "     "
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 0. Loss: 1.1792594927890683.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 0. Loss: 1.1792594927890683.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 100. Loss: 0.665206136517416.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 100. Loss: 0.665206136517416.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 200. Loss: 0.3664518310443893.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 200. Loss: 0.3664518310443893.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 300. Loss: 0.3604386464232479.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 300. Loss: 0.3604386464232479.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 400. Loss: 0.3642104383812329.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 400. Loss: 0.3642104383812329.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 500. Loss: 1.1027565341665915.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 500. Loss: 1.1027565341665915.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 600. Loss: 0.3475179571080419.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 600. Loss: 0.3475179571080419.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 700. Loss: 0.3476493376644345.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 700. Loss: 0.3476493376644345.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 800. Loss: 0.35391508528293136.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 800. Loss: 0.35391508528293136.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 900. Loss: 1.1499063030207468.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 900. Loss: 1.1499063030207468.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 1000. Loss: 0.34633731889328656.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 1000. Loss: 0.34633731889328656.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 1100. Loss: 0.36132802104140804.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 1100. Loss: 0.36132802104140804.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 1200. Loss: 0.35600205387839.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 1200. Loss: 0.35600205387839.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 1300. Loss: 0.33705413075274615.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 1300. Loss: 0.33705413075274615.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 1400. Loss: 1.118060265165436.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 1400. Loss: 1.118060265165436.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 1500. Loss: 0.3390875679984879.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 1500. Loss: 0.3390875679984879.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 1600. Loss: 0.3517322836263641.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 1600. Loss: 0.3517322836263641.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 1700. Loss: 0.3446791456071745.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 1700. Loss: 0.3446791456071745.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 1800. Loss: 1.2321588574251892.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 1800. Loss: 1.2321588574251892.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 1900. Loss: 0.34143769071419794.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 1900. Loss: 0.34143769071419794.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 2000. Loss: 0.3362848169353938.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 2000. Loss: 0.3362848169353938.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 2100. Loss: 0.3275794671487767.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 2100. Loss: 0.3275794671487767.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 2200. Loss: 0.35411406000530465.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 2200. Loss: 0.35411406000530465.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 2300. Loss: 1.1876286568670307.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 2300. Loss: 1.1876286568670307.Correct:983. total:983. Testing Accuracy: 100.0.\n",
            "Iteration: 2400. Loss: 0.32765950831436236.Correct:2980. total:3927. Training Accuracy: 75.88489941431118.\n",
            "Iteration: 2400. Loss: 0.32765950831436236.Correct:983. total:983. Testing Accuracy: 100.0.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o9bTYgfM3sH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "833d03ef-b097-44e2-a102-88f88eb14d8b"
      },
      "source": [
        "##Concatenating the tensors\n",
        "\n",
        "import torch as pytorch\n",
        "\n",
        "pytorch.set_default_tensor_type('torch.DoubleTensor')\n",
        "\n",
        "X_1=X_1.type(torch.DoubleTensor)\n",
        "T_1=T_1.type(torch.DoubleTensor)\n",
        "\n",
        "X_2=X_2.type(torch.DoubleTensor)\n",
        "T_2=T_2.type(torch.DoubleTensor)\n",
        "\n",
        "'''\n",
        "X=torch.cat((X_1,X_2), 0)\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "X_tr=torch.cat((x_tr,x_tr2),0)\n",
        "\n",
        "print(X_tr.shape)\n",
        "\n",
        "Y_tr=torch.cat((y_tr,y_tr2),0)  ##y_tr2 doesn't have values, we should calculate using heuristics\n",
        "\n",
        "print(\"\\n target shape =\", Y_tr.shape)\n",
        "\n",
        "X_valid=torch.cat((x_valid,x_valid2),0)\n",
        "\n",
        "Y_valid=torch.cat((y_valid,y_valid2),0)\n",
        "'''\n",
        "\n",
        "print(\"\\n X_1 shape =\", X.shape)\n",
        "#x_tr = torch.tensor(X_1[train_idx], dtype=torch.long)\n",
        "#y_tr = torch.tensor(T_1[train_idx], dtype=torch.float32)\n",
        "#train = TensorDataset(x_tr, y_tr)\n",
        "#trainloader = DataLoader(train, batch_size=128)\n",
        "\n",
        "\n",
        "train_pca=TensorDataset(x_tr, y_tr)\n",
        "trainloader_pca=DataLoader(train_pca, batch_size=128)\n",
        "\n",
        "\n",
        "valid_pca=TensorDataset(x_valid, y_valid)\n",
        "validloader_pca=DataLoader(valid_pca, batch_size=128)\n",
        "\n",
        "\n",
        "print(X_1.type())\n",
        "\n",
        "\n",
        "\n",
        "print(x_tr.type(), x_valid.type())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " X_1 shape = torch.Size([4910, 3])\n",
            "torch.DoubleTensor\n",
            "torch.LongTensor torch.LongTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u84KoxvFawmo",
        "colab_type": "code",
        "outputId": "946746ec-7248-41dc-80c1-0562d41a43f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "##Training the data\n",
        "iterations = 0\n",
        "for epoch in range(int(epochs)):\n",
        "    for i, (data_X, labels) in enumerate(trainloader_pca):\n",
        "      for j in range(len(labels)):\n",
        "                     assert 0 <= labels[j].data  < 2\n",
        "      if(min(labels.data)>=0 and max(labels.data)<2):\n",
        "        #data_X = Variable(data_X.view(-1,34))\n",
        "        data_X = Variable(data_X.view(-1,3))\n",
        "        \n",
        "        #print(\"\\n target class\", labels[0].data,labels[1].data, labels.shape,\"\\n\")\n",
        "        #print(\"\\n length of data_X = \", len(data_X), data_X.shape)\n",
        "        labels = Variable(labels)\n",
        "        labels=torch.tensor(labels, dtype=torch.long)\n",
        "        #labels=labels.view([128])\n",
        "        #temp1=labels\n",
        "        #temp1.resize([128])\n",
        "        #print(\"\\n temp1 type and shape =\", type(temp1), temp1.shape)\n",
        "        #print(labels.__class__)\n",
        "        #print(labels.shape)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        data_X=torch.tensor(data_X, dtype=torch.double)\n",
        "        #print(data_X.shape, data_X.type())\n",
        "        \n",
        "        outputs = model(data_X)\n",
        "        #print(\"\\n outputs shape= \", outputs.shape, \"\\n target shape = \", labels.shape)\n",
        "        labels=torch.tensor(labels, dtype=torch.double)\n",
        "        #print(\"\\n output type =\", outputs.type())\n",
        "        #outputs=model()\n",
        "        #labels = labels.squeeze_()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "      \n",
        "\n",
        "        \n",
        "        \n",
        "        if iterations%100==0:\n",
        "            # calculate Training Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for i, (data_X, labels) in enumerate(trainloader_pca):\n",
        "                #data_X = Variable(data_X.view(-1, 34))\n",
        "                data_X = Variable(data_X.view(-1,3))\n",
        "                data_X=torch.tensor(data_X, dtype=torch.double)\n",
        "                labels=torch.tensor(labels, dtype=torch.long)\n",
        "                \n",
        "                outputs = model(data_X)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total+= labels.size(0)\n",
        "                # for gpu, bring the predicted and labels back to cpu fro python operations to work\n",
        "                pr=predicted.numpy()\n",
        "                lb=labels.numpy()\n",
        "                for i in range(len(pr)):\n",
        "                  if(pr[i]==lb[i]):\n",
        "                    correct = correct+ 1\n",
        "                    \n",
        "                #correct+= (predicted == labels).sum()\n",
        "            accuracy = 100 * correct/total\n",
        "            print(\"Iteration: {}. Loss: {}.Correct:{}. total:{}. Training Accuracy: {}.\".format(iterations, loss.item(), correct, total,  accuracy))\n",
        "        \n",
        "        #if iterations%100==0:\n",
        "            # calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for i, (data_X, labels) in enumerate(validloader_pca):\n",
        "                #data_X = Variable(data_X.view(-1, 34))\n",
        "                data_X = Variable(data_X.view(-1,3))\n",
        "                data_X=torch.tensor(data_X, dtype=torch.double)\n",
        "                labels=torch.tensor(labels, dtype=torch.long)\n",
        "                \n",
        "                outputs = model(data_X)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total+= labels.size(0)\n",
        "                # for gpu, bring the predicted and labels back to cpu fro python operations to work\n",
        "                pr=predicted.numpy()\n",
        "                lb=labels.numpy()\n",
        "                for i in range(len(pr)):\n",
        "                  if(pr[i]==lb[i]):\n",
        "                    correct = correct+ 1\n",
        "                    \n",
        "                #correct+= (predicted == labels).sum()\n",
        "            accuracy = 100 * correct/total\n",
        "            print(\"Iteration: {}. Loss: {}.Correct:{}. total:{}. Testing Accuracy: {}.\".format(iterations, loss.item(), correct, total,  accuracy))\n",
        "            \n",
        "        iterations+=1"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 0. Loss: 1.1497421062627073.Correct:577. total:1524. Training Accuracy: 37.86089238845145.\n",
            "Iteration: 0. Loss: 1.1497421062627073.Correct:382. total:382. Testing Accuracy: 100.0.\n",
            "Iteration: 100. Loss: 1.0286936708887604.Correct:577. total:1524. Training Accuracy: 37.86089238845145.\n",
            "Iteration: 100. Loss: 1.0286936708887604.Correct:382. total:382. Testing Accuracy: 100.0.\n",
            "Iteration: 200. Loss: 0.395603160518593.Correct:577. total:1524. Training Accuracy: 37.86089238845145.\n",
            "Iteration: 200. Loss: 0.395603160518593.Correct:382. total:382. Testing Accuracy: 100.0.\n",
            "Iteration: 300. Loss: 1.0913695205003884.Correct:577. total:1524. Training Accuracy: 37.86089238845145.\n",
            "Iteration: 300. Loss: 1.0913695205003884.Correct:382. total:382. Testing Accuracy: 100.0.\n",
            "Iteration: 400. Loss: 0.9787102389429732.Correct:577. total:1524. Training Accuracy: 37.86089238845145.\n",
            "Iteration: 400. Loss: 0.9787102389429732.Correct:382. total:382. Testing Accuracy: 100.0.\n",
            "Iteration: 500. Loss: 0.42145050994246575.Correct:577. total:1524. Training Accuracy: 37.86089238845145.\n",
            "Iteration: 500. Loss: 0.42145050994246575.Correct:382. total:382. Testing Accuracy: 100.0.\n",
            "Iteration: 600. Loss: 1.0387739891835892.Correct:577. total:1524. Training Accuracy: 37.86089238845145.\n",
            "Iteration: 600. Loss: 1.0387739891835892.Correct:382. total:382. Testing Accuracy: 100.0.\n",
            "Iteration: 700. Loss: 0.9339185368402223.Correct:577. total:1524. Training Accuracy: 37.86089238845145.\n",
            "Iteration: 700. Loss: 0.9339185368402223.Correct:382. total:382. Testing Accuracy: 100.0.\n",
            "Iteration: 800. Loss: 0.4465277120476397.Correct:577. total:1524. Training Accuracy: 37.86089238845145.\n",
            "Iteration: 800. Loss: 0.4465277120476397.Correct:382. total:382. Testing Accuracy: 100.0.\n",
            "Iteration: 900. Loss: 0.9910947244013466.Correct:577. total:1524. Training Accuracy: 37.86089238845145.\n",
            "Iteration: 900. Loss: 0.9910947244013466.Correct:382. total:382. Testing Accuracy: 100.0.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQzLT4jrsKiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}