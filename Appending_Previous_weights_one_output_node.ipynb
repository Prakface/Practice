{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Appending Previous weights_one_output_node.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prakface/Practice/blob/master/Appending_Previous_weights_one_output_node.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyuuKsCtSRaB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3c2f4b92-b0ee-4793-e1df-43da81c9fd38"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "url='https://raw.githubusercontent.com/Prakface/Practice/master/One_mon_present_full.csv'\n",
        "\n",
        "url2='https://raw.githubusercontent.com/Prakface/Practice/master/Final_one_month_prev_features.csv'\n",
        "\n",
        "url_h='https://raw.githubusercontent.com/Prakface/Practice/master/heuristic_labels.csv'\n",
        "\n",
        "data = pd.read_csv(url) \n",
        "\n",
        "data2= pd.read_csv(url2)\n",
        "\n",
        "print(\"Data Shape:\", data.shape) \n",
        "\n",
        "#data=pd.read_csv(url)\n",
        "\n",
        "df=pd.DataFrame(data)\n",
        "print(data.head()) \n",
        "\n",
        "\n",
        "data_modified= data.dropna()\n",
        "\n",
        "data_modified.to_csv(\"modifiedData.csv\", index=False)\n",
        "\n",
        "\n",
        "df2=pd.read_csv(\"modifiedData.csv\")\n",
        "\n",
        "print(df2[0:6])\n",
        "\n",
        "print(df2['result'])\n",
        "\n",
        "df_main=df2[df2.columns[~df2.columns.isin(['text', 'user_name'])]]\n",
        "\n",
        "print(df_main.columns)\n",
        "\n",
        "print(len(df_main.columns))\n",
        "\n",
        "  \n",
        "# X_1, y_1 means rpesent tweets' data\n",
        "X_1=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]] #removing result attribute as it is class label, hence we get 34 attributes\n",
        "X_1=X_1.iloc[:,1:len(X_1.columns)].values   #removing the unnamed attribute\n",
        "x_1=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]]\n",
        "x_1=x_1.iloc[:,1:len(x_1.columns)].values \n",
        "y_1=df_main.loc[:, ['result']].values\n",
        "\n",
        "\n",
        "print(type(X_1), type(y_1), type(x_1), type(y_1))\n",
        "\n",
        "print(X_1.shape)\n",
        "print(y_1.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Shape: (1908, 40)\n",
            "  Unnamed: 0 cat1  cat10  ...      tweet_id  url      user_name\n",
            "0          0    0      0  ...  8.323790e+17  0.0  THEJEROMEOWEN\n",
            "1          1    0      0  ...  8.323786e+17  0.0       Acejinjo\n",
            "2          2    0      0  ...  8.323780e+17  0.0     RabRakha21\n",
            "3          3    0      0  ...  8.323777e+17  0.0       RS_Aloha\n",
            "4          4    0      0  ...  8.323767e+17  0.0  preciselyizzy\n",
            "\n",
            "[5 rows x 40 columns]\n",
            "   Unnamed: 0  cat1  cat10  ...      tweet_id  url        user_name\n",
            "0           0     0      0  ...  8.323790e+17  0.0    THEJEROMEOWEN\n",
            "1           1     0      0  ...  8.323786e+17  0.0         Acejinjo\n",
            "2           2     0      0  ...  8.323780e+17  0.0       RabRakha21\n",
            "3           3     0      0  ...  8.323777e+17  0.0         RS_Aloha\n",
            "4           4     0      0  ...  8.323767e+17  0.0    preciselyizzy\n",
            "5           5     0      0  ...  8.323759e+17  0.0  thefireistarted\n",
            "\n",
            "[6 rows x 40 columns]\n",
            "0       1.0\n",
            "1       1.0\n",
            "2       1.0\n",
            "3       1.0\n",
            "4       1.0\n",
            "5       1.0\n",
            "6       1.0\n",
            "7       1.0\n",
            "8       1.0\n",
            "9       1.0\n",
            "10      1.0\n",
            "11      1.0\n",
            "12      1.0\n",
            "13      1.0\n",
            "14      1.0\n",
            "15      1.0\n",
            "16      1.0\n",
            "17      1.0\n",
            "18      1.0\n",
            "19      1.0\n",
            "20      1.0\n",
            "21      1.0\n",
            "22      1.0\n",
            "23      1.0\n",
            "24      1.0\n",
            "25      1.0\n",
            "26      1.0\n",
            "27      1.0\n",
            "28      1.0\n",
            "29      1.0\n",
            "       ... \n",
            "1876    0.0\n",
            "1877    0.0\n",
            "1878    0.0\n",
            "1879    0.0\n",
            "1880    0.0\n",
            "1881    0.0\n",
            "1882    0.0\n",
            "1883    0.0\n",
            "1884    0.0\n",
            "1885    0.0\n",
            "1886    0.0\n",
            "1887    0.0\n",
            "1888    0.0\n",
            "1889    0.0\n",
            "1890    0.0\n",
            "1891    0.0\n",
            "1892    0.0\n",
            "1893    0.0\n",
            "1894    0.0\n",
            "1895    0.0\n",
            "1896    0.0\n",
            "1897    0.0\n",
            "1898    0.0\n",
            "1899    0.0\n",
            "1900    0.0\n",
            "1901    0.0\n",
            "1902    0.0\n",
            "1903    0.0\n",
            "1904    0.0\n",
            "1905    0.0\n",
            "Name: result, Length: 1906, dtype: float64\n",
            "Index(['Unnamed: 0', 'cat1', 'cat10', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6',\n",
            "       'cat7', 'cat8', 'cat9', 'favorite_count', 'hour', 'image', 'level',\n",
            "       'nadj', 'nadv', 'nemoji', 'nlevel', 'nword', 'orginal', 'padj', 'padv',\n",
            "       'pemoji', 'plevel', 'pnoun', 'punc1', 'punc2', 'punc3', 'pword',\n",
            "       'question', 'result', 'retweets_count', 'sarcasm', 'sentiment', 'time',\n",
            "       'tweet_id', 'url'],\n",
            "      dtype='object')\n",
            "38\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(1906, 34)\n",
            "(1906, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdo99HcxTGL2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b6db12b1-0a68-46ba-e421-b3b5950b8601"
      },
      "source": [
        "data2= pd.read_csv(url2)\n",
        "\n",
        "print(\"Data Shape:\", data2.shape) \n",
        "\n",
        "#data=pd.read_csv(url)\n",
        "\n",
        "df_prev=pd.DataFrame(data2)\n",
        "print(data2.head()) \n",
        "\n",
        "\n",
        "data2_modified= data2.dropna()\n",
        "\n",
        "data2_modified.to_csv(\"modifiedData2.csv\", index=False)\n",
        "\n",
        "\n",
        "df_2=pd.read_csv(\"modifiedData2.csv\")\n",
        "\n",
        "print(df_2[0:6])\n",
        "\n",
        "print(df_2['result'])\n",
        "\n",
        "df_main2=df_2[df_2.columns[~df_2.columns.isin(['text', 'user_name'])]]\n",
        "\n",
        "print(df_main2.columns)\n",
        "\n",
        "print(len(df_main2.columns))\n",
        "\n",
        "  \n",
        "\n",
        "X_2=df_main2[df_main2.columns[~df_main2.columns.isin(['time', 'tweet_id','result'])]] #removing result attribute as it is class label, hence we get 34 attributes\n",
        "X_2=X_2.iloc[:,1:len(X_2.columns)].values   #removing the unnamed attribute\n",
        "x_2=df_main2[df_main2.columns[~df_main2.columns.isin(['time', 'tweet_id','result'])]]\n",
        "x_2=x_2.iloc[:,1:len(x_2.columns)].values \n",
        "y_2=df_main2.loc[:, ['result']].values\n",
        "\n",
        "\n",
        "print(type(X_2), type(y_2), type(x_2), type(y_2))\n",
        "\n",
        "print(X_2.shape)\n",
        "print(y_2.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Shape: (3004, 38)\n",
            "   Unnamed: 0  cat1  cat10  ...             tweet_id  url      user_name\n",
            "0           0     0      0  ...  1155575657402961920    1  THEJEROMEOWEN\n",
            "1           1     0      0  ...  1155459426243043328    0  THEJEROMEOWEN\n",
            "2           2     0      0  ...  1126969730307448832    0     rabrakha14\n",
            "3           3     0      0  ...  1155277550794338304    0       RS_Aloha\n",
            "4           4     0      0  ...  1155188179395207168    0       RS_Aloha\n",
            "\n",
            "[5 rows x 38 columns]\n",
            "   Unnamed: 0  cat1  cat10  ...             tweet_id  url      user_name\n",
            "0           0     0      0  ...  1155575657402961920    1  THEJEROMEOWEN\n",
            "1           1     0      0  ...  1155459426243043328    0  THEJEROMEOWEN\n",
            "2           2     0      0  ...  1126969730307448832    0     rabrakha14\n",
            "3           3     0      0  ...  1155277550794338304    0       RS_Aloha\n",
            "4           4     0      0  ...  1155188179395207168    0       RS_Aloha\n",
            "5           5     0      0  ...  1154962871765393408    0  preciselyizzy\n",
            "\n",
            "[6 rows x 38 columns]\n",
            "0       0\n",
            "1       0\n",
            "2       0\n",
            "3       0\n",
            "4       0\n",
            "5       0\n",
            "6       0\n",
            "7       0\n",
            "8       0\n",
            "9       0\n",
            "10      0\n",
            "11      0\n",
            "12      0\n",
            "13      0\n",
            "14      0\n",
            "15      0\n",
            "16      0\n",
            "17      0\n",
            "18      0\n",
            "19      0\n",
            "20      0\n",
            "21      0\n",
            "22      0\n",
            "23      0\n",
            "24      0\n",
            "25      0\n",
            "26      0\n",
            "27      0\n",
            "28      0\n",
            "29      0\n",
            "       ..\n",
            "2974    0\n",
            "2975    0\n",
            "2976    0\n",
            "2977    0\n",
            "2978    0\n",
            "2979    0\n",
            "2980    0\n",
            "2981    0\n",
            "2982    0\n",
            "2983    0\n",
            "2984    0\n",
            "2985    0\n",
            "2986    0\n",
            "2987    0\n",
            "2988    0\n",
            "2989    0\n",
            "2990    0\n",
            "2991    0\n",
            "2992    0\n",
            "2993    0\n",
            "2994    0\n",
            "2995    0\n",
            "2996    0\n",
            "2997    0\n",
            "2998    0\n",
            "2999    0\n",
            "3000    0\n",
            "3001    0\n",
            "3002    0\n",
            "3003    0\n",
            "Name: result, Length: 3004, dtype: int64\n",
            "Index(['Unnamed: 0', 'cat1', 'cat10', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6',\n",
            "       'cat7', 'cat8', 'cat9', 'favorite_count', 'hour', 'image', 'level',\n",
            "       'nadj', 'nadv', 'nemoji', 'nlevel', 'nword', 'orginal', 'padj', 'padv',\n",
            "       'pemoji', 'plevel', 'pnoun', 'punc1', 'punc2', 'punc3', 'pword',\n",
            "       'question', 'result', 'retweets_count', 'sarcasm', 'sentiment',\n",
            "       'tweet_id', 'url'],\n",
            "      dtype='object')\n",
            "37\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(3004, 34)\n",
            "(3004, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ekN67DFTN9K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "04557e68-9da6-4aac-a87a-b1548ea3211d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df_h=pd.read_csv(url_h)\n",
        "\n",
        "print(df_h.columns)\n",
        "\n",
        "\n",
        "'''\n",
        "the following way is wrong\n",
        "label1=df_h.heuristic1.values\n",
        "label_1=df_h.heuristic1_1.values\n",
        "label2=df_h.heuristic2.values\n",
        "label3=df_h.heuristic3.values\n",
        "\n",
        "print(type(label1), type(label2), type(label3))\n",
        "\n",
        "\n",
        "\n",
        "print(type(label1), type(label2), type(label3))\n",
        "\n",
        "print(y_1.shape, label1.shape, label2.shape, label3.shape)\n",
        "\n",
        "#print(len(label1),len(label2),len(label3), len(label_1))\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "label1=df_h.loc[:, ['heuristic1']].values\n",
        "label_1=df_h.loc[:,['heuristic1_1']].values\n",
        "label2=df_h.loc[:, ['heuristic2']].values\n",
        "label3=df_h.loc[:, ['heuristic3']].values\n",
        "\n",
        "print(type(label1), type(label2), type(label3))\n",
        "\n",
        "\n",
        "\n",
        "print(type(label1), type(label2), type(label3))\n",
        "\n",
        "print(y_1.shape, label1.shape, label2.shape, label3.shape)\n",
        "\n",
        "\n",
        "tem1y=np.append(y_1, label1, axis=0)\n",
        "tem2y=np.append(y_1, label2, axis=0)\n",
        "tem3y=np.append(y_1, label3, axis=0)\n",
        "\n",
        "tem_1y=np.append(y_1, label_1, axis=0)\n",
        "\n",
        "T_h1=torch.from_numpy(tem1y)\n",
        "T_h2=torch.from_numpy(tem2y)\n",
        "T_h3=torch.from_numpy(tem3y)\n",
        "T_h_1=torch.from_numpy(tem_1y)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Unnamed: 0', 'heuristic1', 'heuristic1_1', 'heuristic2', 'heuristic3'], dtype='object')\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(1906, 1) (3273, 1) (3273, 1) (3273, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26g-UYJ5TTDL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a07fc3d3-2119-4bec-d8c4-1f29ffd3011a"
      },
      "source": [
        "#Appending present and previosu data with actual label data...\n",
        "\n",
        "tem=np.append(X_1, X_2, axis=0)\n",
        "tem_y=np.append(y_1,label1,axis=0)\n",
        "print(X_1.shape, X_2.shape, tem.shape)\n",
        "print(y_1.shape, y_2.shape, tem_y.shape)\n",
        "\n",
        "X=tem\n",
        "T=tem_y\n",
        "\n",
        "print(X.shape, T.shape)\n",
        "\n",
        "print(type(X_1))\n",
        "#convert to tensor\n",
        "X = torch.from_numpy(X)\n",
        "T = torch.from_numpy(T)\n",
        "\n",
        "X_1 = torch.from_numpy(X_1)\n",
        "T_1 = torch.from_numpy(y_1)\n",
        "\n",
        "X_2 = torch.from_numpy(X_2)\n",
        "T_2 = torch.from_numpy(y_2)\n",
        "\n",
        "print(type(X), type(T))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1906, 34) (3004, 34) (4910, 34)\n",
            "(1906, 1) (3004, 1) (5179, 1)\n",
            "(4910, 34) (5179, 1)\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEBSyy3oTWfA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "b568fb11-dfdf-491a-e3a3-78cfead50be3"
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.nn.functional as F\n",
        "\n",
        "## create training and validation split \n",
        "split_size = int(0.8 * len(X_1))\n",
        "index_list = list(range(len(X_1)))\n",
        "train_idx, valid_idx = index_list[:split_size], index_list[split_size:]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "x_tr = torch.tensor(X[train_idx], dtype=torch.long)\n",
        "y_tr = torch.tensor(T[train_idx], dtype=torch.float32)\n",
        "train = TensorDataset(x_tr, y_tr)\n",
        "trainloader = DataLoader(train, batch_size=128)\n",
        "'''\n",
        "\n",
        "x_tr = torch.tensor(X_1[train_idx], dtype=torch.long)\n",
        "y_tr = torch.tensor(T_1[train_idx], dtype=torch.float32)\n",
        "train = TensorDataset(x_tr, y_tr)\n",
        "trainloader = DataLoader(train, batch_size=128)\n",
        "\n",
        "x_valid = torch.tensor(X_1[valid_idx], dtype=torch.long)\n",
        "y_valid = torch.tensor(T_1[valid_idx], dtype=torch.float32)\n",
        "valid = TensorDataset(x_valid, y_valid)\n",
        "validloader = DataLoader(valid, batch_size=128)\n",
        "\n",
        "x_tr2 = torch.tensor(X_2[train_idx], dtype=torch.long)\n",
        "y_tr2 = torch.tensor(T_2[train_idx], dtype=torch.float32)\n",
        "train2 = TensorDataset(x_tr2, y_tr2)\n",
        "trainloader2 = DataLoader(train2, batch_size=128)\n",
        "\n",
        "\n",
        "\n",
        "##Following is Auxiliary data set\n",
        "\n",
        "\n",
        "split_size = int(0.8 * len(X_2))\n",
        "index_list = list(range(len(X_2)))\n",
        "train_idx, valid_idx = index_list[:split_size], index_list[split_size:]\n",
        "\n",
        "\n",
        "x_tr2 = torch.tensor(X_2[train_idx], dtype=torch.long)\n",
        "y_tr2 = torch.tensor(T_2[train_idx], dtype=torch.float32)\n",
        "train2 = TensorDataset(x_tr2, y_tr2)\n",
        "trainloader2 = DataLoader(train2, batch_size=128)\n",
        "\n",
        "x_valid2 = torch.tensor(X_2[valid_idx], dtype=torch.long)\n",
        "y_valid2 = torch.tensor(T_2[valid_idx], dtype=torch.float32)\n",
        "valid2 = TensorDataset(x_valid2, y_valid2)\n",
        "validloader = DataLoader(valid2, batch_size=128)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCnwK-MPTamG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "f751f68d-1297-4097-cea3-80da5758c0cb"
      },
      "source": [
        "##Concatenating the tensors\n",
        "\n",
        "import torch as pytorch\n",
        "\n",
        "pytorch.set_default_tensor_type('torch.DoubleTensor')\n",
        "\n",
        "X_1=X_1.type(torch.DoubleTensor)\n",
        "T_1=T_1.type(torch.DoubleTensor)\n",
        "\n",
        "X_2=X_2.type(torch.DoubleTensor)\n",
        "T_2=T_2.type(torch.DoubleTensor)\n",
        "\n",
        "\n",
        "X=torch.cat((X_1,X_2), 0)\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "X_tr=torch.cat((x_tr,x_tr2),0)\n",
        "\n",
        "print(X_tr.shape)\n",
        "\n",
        "Y_tr=torch.cat((y_tr,y_tr2),0)  ##y_tr2 doesn't have values, we should calculate using heuristics\n",
        "\n",
        "X_valid=torch.cat((x_valid,x_valid2),0)\n",
        "\n",
        "Y_valid=torch.cat((y_valid,y_valid2),0)\n",
        "\n",
        "Train=TensorDataset(X_tr, Y_tr)\n",
        "TrainLoader=DataLoader(Train, batch_size=128)\n",
        "\n",
        "\n",
        "Valid=TensorDataset(X_valid, Y_valid)\n",
        "ValidLoader=DataLoader(Valid, batch_size=128)\n",
        "\n",
        "\n",
        "print(X_tr.type())\n",
        "\n",
        "X_tr=torch.tensor(X_tr, dtype=torch.double)\n",
        "\n",
        "X_valid=torch.tensor(X_valid, dtype=torch.double)\n",
        "\n",
        "print(X_tr.type(), X_valid.type())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4910, 34])\n",
            "torch.Size([3927, 34])\n",
            "torch.LongTensor\n",
            "torch.DoubleTensor torch.DoubleTensor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ4KumUcTpvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 50\n",
        "n_iters = 3000\n",
        "epochs = n_iters / (len(X_1) / batch_size)\n",
        "epochs2= n_iters / (len(X_2) / batch_size)\n",
        "#epochs= n_iters/((len(X_1)+len(X_2))/batch_size)\n",
        "input_dim = 34\n",
        "output_dim = 1\n",
        "lr_rate = 0.001\n",
        "\n",
        "class LogisticRegression(torch.nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = torch.nn.Linear(input_dim,1)\n",
        "        self.sigmoid=nn.Sigmoid()\n",
        "        #self.linear = torch.nn.Linear(2*input_dim, output_dim)\n",
        "        #raise NotImplementedError()\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = self.linear(x)\n",
        "        #outputs = torch.sigmoid(outputs)\n",
        "        outputs=self.sigmoid(outputs)\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXFQ0kdjUWor",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2d131595-e8f8-4ac6-8936-dac753029bca"
      },
      "source": [
        "model = LogisticRegression(input_dim)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss() # computes softmax and then the cross entropy\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n initialized_weights = \\n\")\n",
        "for param in model.parameters():\n",
        "  print(param.data,\"Hi\\n\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " initialized_weights = \n",
            "\n",
            "tensor([[ 0.0008,  0.0947, -0.1065, -0.1455, -0.1184,  0.1585, -0.1456, -0.1269,\n",
            "          0.0481,  0.0275, -0.0834, -0.0839,  0.1300,  0.1578,  0.0997,  0.0817,\n",
            "         -0.0487, -0.0502,  0.1698, -0.0350, -0.0276,  0.1011,  0.0646, -0.1476,\n",
            "          0.1237, -0.1166,  0.0754,  0.0275, -0.0185,  0.1583, -0.0173,  0.1128,\n",
            "         -0.1325,  0.1212]]) Hi\n",
            "\n",
            "tensor([-0.1489]) Hi\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDOk5iTjU492",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "c17a9fe7-32dd-4b0a-dea3-2699869916af"
      },
      "source": [
        "##Training the data\n",
        "iterations = 0\n",
        "for epoch in range(int(epochs)):\n",
        "    for i, (data_X, labels) in enumerate(trainloader):\n",
        "        data_X = Variable(data_X.view(-1,34))\n",
        "        print(\"\\n length of data_X = \", len(data_X), data_X.shape)\n",
        "        labels = Variable(labels)\n",
        "        labels=torch.tensor(labels, dtype=torch.long)\n",
        "        #print(labels.__class__)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        data_X=torch.tensor(data_X, dtype=torch.double)\n",
        "        #print(data_X.shape, data_X.type())\n",
        "        \n",
        "        outputs = model(data_X)\n",
        "        #outputs=model()\n",
        "        labels = labels.squeeze_()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        iterations+=1\n",
        "        if iterations%100==0:\n",
        "            # calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for data_X, labels in validloader:\n",
        "                data_X = Variable(data_X.view(-1, 34))\n",
        "                \n",
        "                data_X=torch.tensor(data_X, dtype=torch.double)\n",
        "                labels=torch.tensor(labels, dtype=torch.long)\n",
        "                \n",
        "                outputs = model(data_X)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total+= labels.size(0)\n",
        "                # for gpu, bring the predicted and labels back to cpu fro python operations to work\n",
        "                pr=predicted.numpy()\n",
        "                lb=labels.numpy()\n",
        "                for i in range(len(pr)):\n",
        "                  if(pr[i]==lb[i]):\n",
        "                    correct = correct+ 1\n",
        "                    \n",
        "                #correct+= (predicted == labels).sum()\n",
        "            accuracy = 100 * correct/total\n",
        "            print(\"Iteration: {}. Loss: {}.Correct:{}. total:{}. Accuracy: {}.\".format(iterations, loss.item(), correct, total,  accuracy))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " length of data_X =  128 torch.Size([128, 34])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-1023803e6516>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#outputs=model()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 916\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2007\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2009\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1836\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1837\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1838\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1839\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /pytorch/aten/src/THNN/generic/ClassNLLCriterion.c:97"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQzLT4jrsKiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}