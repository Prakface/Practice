{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Appending _previous_with_new_weights.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prakface/Practice/blob/master/Appending__previous_with_new_weights.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeeEVGmX0Yol",
        "colab_type": "code",
        "outputId": "d8de6f7f-c038-41e1-a896-071607153c78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "url='https://raw.githubusercontent.com/Prakface/Practice/master/One_mon_present_full.csv'\n",
        "\n",
        "url2='https://raw.githubusercontent.com/Prakface/Practice/master/Final_one_month_prev_features.csv'\n",
        "\n",
        "data = pd.read_csv(url) \n",
        "\n",
        "data2= pd.read_csv(url2)\n",
        "\n",
        "print(\"Data Shape:\", data.shape) \n",
        "\n",
        "#data=pd.read_csv(url)\n",
        "\n",
        "df=pd.DataFrame(data)\n",
        "print(data.head()) \n",
        "\n",
        "\n",
        "data_modified= data.dropna()\n",
        "\n",
        "data_modified.to_csv(\"modifiedData.csv\", index=False)\n",
        "\n",
        "\n",
        "df2=pd.read_csv(\"modifiedData.csv\")\n",
        "\n",
        "print(df2[0:6])\n",
        "\n",
        "print(df2['result'])\n",
        "\n",
        "df_main=df2[df2.columns[~df2.columns.isin(['text', 'user_name'])]]\n",
        "\n",
        "print(df_main.columns)\n",
        "\n",
        "print(len(df_main.columns))\n",
        "\n",
        "  \n",
        "# X_1, y_1 means rpesent tweets' data\n",
        "X_1=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]] #removing result attribute as it is class label, hence we get 34 attributes\n",
        "X_1=X_1.iloc[:,1:len(X_1.columns)].values   #removing the unnamed attribute\n",
        "x_1=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]]\n",
        "x_1=x_1.iloc[:,1:len(x_1.columns)].values \n",
        "y_1=df_main.loc[:, ['result']].values\n",
        "\n",
        "\n",
        "print(type(X_1), type(y_1), type(x_1), type(y_1))\n",
        "\n",
        "print(X_1.shape)\n",
        "print(y_1.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Shape: (1908, 40)\n",
            "  Unnamed: 0 cat1  cat10  ...      tweet_id  url      user_name\n",
            "0          0    0      0  ...  8.323790e+17  0.0  THEJEROMEOWEN\n",
            "1          1    0      0  ...  8.323786e+17  0.0       Acejinjo\n",
            "2          2    0      0  ...  8.323780e+17  0.0     RabRakha21\n",
            "3          3    0      0  ...  8.323777e+17  0.0       RS_Aloha\n",
            "4          4    0      0  ...  8.323767e+17  0.0  preciselyizzy\n",
            "\n",
            "[5 rows x 40 columns]\n",
            "   Unnamed: 0  cat1  cat10  ...      tweet_id  url        user_name\n",
            "0           0     0      0  ...  8.323790e+17  0.0    THEJEROMEOWEN\n",
            "1           1     0      0  ...  8.323786e+17  0.0         Acejinjo\n",
            "2           2     0      0  ...  8.323780e+17  0.0       RabRakha21\n",
            "3           3     0      0  ...  8.323777e+17  0.0         RS_Aloha\n",
            "4           4     0      0  ...  8.323767e+17  0.0    preciselyizzy\n",
            "5           5     0      0  ...  8.323759e+17  0.0  thefireistarted\n",
            "\n",
            "[6 rows x 40 columns]\n",
            "0       1.0\n",
            "1       1.0\n",
            "2       1.0\n",
            "3       1.0\n",
            "4       1.0\n",
            "5       1.0\n",
            "6       1.0\n",
            "7       1.0\n",
            "8       1.0\n",
            "9       1.0\n",
            "10      1.0\n",
            "11      1.0\n",
            "12      1.0\n",
            "13      1.0\n",
            "14      1.0\n",
            "15      1.0\n",
            "16      1.0\n",
            "17      1.0\n",
            "18      1.0\n",
            "19      1.0\n",
            "20      1.0\n",
            "21      1.0\n",
            "22      1.0\n",
            "23      1.0\n",
            "24      1.0\n",
            "25      1.0\n",
            "26      1.0\n",
            "27      1.0\n",
            "28      1.0\n",
            "29      1.0\n",
            "       ... \n",
            "1876    0.0\n",
            "1877    0.0\n",
            "1878    0.0\n",
            "1879    0.0\n",
            "1880    0.0\n",
            "1881    0.0\n",
            "1882    0.0\n",
            "1883    0.0\n",
            "1884    0.0\n",
            "1885    0.0\n",
            "1886    0.0\n",
            "1887    0.0\n",
            "1888    0.0\n",
            "1889    0.0\n",
            "1890    0.0\n",
            "1891    0.0\n",
            "1892    0.0\n",
            "1893    0.0\n",
            "1894    0.0\n",
            "1895    0.0\n",
            "1896    0.0\n",
            "1897    0.0\n",
            "1898    0.0\n",
            "1899    0.0\n",
            "1900    0.0\n",
            "1901    0.0\n",
            "1902    0.0\n",
            "1903    0.0\n",
            "1904    0.0\n",
            "1905    0.0\n",
            "Name: result, Length: 1906, dtype: float64\n",
            "Index(['Unnamed: 0', 'cat1', 'cat10', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6',\n",
            "       'cat7', 'cat8', 'cat9', 'favorite_count', 'hour', 'image', 'level',\n",
            "       'nadj', 'nadv', 'nemoji', 'nlevel', 'nword', 'orginal', 'padj', 'padv',\n",
            "       'pemoji', 'plevel', 'pnoun', 'punc1', 'punc2', 'punc3', 'pword',\n",
            "       'question', 'result', 'retweets_count', 'sarcasm', 'sentiment', 'time',\n",
            "       'tweet_id', 'url'],\n",
            "      dtype='object')\n",
            "38\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(1906, 34)\n",
            "(1906, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq0FqtXk0gT9",
        "colab_type": "code",
        "outputId": "0fc5d226-1678-40c5-85f5-9c39cb8ef8df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data2= pd.read_csv(url2)\n",
        "\n",
        "print(\"Data Shape:\", data2.shape) \n",
        "\n",
        "#data=pd.read_csv(url)\n",
        "\n",
        "df_prev=pd.DataFrame(data2)\n",
        "print(data2.head()) \n",
        "\n",
        "\n",
        "data2_modified= data2.dropna()\n",
        "\n",
        "data2_modified.to_csv(\"modifiedData2.csv\", index=False)\n",
        "\n",
        "\n",
        "df_2=pd.read_csv(\"modifiedData2.csv\")\n",
        "\n",
        "print(df_2[0:6])\n",
        "\n",
        "print(df_2['result'])\n",
        "\n",
        "df_main2=df_2[df_2.columns[~df_2.columns.isin(['text', 'user_name'])]]\n",
        "\n",
        "print(df_main2.columns)\n",
        "\n",
        "print(len(df_main2.columns))\n",
        "\n",
        "  \n",
        "\n",
        "X_2=df_main2[df_main2.columns[~df_main2.columns.isin(['time', 'tweet_id','result'])]] #removing result attribute as it is class label, hence we get 34 attributes\n",
        "X_2=X_2.iloc[:,1:len(X_2.columns)].values   #removing the unnamed attribute\n",
        "x_2=df_main2[df_main2.columns[~df_main2.columns.isin(['time', 'tweet_id','result'])]]\n",
        "x_2=x_2.iloc[:,1:len(x_2.columns)].values \n",
        "y_2=df_main2.loc[:, ['result']].values\n",
        "\n",
        "\n",
        "print(type(X_2), type(y_2), type(x_2), type(y_2))\n",
        "\n",
        "print(X_2.shape)\n",
        "print(y_2.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Shape: (3004, 38)\n",
            "   Unnamed: 0  cat1  cat10  ...             tweet_id  url      user_name\n",
            "0           0     0      0  ...  1155575657402961920    1  THEJEROMEOWEN\n",
            "1           1     0      0  ...  1155459426243043328    0  THEJEROMEOWEN\n",
            "2           2     0      0  ...  1126969730307448832    0     rabrakha14\n",
            "3           3     0      0  ...  1155277550794338304    0       RS_Aloha\n",
            "4           4     0      0  ...  1155188179395207168    0       RS_Aloha\n",
            "\n",
            "[5 rows x 38 columns]\n",
            "   Unnamed: 0  cat1  cat10  ...             tweet_id  url      user_name\n",
            "0           0     0      0  ...  1155575657402961920    1  THEJEROMEOWEN\n",
            "1           1     0      0  ...  1155459426243043328    0  THEJEROMEOWEN\n",
            "2           2     0      0  ...  1126969730307448832    0     rabrakha14\n",
            "3           3     0      0  ...  1155277550794338304    0       RS_Aloha\n",
            "4           4     0      0  ...  1155188179395207168    0       RS_Aloha\n",
            "5           5     0      0  ...  1154962871765393408    0  preciselyizzy\n",
            "\n",
            "[6 rows x 38 columns]\n",
            "0       0\n",
            "1       0\n",
            "2       0\n",
            "3       0\n",
            "4       0\n",
            "5       0\n",
            "6       0\n",
            "7       0\n",
            "8       0\n",
            "9       0\n",
            "10      0\n",
            "11      0\n",
            "12      0\n",
            "13      0\n",
            "14      0\n",
            "15      0\n",
            "16      0\n",
            "17      0\n",
            "18      0\n",
            "19      0\n",
            "20      0\n",
            "21      0\n",
            "22      0\n",
            "23      0\n",
            "24      0\n",
            "25      0\n",
            "26      0\n",
            "27      0\n",
            "28      0\n",
            "29      0\n",
            "       ..\n",
            "2974    0\n",
            "2975    0\n",
            "2976    0\n",
            "2977    0\n",
            "2978    0\n",
            "2979    0\n",
            "2980    0\n",
            "2981    0\n",
            "2982    0\n",
            "2983    0\n",
            "2984    0\n",
            "2985    0\n",
            "2986    0\n",
            "2987    0\n",
            "2988    0\n",
            "2989    0\n",
            "2990    0\n",
            "2991    0\n",
            "2992    0\n",
            "2993    0\n",
            "2994    0\n",
            "2995    0\n",
            "2996    0\n",
            "2997    0\n",
            "2998    0\n",
            "2999    0\n",
            "3000    0\n",
            "3001    0\n",
            "3002    0\n",
            "3003    0\n",
            "Name: result, Length: 3004, dtype: int64\n",
            "Index(['Unnamed: 0', 'cat1', 'cat10', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6',\n",
            "       'cat7', 'cat8', 'cat9', 'favorite_count', 'hour', 'image', 'level',\n",
            "       'nadj', 'nadv', 'nemoji', 'nlevel', 'nword', 'orginal', 'padj', 'padv',\n",
            "       'pemoji', 'plevel', 'pnoun', 'punc1', 'punc2', 'punc3', 'pword',\n",
            "       'question', 'result', 'retweets_count', 'sarcasm', 'sentiment',\n",
            "       'tweet_id', 'url'],\n",
            "      dtype='object')\n",
            "37\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(3004, 34)\n",
            "(3004, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL987O0l0juP",
        "colab_type": "code",
        "outputId": "1d14f73d-e486-4cd4-ee49-8814687d270b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#Appending present and previosu data\n",
        "\n",
        "tem=np.append(X_1, X_2, axis=0)\n",
        "tem_y=np.append(y_1,y_2,axis=0)\n",
        "print(X_1.shape, X_2.shape, tem.shape)\n",
        "print(y_1.shape, y_2.shape, tem_y.shape)\n",
        "\n",
        "X=tem\n",
        "T=tem_y\n",
        "\n",
        "print(X.shape, T.shape)\n",
        "\n",
        "print(type(X_1))\n",
        "#convert to tensor\n",
        "X = torch.from_numpy(X)\n",
        "T = torch.from_numpy(T)\n",
        "\n",
        "X_1 = torch.from_numpy(X_1)\n",
        "T_1 = torch.from_numpy(y_1)\n",
        "\n",
        "X_2 = torch.from_numpy(X_2)\n",
        "T_2 = torch.from_numpy(y_2)\n",
        "\n",
        "print(type(X), type(T))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1906, 34) (3004, 34) (4910, 34)\n",
            "(1906, 1) (3004, 1) (4910, 1)\n",
            "(4910, 34) (4910, 1)\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJyAI-8h0pKH",
        "colab_type": "code",
        "outputId": "e39edab3-85fc-4687-91e6-cf9a67532cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "\n",
        "\n",
        "#X_2 = torch.from_numpy(X_2)\n",
        "#T_2 = torch.from_numpy(y_2)\n",
        "\n",
        "import torch as pytorch\n",
        "\n",
        "pytorch.set_default_tensor_type('torch.DoubleTensor')\n",
        "#random weights\n",
        "X_2=X_2.type(torch.DoubleTensor)\n",
        "T_2=T_2.type(torch.DoubleTensor)\n",
        "\n",
        "print(torch.Tensor(X_2).dtype)\n",
        "print(torch.Tensor(X_1).dtype)\n",
        "print(\"\\n dtype of T_2 \\n\", torch.Tensor(T_2).dtype)\n",
        "\n",
        "W = Variable(torch.randn(1, 34, dtype=torch.double), requires_grad=True)\n",
        "b = Variable(torch.randn(1, 1, dtype=torch.double), requires_grad=True)\n",
        "print(W.size())\n",
        "\n",
        "#Weights for Previoes tweets\n",
        "#W1 = Variable(torch.randn(1, 34, dtype=torch.double), requires_grad=True)\n",
        "W_p = Variable(torch.randn(1, 34, dtype=torch.double), requires_grad=True)\n",
        "#W_p=W_p.type(torch.LongTensor)\n",
        "b_p = Variable(torch.randn(1, 1, dtype=torch.double), requires_grad=True)\n",
        "print(W_p.size(), torch.Tensor(W_p).dtype)\n",
        "print(W.size(), torch.Tensor(W_p).dtype)\n",
        "\n",
        "\n",
        "#sigmoid\n",
        "def sigmoid(x):\n",
        "    return 1/(1+torch.exp(-x))\n",
        "\n",
        "# Loss (cross entropy) error function\n",
        "def error(output, target):\n",
        "    return -target * torch.log(output) - (1-target) * torch.log(1-output)\n",
        "  \n",
        "#out = sigmoid(torch.mm(X, W.view(34,1))+b)\n",
        "\n",
        "out_present= sigmoid(torch.mm(X_1, W.view(34,1))+b)\n",
        "\n",
        "#W1=W1.type(torch.LongTensor)\n",
        "#out_present2= sigmoid(torch.mm(X_2, W1.view(34,1))+b)\n",
        "\n",
        "out_prev= sigmoid(torch.mm(X_2, W_p.view(34,1))+b_p)\n",
        "print(W.size())\n",
        "\n",
        "\n",
        "\n",
        "#we also could use: torch.nn.Sigmoid()\n",
        "#out = torch.nn.Sigmoid()(torch.mm(X, W.view(2,1))+b)\n",
        "\n",
        "#print(out.shape, T.shape)\n",
        "\n",
        "print(out_present.shape, T_1.shape)\n",
        "\n",
        "print(out_prev.shape, T_2.shape)\n",
        "\n",
        "\n",
        "#err = error(out,T)\n",
        "err_1 = error(out_present,T_1)\n",
        "err_2 = error(out_prev,T_2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#loss = torch.mean(err)\n",
        "loss = torch.sum(torch.mean(err_1)+torch.mean(err_2))\n",
        "\n",
        "print(err_1, err_2)\n",
        "print(torch.sum(err_1), torch.sum(err_2))\n",
        "\n",
        "#we need to scale down"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.float64\n",
            "torch.float64\n",
            "\n",
            " dtype of T_2 \n",
            " torch.float64\n",
            "torch.Size([1, 34])\n",
            "torch.Size([1, 34]) torch.float64\n",
            "torch.Size([1, 34]) torch.float64\n",
            "torch.Size([1, 34])\n",
            "torch.Size([1906, 1]) torch.Size([1906, 1])\n",
            "torch.Size([3004, 1]) torch.Size([3004, 1])\n",
            "tensor([[4.2635e+01],\n",
            "        [4.5219e+01],\n",
            "        [4.0113e+01],\n",
            "        ...,\n",
            "        [2.7789e-13],\n",
            "        [1.8874e-14],\n",
            "        [4.8073e-13]], grad_fn=<SubBackward0>) tensor([[9.9692e-10],\n",
            "        [       nan],\n",
            "        [3.0203e-11],\n",
            "        ...,\n",
            "        [1.0241e-09],\n",
            "        [       nan],\n",
            "        [       nan]], grad_fn=<SubBackward0>)\n",
            "tensor(nan, grad_fn=<SumBackward0>) tensor(nan, grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUt6oZX81uQe",
        "colab_type": "text"
      },
      "source": [
        "unexpected type error , while the same type is working for out , it is not for out2 This is because X_2 (the first argument ) is in Long format, so the second argument is also expected to be long.. To solve the issue, we need to convert X_2 to double format.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5PDp5SZ0tbN",
        "colab_type": "code",
        "outputId": "dcf0f174-7a8a-4bcc-cd56-f91f1f014d10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## Scaling data set and applying the logistic regression\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "'''\n",
        "X=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]] #removing result attribute as it is class label, hence we get 34 attributes\n",
        "X=X.iloc[:,1:len(X.columns)].values   #removing the unnamed attribute\n",
        "x=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]]\n",
        "x=x.iloc[:,1:len(x.columns)].values \n",
        "y=df_main.loc[:, ['result']].values\n",
        "'''\n",
        "\n",
        "# X_1, y_1 means rpesent tweets' data\n",
        "X_1=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]] #removing result attribute as it is class label, hence we get 34 attributes\n",
        "X_1=X_1.iloc[:,1:len(X_1.columns)].values   #removing the unnamed attribute\n",
        "x_1=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]]\n",
        "x_1=x_1.iloc[:,1:len(x_1.columns)].values \n",
        "y_1=df_main.loc[:, ['result']].values\n",
        "\n",
        "\n",
        "\n",
        "data1=X_1\n",
        "\n",
        "scaler = StandardScaler()\n",
        "print(scaler.fit(data1))\n",
        "print(scaler.transform(data1))\n",
        "\n",
        "new_data1=scaler.transform(data1)\n",
        "\n",
        "X_1=torch.from_numpy(new_data1)\n",
        "T_1= torch.from_numpy(y_1)\n",
        "\n",
        "#random weights\n",
        "W = Variable(torch.randn(1, 34, dtype=torch.double), requires_grad=True)\n",
        "b = Variable(torch.randn(1, 1, dtype=torch.double), requires_grad=True)\n",
        "\n",
        "\n",
        "import torch as pytorch\n",
        "X_2=df_main2[df_main2.columns[~df_main2.columns.isin(['time', 'tweet_id','result'])]] #removing result attribute as it is class label, hence we get 34 attributes\n",
        "X_2=X_2.iloc[:,1:len(X_2.columns)].values   #removing the unnamed attribute\n",
        "x_2=df_main2[df_main2.columns[~df_main2.columns.isin(['time', 'tweet_id','result'])]]\n",
        "x_2=x_2.iloc[:,1:len(x_2.columns)].values \n",
        "y_2=df_main2.loc[:, ['result']].values\n",
        "\n",
        "\n",
        "data2=X_2\n",
        "\n",
        "scaler = StandardScaler()\n",
        "print(scaler.fit(data2))\n",
        "print(scaler.transform(data2))\n",
        "new_data2=scaler.transform(data2)\n",
        "\n",
        "X_2=torch.from_numpy(new_data2)\n",
        "T_2= torch.from_numpy(y_2)\n",
        "\n",
        "#do rescaling again\n",
        "\n",
        "d3=data2\n",
        "scaler2=StandardScaler()\n",
        "print(scaler.fit(d3))\n",
        "print(scaler.transform(d3))\n",
        "\n",
        "new_data3=scaler.transform(d3)\n",
        "\n",
        "X_2=torch.from_numpy(new_data3)\n",
        "T_2= torch.from_numpy(y_2)\n",
        "\n",
        "\n",
        "#normalizing the data\n",
        "\n",
        "\n",
        "\n",
        "pytorch.set_default_tensor_type('torch.DoubleTensor')\n",
        "#random weights\n",
        "X_2=X_2.type(torch.DoubleTensor)\n",
        "T_2=T_2.type(torch.DoubleTensor)\n",
        "\n",
        "print(torch.Tensor(X_2).dtype)\n",
        "print(torch.Tensor(X_1).dtype)\n",
        "print(\"\\n dtype of T_2 \\n\", torch.Tensor(T_2).dtype)\n",
        "\n",
        "\n",
        "W_p = Variable(torch.randn(1, 34, dtype=torch.double), requires_grad=True)\n",
        "#W_p=W_p.type(torch.LongTensor)\n",
        "b_p = Variable(torch.randn(1, 1, dtype=torch.double), requires_grad=True)\n",
        "print(W_p.size(), torch.Tensor(W_p).dtype)\n",
        "print(W.size(), torch.Tensor(W_p).dtype)\n",
        "\n",
        "\n",
        "#sigmoid\n",
        "def sigmoid(x):\n",
        "    return 1/(1+torch.exp(-x))\n",
        "\n",
        "# Loss (cross entropy) error function\n",
        "def error(output, target):\n",
        "    return -target * torch.log(output) - (1-target) * torch.log(1-output)\n",
        "  \n",
        "out = sigmoid(torch.mm(X_1, W.view(34,1))+b)\n",
        "#we also could use: torch.nn.Sigmoid()\n",
        "#out = torch.nn.Sigmoid()(torch.mm(X, W.view(2,1))+b)\n",
        "#err = error(out,T)\n",
        "#loss = torch.mean(err)  \n",
        "\n",
        "#print(err)\n",
        "#print(torch.mean(err))\n",
        "out_prev= sigmoid(torch.mm(X_2, W_p.view(34,1))+b_p)\n",
        "print(W.size())\n",
        "\n",
        "\n",
        "\n",
        "#we also could use: torch.nn.Sigmoid()\n",
        "#out = torch.nn.Sigmoid()(torch.mm(X, W.view(2,1))+b)\n",
        "\n",
        "#print(out.shape, T.shape)\n",
        "\n",
        "print(out_present.shape, T_1.shape)\n",
        "\n",
        "print(out_prev.shape, T_2.shape)\n",
        "\n",
        "\n",
        "#err = error(out,T)\n",
        "err_1 = error(out,T_1)\n",
        "err_2 = error(out_prev,T_2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#loss = torch.mean(err)\n",
        "loss = torch.sum(torch.mean(err_1)+torch.mean(err_2))\n",
        "\n",
        "print(err_1,\"\\n \\n\" , err_2)\n",
        "\n",
        "print(\"\\n mean of errors \\n\")\n",
        "print(torch.mean(err_1), \"\\n \\n\", torch.mean(err_2))\n",
        "\n",
        "print(\"\\n sum of errors \\n\")\n",
        "print(torch.sum(err_1), \"\\n \\n\", torch.sum(err_2))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
            "[[-0.13476792 -0.19493167 -0.19200937 ...  0.         -0.36993901\n",
            "  -0.33372183]\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.         -1.60479674\n",
            "  -0.33372183]\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.          0.86491871\n",
            "  -0.33372183]\n",
            " ...\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.          0.86491871\n",
            "   2.99650757]\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.         -1.60479674\n",
            "  -0.33372183]\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.          0.86491871\n",
            "  -0.33372183]]\n",
            "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
            "[[-0.11763217 -0.21155006 -0.18703747 ...  0.         -0.33180166\n",
            "   1.66123437]\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.         -0.33180166\n",
            "  -0.60196202]\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]\n",
            " ...\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.         -1.76388815\n",
            "   1.66123437]\n",
            " [-0.11763217  7.83270806 -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]\n",
            " [-0.11763217  3.810579   -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]]\n",
            "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
            "[[-0.11763217 -0.21155006 -0.18703747 ...  0.         -0.33180166\n",
            "   1.66123437]\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.         -0.33180166\n",
            "  -0.60196202]\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]\n",
            " ...\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.         -1.76388815\n",
            "   1.66123437]\n",
            " [-0.11763217  7.83270806 -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]\n",
            " [-0.11763217  3.810579   -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]]\n",
            "torch.float64\n",
            "torch.float64\n",
            "\n",
            " dtype of T_2 \n",
            " torch.float64\n",
            "torch.Size([1, 34]) torch.float64\n",
            "torch.Size([1, 34]) torch.float64\n",
            "torch.Size([1, 34])\n",
            "torch.Size([1906, 1]) torch.Size([1906, 1])\n",
            "torch.Size([3004, 1]) torch.Size([3004, 1])\n",
            "tensor([[5.5217e+00],\n",
            "        [5.3616e-06],\n",
            "        [8.1066e-05],\n",
            "        ...,\n",
            "        [1.7598e-01],\n",
            "        [7.1447e+00],\n",
            "        [2.3921e+00]], grad_fn=<SubBackward0>) \n",
            " \n",
            " tensor([[3.7355e+00],\n",
            "        [3.5029e-01],\n",
            "        [3.9970e+00],\n",
            "        ...,\n",
            "        [5.1022e-04],\n",
            "        [7.2785e-03],\n",
            "        [7.3004e-01]], grad_fn=<SubBackward0>)\n",
            "\n",
            " mean of errors \n",
            "\n",
            "tensor(1.8355, grad_fn=<MeanBackward0>) \n",
            " \n",
            " tensor(1.9108, grad_fn=<MeanBackward0>)\n",
            "\n",
            " sum of errors \n",
            "\n",
            "tensor(3498.4966, grad_fn=<SumBackward0>) \n",
            " \n",
            " tensor(5740.0011, grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xN162bo6PPXO",
        "colab_type": "text"
      },
      "source": [
        "We are getting NaN for previous tweets sum !!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD2euRoD03Gy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random \n",
        "from random import randint\n",
        "\n",
        "\n",
        "test_X=[]\n",
        "test_y=[]\n",
        "\n",
        "temp=random.sample(range(1,len(X)), 10)\n",
        "print(temp)\n",
        "\n",
        "for i in temp:\n",
        "  test_X.append(X[i])\n",
        "  test_y.append(y[i])\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "print(type(test_X), type(test_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eAlkp0UvLHH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ba788419-e047-4189-958b-9b2a6e1b1f11"
      },
      "source": [
        "x=[1,3,4]\n",
        "y=[1,7,8,5,6,3,4]\n",
        "z=[3,5,6,8,4,9.1]\n",
        "\n",
        "for i, j,k in zip(y,z,x):\n",
        "  print(i,j,k)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 3 1\n",
            "7 5 3\n",
            "8 6 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF14K01Y077q",
        "colab_type": "code",
        "outputId": "c7ecf6ef-d495-41b6-bff1-58d32d161ded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_1.numpy(), T_1.numpy(), test_size=0.33, random_state=42)\n",
        "\n",
        "X_1=torch.from_numpy(X_train1)\n",
        "T_1=torch.from_numpy(y_train1)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_2.numpy(), T_2.numpy(), test_size=0.33, random_state=53)\n",
        "\n",
        "X_2=torch.from_numpy(X_train2)\n",
        "T_2=torch.from_numpy(y_train2)\n",
        "#test_X=torch.from_numpy(X_test)\n",
        "#test_y=torch.from_numpy(y_test)\n",
        "test_X1=[]\n",
        "test_y1=[]\n",
        "test_X2=[]\n",
        "test_y2=[]\n",
        "for i in X_test1:\n",
        "  test_X1.append(i)\n",
        "  \n",
        "for i in y_test1:\n",
        "  test_y1.append(i)\n",
        "  \n",
        "  \n",
        "  \n",
        "for i in X_test2:\n",
        "  test_X2.append(i)\n",
        "  \n",
        "for i in y_test2:\n",
        "  test_y2.append(i)\n",
        "  \n",
        "  \n",
        "print(type(test_X1), type(test_y1), type(test_X2), type(test_y2))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'> <class 'list'> <class 'list'> <class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVU1m3aE0-SD",
        "colab_type": "code",
        "outputId": "03de6dcc-b118-4e48-ecc1-1d634648c30b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "import math \n",
        "\n",
        "epochs=1500\n",
        "alpha=0.001\n",
        "n_iter=1\n",
        "\n",
        "torch.set_default_tensor_type('torch.DoubleTensor')\n",
        "for i in range(epochs):\n",
        "    #alternative0 (explicit definition)\n",
        "    out = sigmoid(torch.mm(X_1, W.view(34,1))+b)\n",
        "    out_prev=sigmoid(torch.mm(X_2,W_p.view(34,1))+b_p)\n",
        "    #we also could use: torch.nn.Sigmoid()\n",
        "    #out = torch.nn.Sigmoid()(torch.mm(X, W.view(2,1))+b)\n",
        "    err_1 = error(out,T_1)\n",
        "    err_2= error(out_prev, T_2)\n",
        "    loss = torch.sum(torch.mean(err_1)+toch.mean(err_2)\n",
        "\n",
        "    #alternative1 (pytorch defined loss function)\n",
        "    #out = torch.mm(X, W.view(2,1))+b\n",
        "    #loss = criterion(out, T.double())     \n",
        "\n",
        "    #alternative2 (custom error function)\n",
        "    #cross_entropy = CE.apply\n",
        "    #out = sigmoid(torch.mm(X, W.view(2,1))+b)\n",
        "    #err = cross_entropy(out,T)\n",
        "    #loss = torch.mean(err)    \n",
        "    \n",
        "    #compute gradients\n",
        "    loss.backward()\n",
        "\n",
        "    last_w = W.data.numpy()[0].copy()\n",
        "    last_b = b.data.numpy()[0].copy()\n",
        "    last_w2 = W_p.data.numpy()[0].copy()\n",
        "    last_b2 = b_p.data.numpy()[0].copy()                 \n",
        "       \n",
        "    with torch.no_grad():\n",
        "        W -= alpha * W.grad\n",
        "        b -= alpha * b.grad\n",
        "        W_p -= alpha * W_p.grad\n",
        "        b_p -= alpha * b_p.grad             \n",
        "        \n",
        "\n",
        "        # Manually zero the gradients after updating weights\n",
        "        W.grad.zero_()\n",
        "        b.grad.zero_()\n",
        "                     \n",
        "        W_p.grad.zero_()\n",
        "        b_p.grad.zero_()             \n",
        "        #print(loss)\n",
        "    \n",
        "    n_iter+=1\n",
        "    if n_iter%100==0:\n",
        "      correct = 0\n",
        "      total = 0\n",
        "            \n",
        "      # Iterate through train dataset\n",
        "      for X_v1, y_v1, X_v2,y_v2 in zip(X_train1,y_train1,X_train2,y_train2):\n",
        "        #print(\"Hi\")\n",
        "        # Load images to a Torch Variable\n",
        "        #images = Variable(images.view(-1, 28*28))\n",
        "        # Forward pass only to get logits/output\n",
        "        #outputs = sigmoid(X_val)\n",
        "        X_v1=torch.Tensor(X_v1)\n",
        "        X_temp1=(X_v1.view(1,34))\n",
        "        W_temp1=(W.view(34,1))\n",
        "                     \n",
        "        X_v2=torch.Tensor(X_v2)\n",
        "        X_temp2=(X_v2.view(1,34))\n",
        "        W_temp2=(W_p.view(34,1))\n",
        "        #print(X_val)\n",
        "        outputs=sigmoid(torch.mm(X_temp,W_temp)+b)\n",
        "        \n",
        "        outputs2=sigmoid(torch.mm(X_temp2,W_temp2)+b_p)\n",
        "        #print(outputs)\n",
        "        # Get predictions from the maximum value\n",
        "        #_, predicted = torch.max(outputs.data, 1)\n",
        "        # prediction part              \n",
        "        pred_val1=(outputs.detach().numpy())\n",
        "                     \n",
        "        pred_val2=(outputs2.detach().numpy())\n",
        "                     \n",
        "                     \n",
        "        pred_val= (2*pred_val1*pred_val2)/ (pred_val1 + pred_val2)   #using harmonic mean\n",
        "                     \n",
        "        #pred_val= (pred_val1 + pred_val2 ) /2      #using Arithmetic mean\n",
        "                     \n",
        "                     \n",
        "                     \n",
        "                     \n",
        "        #print(type(pred_val), pred_val) \n",
        "        # for accessing scalar value from tensor, by converting it to numpy array\n",
        "        for i in pred_val:\n",
        "          for j in i:\n",
        "            #print(type(j))\n",
        "            temp=j\n",
        "            \n",
        "        predicted=round(temp)\n",
        "        # Total number of labels\n",
        "        #total += y_val.size(0)\n",
        "        total+=1\n",
        "        # Total correct predictions\n",
        "        correct += (predicted == y_v).sum()\n",
        "        \n",
        "      accuracy = 100 * correct / total\n",
        "      print(\"\\n In epoch \", n_iter, \" Training accuracy= \", accuracy)\n",
        "      \n",
        "      \n",
        "      # Iterate through test dataset\n",
        "      for X_v1, y_v1, X_v2,y_v2 in zip(X_test1,y_test1,X_test2,y_test2):\n",
        "        #print(\"Hi\")\n",
        "        # Load images to a Torch Variable\n",
        "        #images = Variable(images.view(-1, 28*28))\n",
        "        # Forward pass only to get logits/output\n",
        "        #outputs = sigmoid(X_val)\n",
        "        X_v1=torch.Tensor(X_v1)\n",
        "        X_temp1=(X_v1.view(1,34))\n",
        "        W_temp1=(W.view(34,1))\n",
        "                     \n",
        "        X_v2=torch.Tensor(X_v2)\n",
        "        X_temp2=(X_v2.view(1,34))\n",
        "        W_temp2=(W_p.view(34,1))\n",
        "        #print(X_val)\n",
        "        outputs=sigmoid(torch.mm(X_temp,W_temp)+b)\n",
        "        \n",
        "        outputs2=sigmoid(torch.mm(X_temp2,W_temp2)+b_p)\n",
        "        #print(outputs)\n",
        "        # Get predictions from the maximum value\n",
        "        #_, predicted = torch.max(outputs.data, 1)\n",
        "        # prediction part              \n",
        "        pred_val1=(outputs.detach().numpy())\n",
        "                     \n",
        "        pred_val2=(outputs2.detach().numpy())\n",
        "                     \n",
        "                     \n",
        "        pred_val= (2*pred_val1*pred_val2)/ (pred_val1 + pred_val2)   #using harmonic mean\n",
        "                     \n",
        "        #pred_val= (pred_val1 + pred_val2 ) /2      #using Arithmetic mean\n",
        "                     \n",
        "                     \n",
        "                     \n",
        "                     \n",
        "        #print(type(pred_val), pred_val) \n",
        "        # for accessing scalar value from tensor, by converting it to numpy array\n",
        "        for i in pred_val:\n",
        "          for j in i:\n",
        "            #print(type(j))\n",
        "            temp=j\n",
        "            \n",
        "        predicted=round(temp)\n",
        "        # Total number of labels\n",
        "        #total += y_val.size(0)\n",
        "        total+=1\n",
        "        # Total correct predictions\n",
        "        correct += (predicted == y_v).sum()\n",
        "                     \n",
        "      accuracy = 100 * correct / total\n",
        "      print(\"\\n In epoch \", n_iter, \" Testing accuracy= \", accuracy)\n",
        "      "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-37ed390755e9>\"\u001b[0;36m, line \u001b[0;32m29\u001b[0m\n\u001b[0;31m    loss.backward()\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9fBFG5WtZQv",
        "colab_type": "code",
        "outputId": "ae23a90a-36e4-4d50-a467-2aafe4faa815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "########With different loss functions, independent training####\n",
        "\n",
        "\n",
        "## Scaling data set and applying the logistic regression\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "'''\n",
        "X=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]] #removing result attribute as it is class label, hence we get 34 attributes\n",
        "X=X.iloc[:,1:len(X.columns)].values   #removing the unnamed attribute\n",
        "x=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]]\n",
        "x=x.iloc[:,1:len(x.columns)].values \n",
        "y=df_main.loc[:, ['result']].values\n",
        "'''\n",
        "\n",
        "# X_1, y_1 means rpesent tweets' data\n",
        "X_1=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]] #removing result attribute as it is class label, hence we get 34 attributes\n",
        "X_1=X_1.iloc[:,1:len(X_1.columns)].values   #removing the unnamed attribute\n",
        "x_1=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]]\n",
        "x_1=x_1.iloc[:,1:len(x_1.columns)].values \n",
        "y_1=df_main.loc[:, ['result']].values\n",
        "\n",
        "\n",
        "\n",
        "data1=X_1\n",
        "\n",
        "scaler = StandardScaler()\n",
        "print(scaler.fit(data1))\n",
        "print(scaler.transform(data1))\n",
        "\n",
        "new_data1=scaler.transform(data1)\n",
        "\n",
        "X_1=torch.from_numpy(new_data1)\n",
        "T_1= torch.from_numpy(y_1)\n",
        "\n",
        "#random weights\n",
        "W = Variable(torch.randn(1, 34, dtype=torch.double), requires_grad=True)\n",
        "b = Variable(torch.randn(1, 1, dtype=torch.double), requires_grad=True)\n",
        "\n",
        "\n",
        "import torch as pytorch\n",
        "X_2=df_main2[df_main2.columns[~df_main2.columns.isin(['time', 'tweet_id','result'])]] #removing result attribute as it is class label, hence we get 34 attributes\n",
        "X_2=X_2.iloc[:,1:len(X_2.columns)].values   #removing the unnamed attribute\n",
        "x_2=df_main2[df_main2.columns[~df_main2.columns.isin(['time', 'tweet_id','result'])]]\n",
        "x_2=x_2.iloc[:,1:len(x_2.columns)].values \n",
        "y_2=df_main2.loc[:, ['result']].values\n",
        "\n",
        "\n",
        "data2=X_2\n",
        "\n",
        "scaler = StandardScaler()\n",
        "print(scaler.fit(data2))\n",
        "print(scaler.transform(data2))\n",
        "new_data2=scaler.transform(data2)\n",
        "\n",
        "X_2=torch.from_numpy(new_data2)\n",
        "T_2= torch.from_numpy(y_2)\n",
        "\n",
        "#do rescaling again\n",
        "\n",
        "d3=data2\n",
        "scaler2=StandardScaler()\n",
        "print(scaler.fit(d3))\n",
        "print(scaler.transform(d3))\n",
        "\n",
        "new_data3=scaler.transform(d3)\n",
        "\n",
        "X_2=torch.from_numpy(new_data3)\n",
        "T_2= torch.from_numpy(y_2)\n",
        "\n",
        "\n",
        "#normalizing the data\n",
        "\n",
        "\n",
        "\n",
        "pytorch.set_default_tensor_type('torch.DoubleTensor')\n",
        "#random weights\n",
        "X_2=X_2.type(torch.DoubleTensor)\n",
        "T_2=T_2.type(torch.DoubleTensor)\n",
        "\n",
        "print(torch.Tensor(X_2).dtype)\n",
        "print(torch.Tensor(X_1).dtype)\n",
        "print(\"\\n dtype of T_2 \\n\", torch.Tensor(T_2).dtype)\n",
        "\n",
        "\n",
        "W_p = Variable(torch.randn(1, 34, dtype=torch.double), requires_grad=True)\n",
        "#W_p=W_p.type(torch.LongTensor)\n",
        "b_p = Variable(torch.randn(1, 1, dtype=torch.double), requires_grad=True)\n",
        "print(W_p.size(), torch.Tensor(W_p).dtype)\n",
        "print(W.size(), torch.Tensor(W_p).dtype)\n",
        "\n",
        "\n",
        "#sigmoid\n",
        "def sigmoid(x):\n",
        "    return 1/(1+torch.exp(-x))\n",
        "\n",
        "# Loss (cross entropy) error function\n",
        "def error(output, target):\n",
        "    return -target * torch.log(output) - (1-target) * torch.log(1-output)\n",
        "  \n",
        "out = sigmoid(torch.mm(X_1, W.view(34,1))+b)\n",
        "#we also could use: torch.nn.Sigmoid()\n",
        "#out = torch.nn.Sigmoid()(torch.mm(X, W.view(2,1))+b)\n",
        "#err = error(out,T)\n",
        "#loss = torch.mean(err)  \n",
        "\n",
        "#print(err)\n",
        "#print(torch.mean(err))\n",
        "out_prev= sigmoid(torch.mm(X_2, W_p.view(34,1))+b_p)\n",
        "print(W.size())\n",
        "\n",
        "\n",
        "\n",
        "#we also could use: torch.nn.Sigmoid()\n",
        "#out = torch.nn.Sigmoid()(torch.mm(X, W.view(2,1))+b)\n",
        "\n",
        "#print(out.shape, T.shape)\n",
        "\n",
        "print(out_present.shape, T_1.shape)\n",
        "\n",
        "print(out_prev.shape, T_2.shape)\n",
        "\n",
        "\n",
        "#err = error(out,T)\n",
        "err_1 = error(out,T_1)\n",
        "err_2 = error(out_prev,T_2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#loss = torch.mean(err)\n",
        "loss1 = torch.mean(err_1)\n",
        "loss2 = torch.mean(err_2)\n",
        "\n",
        "print(err_1,\"\\n \\n\" , err_2)\n",
        "\n",
        "print(\"\\n mean of errors \\n\")\n",
        "print(torch.mean(err_1), \"\\n \\n\", torch.mean(err_2))\n",
        "\n",
        "print(\"\\n sum of errors \\n\")\n",
        "print(torch.sum(err_1), \"\\n \\n\", torch.sum(err_2))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
            "[[-0.13476792 -0.19493167 -0.19200937 ...  0.         -0.36993901\n",
            "  -0.33372183]\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.         -1.60479674\n",
            "  -0.33372183]\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.          0.86491871\n",
            "  -0.33372183]\n",
            " ...\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.          0.86491871\n",
            "   2.99650757]\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.         -1.60479674\n",
            "  -0.33372183]\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.          0.86491871\n",
            "  -0.33372183]]\n",
            "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
            "[[-0.11763217 -0.21155006 -0.18703747 ...  0.         -0.33180166\n",
            "   1.66123437]\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.         -0.33180166\n",
            "  -0.60196202]\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]\n",
            " ...\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.         -1.76388815\n",
            "   1.66123437]\n",
            " [-0.11763217  7.83270806 -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]\n",
            " [-0.11763217  3.810579   -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]]\n",
            "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
            "[[-0.11763217 -0.21155006 -0.18703747 ...  0.         -0.33180166\n",
            "   1.66123437]\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.         -0.33180166\n",
            "  -0.60196202]\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]\n",
            " ...\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.         -1.76388815\n",
            "   1.66123437]\n",
            " [-0.11763217  7.83270806 -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]\n",
            " [-0.11763217  3.810579   -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]]\n",
            "torch.float64\n",
            "torch.float64\n",
            "\n",
            " dtype of T_2 \n",
            " torch.float64\n",
            "torch.Size([1, 34]) torch.float64\n",
            "torch.Size([1, 34]) torch.float64\n",
            "torch.Size([1, 34])\n",
            "torch.Size([1906, 1]) torch.Size([1906, 1])\n",
            "torch.Size([3004, 1]) torch.Size([3004, 1])\n",
            "tensor([[2.5973e+00],\n",
            "        [1.5600e-05],\n",
            "        [2.1457e+00],\n",
            "        ...,\n",
            "        [1.6521e+00],\n",
            "        [5.7829e+00],\n",
            "        [2.2144e-02]], grad_fn=<SubBackward0>) \n",
            " \n",
            " tensor([[1.5732e-01],\n",
            "        [4.0556e-01],\n",
            "        [2.3132e+00],\n",
            "        ...,\n",
            "        [7.1825e+00],\n",
            "        [9.8764e-06],\n",
            "        [4.8997e+00]], grad_fn=<SubBackward0>)\n",
            "\n",
            " mean of errors \n",
            "\n",
            "tensor(1.8060, grad_fn=<MeanBackward0>) \n",
            " \n",
            " tensor(1.8675, grad_fn=<MeanBackward0>)\n",
            "\n",
            " sum of errors \n",
            "\n",
            "tensor(3442.2341, grad_fn=<SumBackward0>) \n",
            " \n",
            " tensor(5610.1012, grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzDK4Gt8ttqo",
        "colab_type": "code",
        "outputId": "32b61ebe-df05-4b6b-a8ce-fceb4a14980a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_1.numpy(), T_1.numpy(), test_size=0.33, random_state=42)\n",
        "\n",
        "X_1=torch.from_numpy(X_train1)\n",
        "T_1=torch.from_numpy(y_train1)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_2.numpy(), T_2.numpy(), test_size=0.33, random_state=53)\n",
        "\n",
        "X_2=torch.from_numpy(X_train2)\n",
        "T_2=torch.from_numpy(y_train2)\n",
        "#test_X=torch.from_numpy(X_test)\n",
        "#test_y=torch.from_numpy(y_test)\n",
        "test_X1=[]\n",
        "test_y1=[]\n",
        "test_X2=[]\n",
        "test_y2=[]\n",
        "for i in X_test1:\n",
        "  test_X1.append(i)\n",
        "  \n",
        "for i in y_test1:\n",
        "  test_y1.append(i)\n",
        "  \n",
        "  \n",
        "  \n",
        "for i in X_test2:\n",
        "  test_X2.append(i)\n",
        "  \n",
        "for i in y_test2:\n",
        "  test_y2.append(i)\n",
        "  \n",
        "  \n",
        "print(type(test_X1), type(test_y1), type(test_X2), type(test_y2))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'> <class 'list'> <class 'list'> <class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7F2CQ0at70E",
        "colab_type": "code",
        "outputId": "7d458f80-a2be-4b91-b17c-b5209613fb18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import math \n",
        "\n",
        "epochs=1500\n",
        "alpha=0.001\n",
        "n_iter=1\n",
        "\n",
        "torch.set_default_tensor_type('torch.DoubleTensor')\n",
        "for i in range(epochs):\n",
        "    #alternative0 (explicit definition)\n",
        "    out = sigmoid(torch.mm(X_1, W.view(34,1))+b)\n",
        "    out_prev=sigmoid(torch.mm(X_2,W_p.view(34,1))+b_p)\n",
        "    #we also could use: torch.nn.Sigmoid()\n",
        "    #out = torch.nn.Sigmoid()(torch.mm(X, W.view(2,1))+b)\n",
        "    err_1 = error(out,T_1)\n",
        "    err_2= error(out_prev, T_2)\n",
        "    loss1 = torch.mean(err_1) \n",
        "    loss2 = torch.mean(err_2)\n",
        "\n",
        "    #alternative1 (pytorch defined loss function)\n",
        "    #out = torch.mm(X, W.view(2,1))+b\n",
        "    #loss = criterion(out, T.double())     \n",
        "\n",
        "    #alternative2 (custom error function)\n",
        "    #cross_entropy = CE.apply\n",
        "    #out = sigmoid(torch.mm(X, W.view(2,1))+b)\n",
        "    #err = cross_entropy(out,T)\n",
        "    #loss = torch.mean(err)    \n",
        "    \n",
        "    #compute gradients\n",
        "    loss1.backward()\n",
        "    loss2.backward()\n",
        "\n",
        "    last_w = W.data.numpy()[0].copy()\n",
        "    last_b = b.data.numpy()[0].copy()\n",
        "    last_w2 = W_p.data.numpy()[0].copy()\n",
        "    last_b2 = b_p.data.numpy()[0].copy()                 \n",
        "       \n",
        "    with torch.no_grad():\n",
        "        W -= alpha * W.grad\n",
        "        b -= alpha * b.grad\n",
        "        W_p -= alpha * W_p.grad\n",
        "        b_p -= alpha * b_p.grad             \n",
        "        \n",
        "\n",
        "        # Manually zero the gradients after updating weights\n",
        "        W.grad.zero_()\n",
        "        b.grad.zero_()\n",
        "                     \n",
        "        W_p.grad.zero_()\n",
        "        b_p.grad.zero_()             \n",
        "        #print(loss)\n",
        "    \n",
        "    n_iter+=1\n",
        "    if n_iter%100==0:\n",
        "      correct = 0\n",
        "      total = 0\n",
        "            \n",
        "      # Iterate through train dataset\n",
        "      for X_v1, y_v1, X_v2,y_v2 in zip(X_train1,y_train1,X_train2,y_train2):\n",
        "        #print(\"Hi\")\n",
        "        # Load images to a Torch Variable\n",
        "        #images = Variable(images.view(-1, 28*28))\n",
        "        # Forward pass only to get logits/output\n",
        "        #outputs = sigmoid(X_val)\n",
        "        X_v1=torch.Tensor(X_v1)\n",
        "        X_temp1=(X_v1.view(1,34))\n",
        "        W_temp1=(W.view(34,1))\n",
        "                     \n",
        "        X_v2=torch.Tensor(X_v2)\n",
        "        X_temp2=(X_v2.view(1,34))\n",
        "        W_temp2=(W_p.view(34,1))\n",
        "        #print(X_val)\n",
        "        outputs=sigmoid(torch.mm(X_temp1,W_temp1)+b)\n",
        "        \n",
        "        outputs2=sigmoid(torch.mm(X_temp2,W_temp2)+b_p)\n",
        "        #print(outputs)\n",
        "        # Get predictions from the maximum value\n",
        "        #_, predicted = torch.max(outputs.data, 1)\n",
        "        # prediction part              \n",
        "        pred_val1=(outputs.detach().numpy())\n",
        "                     \n",
        "        pred_val2=(outputs2.detach().numpy())\n",
        "                     \n",
        "                     \n",
        "        pred_val= (2*pred_val1*pred_val2)/ (pred_val1 + pred_val2)   #using harmonic mean\n",
        "                     \n",
        "        #pred_val= (pred_val1 + pred_val2 ) /2      #using Arithmetic mean\n",
        "                     \n",
        "                     \n",
        "                     \n",
        "                     \n",
        "        #print(type(pred_val), pred_val) \n",
        "        # for accessing scalar value from tensor, by converting it to numpy array\n",
        "        for i in pred_val:\n",
        "          for j in i:\n",
        "            #print(type(j))\n",
        "            temp=j\n",
        "            \n",
        "        predicted=round(temp)\n",
        "        # Total number of labels\n",
        "        #total += y_val.size(0)\n",
        "        total+=1\n",
        "        # Total correct predictions\n",
        "        correct += (predicted == y_v1).sum()\n",
        "        \n",
        "      accuracy = 100 * correct / total\n",
        "      print(\"\\n In epoch \", n_iter, \" Training accuracy= \", accuracy)\n",
        "      \n",
        "      \n",
        "      # Iterate through test dataset\n",
        "      for X_v1, y_v1, X_v2,y_v2 in zip(X_test1,y_test1,X_test2,y_test2):\n",
        "        #print(\"Hi\")\n",
        "        # Load images to a Torch Variable\n",
        "        #images = Variable(images.view(-1, 28*28))\n",
        "        # Forward pass only to get logits/output\n",
        "        #outputs = sigmoid(X_val)\n",
        "        X_v1=torch.Tensor(X_v1)\n",
        "        X_temp1=(X_v1.view(1,34))\n",
        "        W_temp1=(W.view(34,1))\n",
        "                     \n",
        "        X_v2=torch.Tensor(X_v2)\n",
        "        X_temp2=(X_v2.view(1,34))\n",
        "        W_temp2=(W_p.view(34,1))\n",
        "        #print(X_val)\n",
        "        outputs=sigmoid(torch.mm(X_temp1,W_temp1)+b)\n",
        "        \n",
        "        outputs2=sigmoid(torch.mm(X_temp2,W_temp2)+b_p)\n",
        "        #print(outputs)\n",
        "        # Get predictions from the maximum value\n",
        "        #_, predicted = torch.max(outputs.data, 1)\n",
        "        # prediction part              \n",
        "        pred_val1=(outputs.detach().numpy())\n",
        "                     \n",
        "        pred_val2=(outputs2.detach().numpy())\n",
        "                     \n",
        "                     \n",
        "        pred_val= (2*pred_val1*pred_val2)/ (pred_val1 + pred_val2)   #using harmonic mean\n",
        "                     \n",
        "        #pred_val= (pred_val1 + pred_val2 ) /2      #using Arithmetic mean\n",
        "                     \n",
        "                     \n",
        "                     \n",
        "                     \n",
        "        #print(type(pred_val), pred_val) \n",
        "        # for accessing scalar value from tensor, by converting it to numpy array\n",
        "        for i in pred_val:\n",
        "          for j in i:\n",
        "            #print(type(j))\n",
        "            temp=j\n",
        "            \n",
        "        predicted=round(temp)\n",
        "        # Total number of labels\n",
        "        #total += y_val.size(0)\n",
        "        total+=1\n",
        "        # Total correct predictions\n",
        "        correct += (predicted == y_v1).sum()\n",
        "                     \n",
        "      accuracy = 100 * correct / total\n",
        "      print(\"\\n In epoch \", n_iter, \" Testing accuracy= \", accuracy)\n",
        "      "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " In epoch  100  Training accuracy=  56.85199686765858\n",
            "\n",
            " In epoch  100  Testing accuracy=  57.34522560335782\n",
            "\n",
            " In epoch  200  Training accuracy=  57.321848081440876\n",
            "\n",
            " In epoch  200  Testing accuracy=  57.607555089192026\n",
            "\n",
            " In epoch  300  Training accuracy=  57.478465152701645\n",
            "\n",
            " In epoch  300  Testing accuracy=  57.555089192025186\n",
            "\n",
            " In epoch  400  Training accuracy=  57.321848081440876\n",
            "\n",
            " In epoch  400  Testing accuracy=  57.39769150052466\n",
            "\n",
            " In epoch  500  Training accuracy=  57.478465152701645\n",
            "\n",
            " In epoch  500  Testing accuracy=  57.660020986358866\n",
            "\n",
            " In epoch  600  Training accuracy=  57.321848081440876\n",
            "\n",
            " In epoch  600  Testing accuracy=  57.555089192025186\n",
            "\n",
            " In epoch  700  Training accuracy=  57.16523101018011\n",
            "\n",
            " In epoch  700  Testing accuracy=  57.555089192025186\n",
            "\n",
            " In epoch  800  Training accuracy=  57.24353954581049\n",
            "\n",
            " In epoch  800  Testing accuracy=  57.502623294858346\n",
            "\n",
            " In epoch  900  Training accuracy=  57.24353954581049\n",
            "\n",
            " In epoch  900  Testing accuracy=  57.29275970619098\n",
            "\n",
            " In epoch  1000  Training accuracy=  57.08692247454972\n",
            "\n",
            " In epoch  1000  Testing accuracy=  57.18782791185729\n",
            "\n",
            " In epoch  1100  Training accuracy=  56.617071260767425\n",
            "\n",
            " In epoch  1100  Testing accuracy=  56.87303252885624\n",
            "\n",
            " In epoch  1200  Training accuracy=  56.85199686765858\n",
            "\n",
            " In epoch  1200  Testing accuracy=  56.92549842602308\n",
            "\n",
            " In epoch  1300  Training accuracy=  56.77368833202819\n",
            "\n",
            " In epoch  1300  Testing accuracy=  56.76810073452256\n",
            "\n",
            " In epoch  1400  Training accuracy=  56.617071260767425\n",
            "\n",
            " In epoch  1400  Testing accuracy=  56.505771248688355\n",
            "\n",
            " In epoch  1500  Training accuracy=  56.14722004698512\n",
            "\n",
            " In epoch  1500  Testing accuracy=  56.29590766002099\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}