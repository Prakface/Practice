{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Appending _previous_with_new_weights.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prakface/Practice/blob/master/Appending__previous_with_new_weights.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeeEVGmX0Yol",
        "colab_type": "code",
        "outputId": "a315003b-8167-452d-85be-6eb48852c3ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "url='https://raw.githubusercontent.com/Prakface/Practice/master/One_mon_present_full.csv'\n",
        "\n",
        "url2='https://raw.githubusercontent.com/Prakface/Practice/master/Final_one_month_prev_features.csv'\n",
        "\n",
        "data = pd.read_csv(url) \n",
        "\n",
        "data2= pd.read_csv(url2)\n",
        "\n",
        "print(\"Data Shape:\", data.shape) \n",
        "\n",
        "#data=pd.read_csv(url)\n",
        "\n",
        "df=pd.DataFrame(data)\n",
        "print(data.head()) \n",
        "\n",
        "\n",
        "data_modified= data.dropna()\n",
        "\n",
        "data_modified.to_csv(\"modifiedData.csv\", index=False)\n",
        "\n",
        "\n",
        "df2=pd.read_csv(\"modifiedData.csv\")\n",
        "\n",
        "print(df2[0:6])\n",
        "\n",
        "print(df2['result'])\n",
        "\n",
        "df_main=df2[df2.columns[~df2.columns.isin(['text', 'user_name'])]]\n",
        "\n",
        "print(df_main.columns)\n",
        "\n",
        "print(len(df_main.columns))\n",
        "\n",
        "  \n",
        "# X_1, y_1 means rpesent tweets' data\n",
        "X_1=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]] #removing result attribute as it is class label, hence we get 34 attributes\n",
        "X_1=X_1.iloc[:,1:len(X_1.columns)].values   #removing the unnamed attribute\n",
        "x_1=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]]\n",
        "x_1=x_1.iloc[:,1:len(x_1.columns)].values \n",
        "y_1=df_main.loc[:, ['result']].values\n",
        "\n",
        "\n",
        "print(type(X_1), type(y_1), type(x_1), type(y_1))\n",
        "\n",
        "print(X_1.shape)\n",
        "print(y_1.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Shape: (1908, 40)\n",
            "  Unnamed: 0 cat1  cat10  ...      tweet_id  url      user_name\n",
            "0          0    0      0  ...  8.323790e+17  0.0  THEJEROMEOWEN\n",
            "1          1    0      0  ...  8.323786e+17  0.0       Acejinjo\n",
            "2          2    0      0  ...  8.323780e+17  0.0     RabRakha21\n",
            "3          3    0      0  ...  8.323777e+17  0.0       RS_Aloha\n",
            "4          4    0      0  ...  8.323767e+17  0.0  preciselyizzy\n",
            "\n",
            "[5 rows x 40 columns]\n",
            "   Unnamed: 0  cat1  cat10  ...      tweet_id  url        user_name\n",
            "0           0     0      0  ...  8.323790e+17  0.0    THEJEROMEOWEN\n",
            "1           1     0      0  ...  8.323786e+17  0.0         Acejinjo\n",
            "2           2     0      0  ...  8.323780e+17  0.0       RabRakha21\n",
            "3           3     0      0  ...  8.323777e+17  0.0         RS_Aloha\n",
            "4           4     0      0  ...  8.323767e+17  0.0    preciselyizzy\n",
            "5           5     0      0  ...  8.323759e+17  0.0  thefireistarted\n",
            "\n",
            "[6 rows x 40 columns]\n",
            "0       1.0\n",
            "1       1.0\n",
            "2       1.0\n",
            "3       1.0\n",
            "4       1.0\n",
            "5       1.0\n",
            "6       1.0\n",
            "7       1.0\n",
            "8       1.0\n",
            "9       1.0\n",
            "10      1.0\n",
            "11      1.0\n",
            "12      1.0\n",
            "13      1.0\n",
            "14      1.0\n",
            "15      1.0\n",
            "16      1.0\n",
            "17      1.0\n",
            "18      1.0\n",
            "19      1.0\n",
            "20      1.0\n",
            "21      1.0\n",
            "22      1.0\n",
            "23      1.0\n",
            "24      1.0\n",
            "25      1.0\n",
            "26      1.0\n",
            "27      1.0\n",
            "28      1.0\n",
            "29      1.0\n",
            "       ... \n",
            "1876    0.0\n",
            "1877    0.0\n",
            "1878    0.0\n",
            "1879    0.0\n",
            "1880    0.0\n",
            "1881    0.0\n",
            "1882    0.0\n",
            "1883    0.0\n",
            "1884    0.0\n",
            "1885    0.0\n",
            "1886    0.0\n",
            "1887    0.0\n",
            "1888    0.0\n",
            "1889    0.0\n",
            "1890    0.0\n",
            "1891    0.0\n",
            "1892    0.0\n",
            "1893    0.0\n",
            "1894    0.0\n",
            "1895    0.0\n",
            "1896    0.0\n",
            "1897    0.0\n",
            "1898    0.0\n",
            "1899    0.0\n",
            "1900    0.0\n",
            "1901    0.0\n",
            "1902    0.0\n",
            "1903    0.0\n",
            "1904    0.0\n",
            "1905    0.0\n",
            "Name: result, Length: 1906, dtype: float64\n",
            "Index(['Unnamed: 0', 'cat1', 'cat10', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6',\n",
            "       'cat7', 'cat8', 'cat9', 'favorite_count', 'hour', 'image', 'level',\n",
            "       'nadj', 'nadv', 'nemoji', 'nlevel', 'nword', 'orginal', 'padj', 'padv',\n",
            "       'pemoji', 'plevel', 'pnoun', 'punc1', 'punc2', 'punc3', 'pword',\n",
            "       'question', 'result', 'retweets_count', 'sarcasm', 'sentiment', 'time',\n",
            "       'tweet_id', 'url'],\n",
            "      dtype='object')\n",
            "38\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(1906, 34)\n",
            "(1906, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq0FqtXk0gT9",
        "colab_type": "code",
        "outputId": "c90b7d95-51ec-49aa-824b-60f9c70d2a23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data2= pd.read_csv(url2)\n",
        "\n",
        "print(\"Data Shape:\", data2.shape) \n",
        "\n",
        "#data=pd.read_csv(url)\n",
        "\n",
        "df_prev=pd.DataFrame(data2)\n",
        "print(data2.head()) \n",
        "\n",
        "\n",
        "data2_modified= data2.dropna()\n",
        "\n",
        "data2_modified.to_csv(\"modifiedData2.csv\", index=False)\n",
        "\n",
        "\n",
        "df_2=pd.read_csv(\"modifiedData2.csv\")\n",
        "\n",
        "print(df_2[0:6])\n",
        "\n",
        "print(df_2['result'])\n",
        "\n",
        "df_main2=df_2[df_2.columns[~df_2.columns.isin(['text', 'user_name'])]]\n",
        "\n",
        "print(df_main2.columns)\n",
        "\n",
        "print(len(df_main2.columns))\n",
        "\n",
        "  \n",
        "\n",
        "X_2=df_main2[df_main2.columns[~df_main2.columns.isin(['time', 'tweet_id','result'])]] #removing result attribute as it is class label, hence we get 34 attributes\n",
        "X_2=X_2.iloc[:,1:len(X_2.columns)].values   #removing the unnamed attribute\n",
        "x_2=df_main2[df_main2.columns[~df_main2.columns.isin(['time', 'tweet_id','result'])]]\n",
        "x_2=x_2.iloc[:,1:len(x_2.columns)].values \n",
        "y_2=df_main2.loc[:, ['result']].values\n",
        "\n",
        "\n",
        "print(type(X_2), type(y_2), type(x_2), type(y_2))\n",
        "\n",
        "print(X_2.shape)\n",
        "print(y_2.shape)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Shape: (3004, 38)\n",
            "   Unnamed: 0  cat1  cat10  ...             tweet_id  url      user_name\n",
            "0           0     0      0  ...  1155575657402961920    1  THEJEROMEOWEN\n",
            "1           1     0      0  ...  1155459426243043328    0  THEJEROMEOWEN\n",
            "2           2     0      0  ...  1126969730307448832    0     rabrakha14\n",
            "3           3     0      0  ...  1155277550794338304    0       RS_Aloha\n",
            "4           4     0      0  ...  1155188179395207168    0       RS_Aloha\n",
            "\n",
            "[5 rows x 38 columns]\n",
            "   Unnamed: 0  cat1  cat10  ...             tweet_id  url      user_name\n",
            "0           0     0      0  ...  1155575657402961920    1  THEJEROMEOWEN\n",
            "1           1     0      0  ...  1155459426243043328    0  THEJEROMEOWEN\n",
            "2           2     0      0  ...  1126969730307448832    0     rabrakha14\n",
            "3           3     0      0  ...  1155277550794338304    0       RS_Aloha\n",
            "4           4     0      0  ...  1155188179395207168    0       RS_Aloha\n",
            "5           5     0      0  ...  1154962871765393408    0  preciselyizzy\n",
            "\n",
            "[6 rows x 38 columns]\n",
            "0       0\n",
            "1       0\n",
            "2       0\n",
            "3       0\n",
            "4       0\n",
            "5       0\n",
            "6       0\n",
            "7       0\n",
            "8       0\n",
            "9       0\n",
            "10      0\n",
            "11      0\n",
            "12      0\n",
            "13      0\n",
            "14      0\n",
            "15      0\n",
            "16      0\n",
            "17      0\n",
            "18      0\n",
            "19      0\n",
            "20      0\n",
            "21      0\n",
            "22      0\n",
            "23      0\n",
            "24      0\n",
            "25      0\n",
            "26      0\n",
            "27      0\n",
            "28      0\n",
            "29      0\n",
            "       ..\n",
            "2974    0\n",
            "2975    0\n",
            "2976    0\n",
            "2977    0\n",
            "2978    0\n",
            "2979    0\n",
            "2980    0\n",
            "2981    0\n",
            "2982    0\n",
            "2983    0\n",
            "2984    0\n",
            "2985    0\n",
            "2986    0\n",
            "2987    0\n",
            "2988    0\n",
            "2989    0\n",
            "2990    0\n",
            "2991    0\n",
            "2992    0\n",
            "2993    0\n",
            "2994    0\n",
            "2995    0\n",
            "2996    0\n",
            "2997    0\n",
            "2998    0\n",
            "2999    0\n",
            "3000    0\n",
            "3001    0\n",
            "3002    0\n",
            "3003    0\n",
            "Name: result, Length: 3004, dtype: int64\n",
            "Index(['Unnamed: 0', 'cat1', 'cat10', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6',\n",
            "       'cat7', 'cat8', 'cat9', 'favorite_count', 'hour', 'image', 'level',\n",
            "       'nadj', 'nadv', 'nemoji', 'nlevel', 'nword', 'orginal', 'padj', 'padv',\n",
            "       'pemoji', 'plevel', 'pnoun', 'punc1', 'punc2', 'punc3', 'pword',\n",
            "       'question', 'result', 'retweets_count', 'sarcasm', 'sentiment',\n",
            "       'tweet_id', 'url'],\n",
            "      dtype='object')\n",
            "37\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(3004, 34)\n",
            "(3004, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL987O0l0juP",
        "colab_type": "code",
        "outputId": "9614effc-45e5-4127-ab17-4c77f30cabab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#Appending present and previosu data\n",
        "\n",
        "tem=np.append(X_1, X_2, axis=0)\n",
        "tem_y=np.append(y_1,y_2,axis=0)\n",
        "print(X_1.shape, X_2.shape, tem.shape)\n",
        "print(y_1.shape, y_2.shape, tem_y.shape)\n",
        "\n",
        "X=tem\n",
        "T=tem_y\n",
        "\n",
        "print(X.shape, T.shape)\n",
        "\n",
        "print(type(X_1))\n",
        "#convert to tensor\n",
        "X = torch.from_numpy(X)\n",
        "T = torch.from_numpy(T)\n",
        "\n",
        "X_1 = torch.from_numpy(X_1)\n",
        "T_1 = torch.from_numpy(y_1)\n",
        "\n",
        "X_2 = torch.from_numpy(X_2)\n",
        "T_2 = torch.from_numpy(y_2)\n",
        "\n",
        "print(type(X), type(T))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1906, 34) (3004, 34) (4910, 34)\n",
            "(1906, 1) (3004, 1) (4910, 1)\n",
            "(4910, 34) (4910, 1)\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJyAI-8h0pKH",
        "colab_type": "code",
        "outputId": "2bcf3779-94e4-408e-c32c-dc3a89b26e16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "\n",
        "\n",
        "#X_2 = torch.from_numpy(X_2)\n",
        "#T_2 = torch.from_numpy(y_2)\n",
        "\n",
        "import torch as pytorch\n",
        "\n",
        "pytorch.set_default_tensor_type('torch.DoubleTensor')\n",
        "#random weights\n",
        "X_2=X_2.type(torch.DoubleTensor)\n",
        "T_2=T_2.type(torch.DoubleTensor)\n",
        "\n",
        "print(torch.Tensor(X_2).dtype)\n",
        "print(torch.Tensor(X_1).dtype)\n",
        "print(\"\\n dtype of T_2 \\n\", torch.Tensor(T_2).dtype)\n",
        "\n",
        "W = Variable(torch.randn(1, 34, dtype=torch.double), requires_grad=True)\n",
        "b = Variable(torch.randn(1, 1, dtype=torch.double), requires_grad=True)\n",
        "print(W.size())\n",
        "\n",
        "#Weights for Previoes tweets\n",
        "#W1 = Variable(torch.randn(1, 34, dtype=torch.double), requires_grad=True)\n",
        "W_p = Variable(torch.randn(1, 34, dtype=torch.double), requires_grad=True)\n",
        "#W_p=W_p.type(torch.LongTensor)\n",
        "b_p = Variable(torch.randn(1, 1, dtype=torch.double), requires_grad=True)\n",
        "print(W_p.size(), torch.Tensor(W_p).dtype)\n",
        "print(W.size(), torch.Tensor(W_p).dtype)\n",
        "\n",
        "\n",
        "#sigmoid\n",
        "def sigmoid(x):\n",
        "    return 1/(1+torch.exp(-x))\n",
        "\n",
        "# Loss (cross entropy) error function\n",
        "def error(output, target):\n",
        "    return -target * torch.log(output) - (1-target) * torch.log(1-output)\n",
        "  \n",
        "#out = sigmoid(torch.mm(X, W.view(34,1))+b)\n",
        "\n",
        "out_present= sigmoid(torch.mm(X_1, W.view(34,1))+b)\n",
        "\n",
        "#W1=W1.type(torch.LongTensor)\n",
        "#out_present2= sigmoid(torch.mm(X_2, W1.view(34,1))+b)\n",
        "\n",
        "out_prev= sigmoid(torch.mm(X_2, W_p.view(34,1))+b_p)\n",
        "print(W.size())\n",
        "\n",
        "\n",
        "\n",
        "#we also could use: torch.nn.Sigmoid()\n",
        "#out = torch.nn.Sigmoid()(torch.mm(X, W.view(2,1))+b)\n",
        "\n",
        "#print(out.shape, T.shape)\n",
        "\n",
        "print(out_present.shape, T_1.shape)\n",
        "\n",
        "print(out_prev.shape, T_2.shape)\n",
        "\n",
        "\n",
        "#err = error(out,T)\n",
        "err_1 = error(out_present,T_1)\n",
        "err_2 = error(out_prev,T_2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#loss = torch.mean(err)\n",
        "loss = torch.sum(torch.mean(err_1)+torch.mean(err_2))\n",
        "\n",
        "print(err_1, err_2)\n",
        "print(torch.sum(err_1), torch.sum(err_2))\n",
        "\n",
        "#we need to scale down"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.float64\n",
            "torch.float64\n",
            "\n",
            " dtype of T_2 \n",
            " torch.float64\n",
            "torch.Size([1, 34])\n",
            "torch.Size([1, 34]) torch.float64\n",
            "torch.Size([1, 34]) torch.float64\n",
            "torch.Size([1, 34])\n",
            "torch.Size([1906, 1]) torch.Size([1906, 1])\n",
            "torch.Size([3004, 1]) torch.Size([3004, 1])\n",
            "tensor([[1.3012e+01],\n",
            "        [9.0400e+00],\n",
            "        [8.6458e+00],\n",
            "        ...,\n",
            "        [4.5775e-05],\n",
            "        [4.8879e-02],\n",
            "        [5.1994e-05]], grad_fn=<SubBackward0>) tensor([[30.8507],\n",
            "        [    nan],\n",
            "        [30.7109],\n",
            "        ...,\n",
            "        [22.6000],\n",
            "        [    nan],\n",
            "        [    nan]], grad_fn=<SubBackward0>)\n",
            "tensor(nan, grad_fn=<SumBackward0>) tensor(nan, grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUt6oZX81uQe",
        "colab_type": "text"
      },
      "source": [
        "unexpected type error , while the same type is working for out , it is not for out2 This is because X_2 (the first argument ) is in Long format, so the second argument is also expected to be long.. To solve the issue, we need to convert X_2 to double format.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5PDp5SZ0tbN",
        "colab_type": "code",
        "outputId": "cfeee5ed-8188-4ed7-9e8e-3c59baedfc99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## Scaling data set and applying the logistic regression\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "'''\n",
        "X=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]] #removing result attribute as it is class label, hence we get 34 attributes\n",
        "X=X.iloc[:,1:len(X.columns)].values   #removing the unnamed attribute\n",
        "x=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]]\n",
        "x=x.iloc[:,1:len(x.columns)].values \n",
        "y=df_main.loc[:, ['result']].values\n",
        "'''\n",
        "\n",
        "# X_1, y_1 means rpesent tweets' data\n",
        "X_1=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]] #removing result attribute as it is class label, hence we get 34 attributes\n",
        "X_1=X_1.iloc[:,1:len(X_1.columns)].values   #removing the unnamed attribute\n",
        "x_1=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]]\n",
        "x_1=x_1.iloc[:,1:len(x_1.columns)].values \n",
        "y_1=df_main.loc[:, ['result']].values\n",
        "\n",
        "\n",
        "\n",
        "data1=X_1\n",
        "\n",
        "scaler = StandardScaler()\n",
        "print(scaler.fit(data1))\n",
        "print(scaler.transform(data1))\n",
        "\n",
        "new_data1=scaler.transform(data1)\n",
        "\n",
        "X_1=torch.from_numpy(new_data1)\n",
        "T_1= torch.from_numpy(y_1)\n",
        "\n",
        "#random weights\n",
        "W = Variable(torch.randn(1, 34, dtype=torch.double), requires_grad=True)\n",
        "b = Variable(torch.randn(1, 1, dtype=torch.double), requires_grad=True)\n",
        "\n",
        "\n",
        "import torch as pytorch\n",
        "X_2=df_main2[df_main2.columns[~df_main2.columns.isin(['time', 'tweet_id','result'])]] #removing result attribute as it is class label, hence we get 34 attributes\n",
        "X_2=X_2.iloc[:,1:len(X_2.columns)].values   #removing the unnamed attribute\n",
        "x_2=df_main2[df_main2.columns[~df_main2.columns.isin(['time', 'tweet_id','result'])]]\n",
        "x_2=x_2.iloc[:,1:len(x_2.columns)].values \n",
        "y_2=df_main2.loc[:, ['result']].values\n",
        "\n",
        "\n",
        "data2=X_2\n",
        "\n",
        "scaler = StandardScaler()\n",
        "print(scaler.fit(data2))\n",
        "print(scaler.transform(data2))\n",
        "new_data2=scaler.transform(data2)\n",
        "\n",
        "X_2=torch.from_numpy(new_data2)\n",
        "T_2= torch.from_numpy(y_2)\n",
        "\n",
        "#do rescaling again\n",
        "\n",
        "d3=data2\n",
        "scaler2=StandardScaler()\n",
        "print(scaler.fit(d3))\n",
        "print(scaler.transform(d3))\n",
        "\n",
        "new_data3=scaler.transform(d3)\n",
        "\n",
        "X_2=torch.from_numpy(new_data3)\n",
        "T_2= torch.from_numpy(y_2)\n",
        "\n",
        "\n",
        "#normalizing the data\n",
        "\n",
        "\n",
        "\n",
        "pytorch.set_default_tensor_type('torch.DoubleTensor')\n",
        "#random weights\n",
        "X_2=X_2.type(torch.DoubleTensor)\n",
        "T_2=T_2.type(torch.DoubleTensor)\n",
        "\n",
        "print(torch.Tensor(X_2).dtype)\n",
        "print(torch.Tensor(X_1).dtype)\n",
        "print(\"\\n dtype of T_2 \\n\", torch.Tensor(T_2).dtype)\n",
        "\n",
        "\n",
        "W_p = Variable(torch.randn(1, 34, dtype=torch.double), requires_grad=True)\n",
        "#W_p=W_p.type(torch.LongTensor)\n",
        "b_p = Variable(torch.randn(1, 1, dtype=torch.double), requires_grad=True)\n",
        "print(W_p.size(), torch.Tensor(W_p).dtype)\n",
        "print(W.size(), torch.Tensor(W_p).dtype)\n",
        "\n",
        "\n",
        "#sigmoid\n",
        "def sigmoid(x):\n",
        "    return 1/(1+torch.exp(-x))\n",
        "\n",
        "# Loss (cross entropy) error function\n",
        "def error(output, target):\n",
        "    return -target * torch.log(output) - (1-target) * torch.log(1-output)\n",
        "  \n",
        "out = sigmoid(torch.mm(X_1, W.view(34,1))+b)\n",
        "#we also could use: torch.nn.Sigmoid()\n",
        "#out = torch.nn.Sigmoid()(torch.mm(X, W.view(2,1))+b)\n",
        "#err = error(out,T)\n",
        "#loss = torch.mean(err)  \n",
        "\n",
        "#print(err)\n",
        "#print(torch.mean(err))\n",
        "out_prev= sigmoid(torch.mm(X_2, W_p.view(34,1))+b_p)\n",
        "print(W.size())\n",
        "\n",
        "\n",
        "\n",
        "#we also could use: torch.nn.Sigmoid()\n",
        "#out = torch.nn.Sigmoid()(torch.mm(X, W.view(2,1))+b)\n",
        "\n",
        "#print(out.shape, T.shape)\n",
        "\n",
        "print(out_present.shape, T_1.shape)\n",
        "\n",
        "print(out_prev.shape, T_2.shape)\n",
        "\n",
        "\n",
        "#err = error(out,T)\n",
        "err_1 = error(out,T_1)\n",
        "err_2 = error(out_prev,T_2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#loss = torch.mean(err)\n",
        "loss = torch.sum(torch.mean(err_1)+torch.mean(err_2))\n",
        "\n",
        "print(err_1,\"\\n \\n\" , err_2)\n",
        "\n",
        "print(\"\\n mean of errors \\n\")\n",
        "print(torch.mean(err_1), \"\\n \\n\", torch.mean(err_2))\n",
        "\n",
        "print(\"\\n sum of errors \\n\")\n",
        "print(torch.sum(err_1), \"\\n \\n\", torch.sum(err_2))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
            "[[-0.13476792 -0.19493167 -0.19200937 ...  0.         -0.36993901\n",
            "  -0.33372183]\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.         -1.60479674\n",
            "  -0.33372183]\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.          0.86491871\n",
            "  -0.33372183]\n",
            " ...\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.          0.86491871\n",
            "   2.99650757]\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.         -1.60479674\n",
            "  -0.33372183]\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.          0.86491871\n",
            "  -0.33372183]]\n",
            "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
            "[[-0.11763217 -0.21155006 -0.18703747 ...  0.         -0.33180166\n",
            "   1.66123437]\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.         -0.33180166\n",
            "  -0.60196202]\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]\n",
            " ...\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.         -1.76388815\n",
            "   1.66123437]\n",
            " [-0.11763217  7.83270806 -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]\n",
            " [-0.11763217  3.810579   -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]]\n",
            "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
            "[[-0.11763217 -0.21155006 -0.18703747 ...  0.         -0.33180166\n",
            "   1.66123437]\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.         -0.33180166\n",
            "  -0.60196202]\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]\n",
            " ...\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.         -1.76388815\n",
            "   1.66123437]\n",
            " [-0.11763217  7.83270806 -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]\n",
            " [-0.11763217  3.810579   -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]]\n",
            "torch.float64\n",
            "torch.float64\n",
            "\n",
            " dtype of T_2 \n",
            " torch.float64\n",
            "torch.Size([1, 34]) torch.float64\n",
            "torch.Size([1, 34]) torch.float64\n",
            "torch.Size([1, 34])\n",
            "torch.Size([1906, 1]) torch.Size([1906, 1])\n",
            "torch.Size([3004, 1]) torch.Size([3004, 1])\n",
            "tensor([[1.2490e+01],\n",
            "        [3.1306e+00],\n",
            "        [1.7140e-01],\n",
            "        ...,\n",
            "        [5.1350e+00],\n",
            "        [4.4870e-04],\n",
            "        [9.5844e-01]], grad_fn=<SubBackward0>) \n",
            " \n",
            " tensor([[4.6001e+00],\n",
            "        [3.4781e-02],\n",
            "        [3.8588e+00],\n",
            "        ...,\n",
            "        [1.0224e+01],\n",
            "        [3.3773e-05],\n",
            "        [2.9374e-04]], grad_fn=<SubBackward0>)\n",
            "\n",
            " mean of errors \n",
            "\n",
            "tensor(2.1296, grad_fn=<MeanBackward0>) \n",
            " \n",
            " tensor(1.9449, grad_fn=<MeanBackward0>)\n",
            "\n",
            " sum of errors \n",
            "\n",
            "tensor(4059.0373, grad_fn=<SumBackward0>) \n",
            " \n",
            " tensor(5842.5852, grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xN162bo6PPXO",
        "colab_type": "text"
      },
      "source": [
        "We are getting NaN for previous tweets sum !!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD2euRoD03Gy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random \n",
        "from random import randint\n",
        "\n",
        "\n",
        "test_X=[]\n",
        "test_y=[]\n",
        "\n",
        "temp=random.sample(range(1,len(X)), 10)\n",
        "print(temp)\n",
        "\n",
        "for i in temp:\n",
        "  test_X.append(X[i])\n",
        "  test_y.append(y[i])\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "print(type(test_X), type(test_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF14K01Y077q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3350ace6-6f6d-48f9-8e1f-831a5dd78f02"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_1.numpy(), T_1.numpy(), test_size=0.33, random_state=42)\n",
        "\n",
        "X_1=torch.from_numpy(X_train1)\n",
        "T_1=torch.from_numpy(y_train1)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_2.numpy(), T_2.numpy(), test_size=0.33, random_state=53)\n",
        "\n",
        "X_2=torch.from_numpy(X_train2)\n",
        "T_2=torch.from_numpy(y_train2)\n",
        "#test_X=torch.from_numpy(X_test)\n",
        "#test_y=torch.from_numpy(y_test)\n",
        "test_X1=[]\n",
        "test_y1=[]\n",
        "test_X2=[]\n",
        "test_y2=[]\n",
        "for i in X_test1:\n",
        "  test_X1.append(i)\n",
        "  \n",
        "for i in y_test1:\n",
        "  test_y1.append(i)\n",
        "  \n",
        "  \n",
        "  \n",
        "for i in X_test2:\n",
        "  test_X2.append(i)\n",
        "  \n",
        "for i in y_test2:\n",
        "  test_y2.append(i)\n",
        "  \n",
        "  \n",
        "print(type(test_X1), type(test_y1), type(test_X2), type(test_y2))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'> <class 'list'> <class 'list'> <class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVU1m3aE0-SD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "51e3b9de-ee71-4307-8fb3-bbf548e9af74"
      },
      "source": [
        "import math \n",
        "\n",
        "epochs=1500\n",
        "alpha=0.001\n",
        "n_iter=1\n",
        "\n",
        "torch.set_default_tensor_type('torch.DoubleTensor')\n",
        "for i in range(epochs):\n",
        "    #alternative0 (explicit definition)\n",
        "    out = sigmoid(torch.mm(X_1, W.view(34,1))+b)\n",
        "    out_prev=sigmoid(torch.mm(X_2,W_p.view(34,1))+b_p)\n",
        "    #we also could use: torch.nn.Sigmoid()\n",
        "    #out = torch.nn.Sigmoid()(torch.mm(X, W.view(2,1))+b)\n",
        "    err = error(out,T)\n",
        "    loss = torch.mean(err)\n",
        "\n",
        "    #alternative1 (pytorch defined loss function)\n",
        "    #out = torch.mm(X, W.view(2,1))+b\n",
        "    #loss = criterion(out, T.double())     \n",
        "\n",
        "    #alternative2 (custom error function)\n",
        "    #cross_entropy = CE.apply\n",
        "    #out = sigmoid(torch.mm(X, W.view(2,1))+b)\n",
        "    #err = cross_entropy(out,T)\n",
        "    #loss = torch.mean(err)    \n",
        "    \n",
        "    #compute gradients\n",
        "    loss.backward()\n",
        "\n",
        "    last_w = W.data.numpy()[0].copy()\n",
        "    last_b = b.data.numpy()[0].copy()\n",
        "       \n",
        "    with torch.no_grad():\n",
        "        W -= alpha * W.grad\n",
        "        b -= alpha * b.grad\n",
        "\n",
        "        # Manually zero the gradients after updating weights\n",
        "        W.grad.zero_()\n",
        "        b.grad.zero_()\n",
        "        #print(loss)\n",
        "    \n",
        "    n_iter+=1\n",
        "    if n_iter%100==0:\n",
        "      correct = 0\n",
        "      total = 0\n",
        "            \n",
        "      # Iterate through test dataset\n",
        "      for X_v, y_v in zip(X_train,y_train):\n",
        "        #print(\"Hi\")\n",
        "        # Load images to a Torch Variable\n",
        "        #images = Variable(images.view(-1, 28*28))\n",
        "        # Forward pass only to get logits/output\n",
        "        #outputs = sigmoid(X_val)\n",
        "        X_v=torch.Tensor(X_v)\n",
        "        X_temp=(X_v.view(1,34))\n",
        "        W_temp=(W.view(34,1))\n",
        "        #print(X_val)\n",
        "        outputs=sigmoid(torch.mm(X_temp,W_temp)+b)\n",
        "        #print(outputs)\n",
        "        # Get predictions from the maximum value\n",
        "        #_, predicted = torch.max(outputs.data, 1)\n",
        "        pred_val=(outputs.detach().numpy())\n",
        "        #print(type(pred_val), pred_val) \n",
        "        # for accessing scalar value from tensor, by converting it to numpy array\n",
        "        for i in pred_val:\n",
        "          for j in i:\n",
        "            #print(type(j))\n",
        "            temp=j\n",
        "            \n",
        "        predicted=round(temp)\n",
        "        # Total number of labels\n",
        "        #total += y_val.size(0)\n",
        "        total+=1\n",
        "        # Total correct predictions\n",
        "        correct += (predicted == y_v).sum()\n",
        "        \n",
        "      accuracy = 100 * correct / total\n",
        "      print(\"\\n In epoch \", n_iter, \" Training accuracy= \", accuracy)\n",
        "      \n",
        "      \n",
        "      # Iterate through test dataset\n",
        "      for X_val, y_val in zip(test_X,test_y):\n",
        "        #print(\"Hi\")\n",
        "        # Load images to a Torch Variable\n",
        "        #images = Variable(images.view(-1, 28*28))\n",
        "        # Forward pass only to get logits/output\n",
        "        #outputs = sigmoid(X_val)\n",
        "        X_val=torch.Tensor(X_val)\n",
        "        X_temp=(X_val.view(1,34))\n",
        "        W_temp=(W.view(34,1))\n",
        "        #print(X_val)\n",
        "        outputs=sigmoid(torch.mm(X_temp,W_temp)+b)\n",
        "        #print(outputs)\n",
        "        # Get predictions from the maximum value\n",
        "        #_, predicted = torch.max(outputs.data, 1)\n",
        "        pred_val=(outputs.detach().numpy())\n",
        "        #print(type(pred_val), pred_val) \n",
        "        # for accessing scalar value from tensor, by converting it to numpy array\n",
        "        for i in pred_val:\n",
        "          for j in i:\n",
        "            #print(type(j))\n",
        "            temp=j\n",
        "            \n",
        "        predicted=round(temp)\n",
        "        # Total number of labels\n",
        "        #total += y_val.size(0)\n",
        "        total+=1\n",
        "        # Total correct predictions\n",
        "        correct += (predicted == y_val).sum()\n",
        "        \n",
        "      accuracy = 100 * correct / total\n",
        "      print(\"\\n In epoch \", n_iter, \" Testing accuracy= \", accuracy)\n",
        "      "
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-a95b8235e1d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m       \u001b[0;31m# Iterate through test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mX_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_v\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;31m#print(\"Hi\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# Load images to a Torch Variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    }
  ]
}