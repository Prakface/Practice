{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Using skorch for cross validation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prakface/Practice/blob/master/Using_skorch_for_cross_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCiVL_fCcv8N",
        "colab_type": "code",
        "outputId": "e49368c3-0c0a-4042-9811-7bfe88bb8089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!pip install -U skorch"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: skorch in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.8.5)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.17.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.21.3)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.14.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->skorch) (0.14.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsVNY__keNV6",
        "colab_type": "code",
        "outputId": "b5808bda-a1aa-4955-c568-5782aaf41f49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "url='https://raw.githubusercontent.com/Prakface/Practice/master/One_mon_present_full.csv'\n",
        "\n",
        "url2='https://raw.githubusercontent.com/Prakface/Practice/master/Final_one_month_prev_features.csv'\n",
        "\n",
        "url_h='https://raw.githubusercontent.com/Prakface/Practice/master/heuristic_labels.csv'\n",
        "\n",
        "data = pd.read_csv(url) \n",
        "\n",
        "data2= pd.read_csv(url2)\n",
        "\n",
        "print(\"Data Shape:\", data.shape) \n",
        "\n",
        "#data=pd.read_csv(url)\n",
        "\n",
        "df=pd.DataFrame(data)\n",
        "print(data.head()) \n",
        "\n",
        "\n",
        "data_modified= data.dropna()\n",
        "\n",
        "data_modified.to_csv(\"modifiedData.csv\", index=False)\n",
        "\n",
        "\n",
        "df2=pd.read_csv(\"modifiedData.csv\")\n",
        "\n",
        "print(df2[0:6])\n",
        "\n",
        "print(df2['result'])\n",
        "\n",
        "df_main=df2[df2.columns[~df2.columns.isin(['text', 'user_name'])]]\n",
        "\n",
        "print(df_main.columns)\n",
        "\n",
        "print(len(df_main.columns))\n",
        "\n",
        "  \n",
        "# X_1, y_1 means rpesent tweets' data\n",
        "X_1=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]] #removing result attribute as it is class label, hence we get 34 attributes\n",
        "X_1=X_1.iloc[:,1:len(X_1.columns)].values   #removing the unnamed attribute\n",
        "x_1=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]]\n",
        "x_1=x_1.iloc[:,1:len(x_1.columns)].values \n",
        "y_1=df_main.loc[:, ['result']].values\n",
        "\n",
        "\n",
        "print(type(X_1), type(y_1), type(x_1), type(y_1))\n",
        "\n",
        "print(X_1.shape)\n",
        "print(y_1.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Shape: (1908, 40)\n",
            "  Unnamed: 0 cat1  cat10  ...      tweet_id  url      user_name\n",
            "0          0    0      0  ...  8.323790e+17  0.0  THEJEROMEOWEN\n",
            "1          1    0      0  ...  8.323786e+17  0.0       Acejinjo\n",
            "2          2    0      0  ...  8.323780e+17  0.0     RabRakha21\n",
            "3          3    0      0  ...  8.323777e+17  0.0       RS_Aloha\n",
            "4          4    0      0  ...  8.323767e+17  0.0  preciselyizzy\n",
            "\n",
            "[5 rows x 40 columns]\n",
            "   Unnamed: 0  cat1  cat10  ...      tweet_id  url        user_name\n",
            "0           0     0      0  ...  8.323790e+17  0.0    THEJEROMEOWEN\n",
            "1           1     0      0  ...  8.323786e+17  0.0         Acejinjo\n",
            "2           2     0      0  ...  8.323780e+17  0.0       RabRakha21\n",
            "3           3     0      0  ...  8.323777e+17  0.0         RS_Aloha\n",
            "4           4     0      0  ...  8.323767e+17  0.0    preciselyizzy\n",
            "5           5     0      0  ...  8.323759e+17  0.0  thefireistarted\n",
            "\n",
            "[6 rows x 40 columns]\n",
            "0       1.0\n",
            "1       1.0\n",
            "2       1.0\n",
            "3       1.0\n",
            "4       1.0\n",
            "       ... \n",
            "1901    0.0\n",
            "1902    0.0\n",
            "1903    0.0\n",
            "1904    0.0\n",
            "1905    0.0\n",
            "Name: result, Length: 1906, dtype: float64\n",
            "Index(['Unnamed: 0', 'cat1', 'cat10', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6',\n",
            "       'cat7', 'cat8', 'cat9', 'favorite_count', 'hour', 'image', 'level',\n",
            "       'nadj', 'nadv', 'nemoji', 'nlevel', 'nword', 'orginal', 'padj', 'padv',\n",
            "       'pemoji', 'plevel', 'pnoun', 'punc1', 'punc2', 'punc3', 'pword',\n",
            "       'question', 'result', 'retweets_count', 'sarcasm', 'sentiment', 'time',\n",
            "       'tweet_id', 'url'],\n",
            "      dtype='object')\n",
            "38\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(1906, 34)\n",
            "(1906, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQGKyM6VeS5M",
        "colab_type": "code",
        "outputId": "53345d27-8878-43c9-84c4-b4f244cb5994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "data2= pd.read_csv(url2)\n",
        "\n",
        "print(\"Data Shape:\", data2.shape) \n",
        "\n",
        "#data=pd.read_csv(url)\n",
        "\n",
        "df_prev=pd.DataFrame(data2)\n",
        "print(data2.head()) \n",
        "\n",
        "\n",
        "data2_modified= data2.dropna()\n",
        "\n",
        "data2_modified.to_csv(\"modifiedData2.csv\", index=False)\n",
        "\n",
        "\n",
        "df_2=pd.read_csv(\"modifiedData2.csv\")\n",
        "\n",
        "print(df_2[0:6])\n",
        "\n",
        "print(df_2['result'])\n",
        "\n",
        "df_main2=df_2[df_2.columns[~df_2.columns.isin(['text', 'user_name'])]]\n",
        "\n",
        "print(df_main2.columns)\n",
        "\n",
        "print(len(df_main2.columns))\n",
        "\n",
        "  \n",
        "\n",
        "X_2=df_main2[df_main2.columns[~df_main2.columns.isin(['time', 'tweet_id','result'])]] #removing result attribute as it is class label, hence we get 34 attributes\n",
        "X_2=X_2.iloc[:,1:len(X_2.columns)].values   #removing the unnamed attribute\n",
        "x_2=df_main2[df_main2.columns[~df_main2.columns.isin(['time', 'tweet_id','result'])]]\n",
        "x_2=x_2.iloc[:,1:len(x_2.columns)].values \n",
        "y_2=df_main2.loc[:, ['result']].values\n",
        "\n",
        "\n",
        "print(type(X_2), type(y_2), type(x_2), type(y_2))\n",
        "\n",
        "print(X_2.shape)\n",
        "print(y_2.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Shape: (3004, 38)\n",
            "   Unnamed: 0  cat1  cat10  ...             tweet_id  url      user_name\n",
            "0           0     0      0  ...  1155575657402961920    1  THEJEROMEOWEN\n",
            "1           1     0      0  ...  1155459426243043328    0  THEJEROMEOWEN\n",
            "2           2     0      0  ...  1126969730307448832    0     rabrakha14\n",
            "3           3     0      0  ...  1155277550794338304    0       RS_Aloha\n",
            "4           4     0      0  ...  1155188179395207168    0       RS_Aloha\n",
            "\n",
            "[5 rows x 38 columns]\n",
            "   Unnamed: 0  cat1  cat10  ...             tweet_id  url      user_name\n",
            "0           0     0      0  ...  1155575657402961920    1  THEJEROMEOWEN\n",
            "1           1     0      0  ...  1155459426243043328    0  THEJEROMEOWEN\n",
            "2           2     0      0  ...  1126969730307448832    0     rabrakha14\n",
            "3           3     0      0  ...  1155277550794338304    0       RS_Aloha\n",
            "4           4     0      0  ...  1155188179395207168    0       RS_Aloha\n",
            "5           5     0      0  ...  1154962871765393408    0  preciselyizzy\n",
            "\n",
            "[6 rows x 38 columns]\n",
            "0       0\n",
            "1       0\n",
            "2       0\n",
            "3       0\n",
            "4       0\n",
            "       ..\n",
            "2999    0\n",
            "3000    0\n",
            "3001    0\n",
            "3002    0\n",
            "3003    0\n",
            "Name: result, Length: 3004, dtype: int64\n",
            "Index(['Unnamed: 0', 'cat1', 'cat10', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6',\n",
            "       'cat7', 'cat8', 'cat9', 'favorite_count', 'hour', 'image', 'level',\n",
            "       'nadj', 'nadv', 'nemoji', 'nlevel', 'nword', 'orginal', 'padj', 'padv',\n",
            "       'pemoji', 'plevel', 'pnoun', 'punc1', 'punc2', 'punc3', 'pword',\n",
            "       'question', 'result', 'retweets_count', 'sarcasm', 'sentiment',\n",
            "       'tweet_id', 'url'],\n",
            "      dtype='object')\n",
            "37\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(3004, 34)\n",
            "(3004, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc7VUL4yebkf",
        "colab_type": "code",
        "outputId": "434199e4-8617-456a-9ab4-ef544546e66c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df_h=pd.read_csv(url_h)\n",
        "\n",
        "print(df_h.columns)\n",
        "\n",
        "\n",
        "'''\n",
        "the following way is wrong\n",
        "label1=df_h.heuristic1.values\n",
        "label_1=df_h.heuristic1_1.values\n",
        "label2=df_h.heuristic2.values\n",
        "label3=df_h.heuristic3.values\n",
        "\n",
        "print(type(label1), type(label2), type(label3))\n",
        "\n",
        "\n",
        "\n",
        "print(type(label1), type(label2), type(label3))\n",
        "\n",
        "print(y_1.shape, label1.shape, label2.shape, label3.shape)\n",
        "\n",
        "#print(len(label1),len(label2),len(label3), len(label_1))\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "label1=df_h.loc[:, ['heuristic1']].values\n",
        "label_1=df_h.loc[:,['heuristic1_1']].values\n",
        "label2=df_h.loc[:, ['heuristic2']].values\n",
        "label3=df_h.loc[:, ['heuristic3']].values\n",
        "\n",
        "print(type(label1), type(label2), type(label3))\n",
        "\n",
        "\n",
        "\n",
        "print(type(label1), type(label2), type(label3))\n",
        "\n",
        "print(y_1.shape, label1.shape, label2.shape, label3.shape)\n",
        "\n",
        "\n",
        "tem1y=np.append(y_1, label1, axis=0)\n",
        "tem2y=np.append(y_1, label2, axis=0)\n",
        "tem3y=np.append(y_1, label3, axis=0)\n",
        "\n",
        "tem_1y=np.append(y_1, label_1, axis=0)\n",
        "\n",
        "T_h1=torch.from_numpy(tem1y)\n",
        "T_h2=torch.from_numpy(tem2y)\n",
        "T_h3=torch.from_numpy(tem3y)\n",
        "T_h_1=torch.from_numpy(tem_1y)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Unnamed: 0', 'heuristic1', 'heuristic1_1', 'heuristic2', 'heuristic3'], dtype='object')\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(1906, 1) (3273, 1) (3273, 1) (3273, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqkdV4kPeg6v",
        "colab_type": "code",
        "outputId": "7f32670f-5cdb-415e-ad26-1f2a2315df6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#Appending present and previosu data with actual label data...\n",
        "\n",
        "tem=np.append(X_1, X_2, axis=0)\n",
        "tem_y=np.append(y_1,label1,axis=0)\n",
        "print(X_1.shape, X_2.shape, tem.shape)\n",
        "#print(y_1.shape, y_2.shape, tem_y.shape)\n",
        "print(y_1.shape, label1.shape, tem_y.shape)\n",
        "X=tem\n",
        "T=tem_y\n",
        "\n",
        "print(X.shape, T.shape)\n",
        "\n",
        "print(type(X_1))\n",
        "#convert to tensor\n",
        "X = torch.from_numpy(X)\n",
        "T = torch.from_numpy(T)\n",
        "\n",
        "X_1 = torch.from_numpy(X_1)\n",
        "T_1 = torch.from_numpy(y_1)\n",
        "\n",
        "X_2 = torch.from_numpy(X_2)\n",
        "T_2 = torch.from_numpy(y_2)\n",
        "\n",
        "print(type(X), type(T))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1906, 34) (3004, 34) (4910, 34)\n",
            "(1906, 1) (3273, 1) (5179, 1)\n",
            "(4910, 34) (5179, 1)\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fU5DEdhem5k",
        "colab_type": "code",
        "outputId": "36c5d0a2-a3eb-4bb6-8869-5c1cde8c697f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "####Applying PCA\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.decomposition import PCA \n",
        "\n",
        "n=3\n",
        "\n",
        "data1=X\n",
        "\n",
        "scaler = StandardScaler()\n",
        "print(scaler.fit(data1))\n",
        "print(scaler.transform(data1))\n",
        "\n",
        "new_data1=scaler.transform(data1)\n",
        "\n",
        "pca = PCA(n_components =n) \n",
        "PCA_Data1=pca.fit_transform(new_data1)\n",
        "\n",
        "#X_1=torch.from_numpy(new_data1)\n",
        "X=torch.from_numpy(PCA_Data1)\n",
        "T= torch.from_numpy(tem_y)\n",
        "\n",
        "\n",
        "data1=X_1\n",
        "\n",
        "scaler = StandardScaler()\n",
        "print(scaler.fit(data1))\n",
        "print(scaler.transform(data1))\n",
        "\n",
        "new_data1=scaler.transform(data1)\n",
        "\n",
        "pca = PCA(n_components =n) \n",
        "PCA_Data1=pca.fit_transform(new_data1)\n",
        "\n",
        "#X_1=torch.from_numpy(new_data1)\n",
        "X_1=torch.from_numpy(PCA_Data1)\n",
        "T_1= torch.from_numpy(y_1)\n",
        "\n",
        "\n",
        "\n",
        "data2=X_2\n",
        "\n",
        "scaler = StandardScaler()\n",
        "print(scaler.fit(data2))\n",
        "print(scaler.transform(data2))\n",
        "new_data2=scaler.transform(data2)\n",
        "\n",
        "pca = PCA(n_components =n) \n",
        "PCA_Data2=pca.fit_transform(new_data2)\n",
        "\n",
        "\n",
        "#X_2=torch.from_numpy(new_data2)\n",
        "X_2=torch.from_numpy(PCA_Data2)\n",
        "T_2= torch.from_numpy(y_2)\n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
            "[[-0.12454675 -0.20523312 -0.1887928  ...  0.         -0.34669442\n",
            "  -0.50254455]\n",
            " [-0.12454675 -0.20523312 -0.1887928  ...  0.         -1.6902379\n",
            "  -0.50254455]\n",
            " [-0.12454675 -0.20523312 -0.1887928  ...  0.          0.99684906\n",
            "  -0.50254455]\n",
            " ...\n",
            " [-0.12454675 -0.20523312 -0.1887928  ...  0.         -1.6902379\n",
            "   1.98987335]\n",
            " [-0.12454675  8.0545589  -0.1887928  ...  0.          0.99684906\n",
            "  -0.50254455]\n",
            " [-0.12454675  3.92466289 -0.1887928  ...  0.          0.99684906\n",
            "  -0.50254455]]\n",
            "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
            "[[-0.13476792 -0.19493167 -0.19200937 ...  0.         -0.36993901\n",
            "  -0.33372183]\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.         -1.60479674\n",
            "  -0.33372183]\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.          0.86491871\n",
            "  -0.33372183]\n",
            " ...\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.          0.86491871\n",
            "   2.99650757]\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.         -1.60479674\n",
            "  -0.33372183]\n",
            " [-0.13476792 -0.19493167 -0.19200937 ...  0.          0.86491871\n",
            "  -0.33372183]]\n",
            "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
            "[[-0.11763217 -0.21155006 -0.18703747 ...  0.         -0.33180166\n",
            "   1.66123437]\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.         -0.33180166\n",
            "  -0.60196202]\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]\n",
            " ...\n",
            " [-0.11763217 -0.21155006 -0.18703747 ...  0.         -1.76388815\n",
            "   1.66123437]\n",
            " [-0.11763217  7.83270806 -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]\n",
            " [-0.11763217  3.810579   -0.18703747 ...  0.          1.10028483\n",
            "  -0.60196202]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2zQznD4euuA",
        "colab_type": "code",
        "outputId": "2db94f19-8072-41e7-8381-4b6028dee8e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.nn.functional as F\n",
        "\n",
        "## create training and validation split \n",
        "split_size = int(0.8 * len(X_1))\n",
        "index_list = list(range(len(X_1)))\n",
        "train_idx, valid_idx = index_list[:split_size], index_list[split_size:]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "x_tr = torch.tensor(X[train_idx], dtype=torch.long)\n",
        "y_tr = torch.tensor(T[train_idx], dtype=torch.float32)\n",
        "train = TensorDataset(x_tr, y_tr)\n",
        "trainloader = DataLoader(train, batch_size=128)\n",
        "'''\n",
        "\n",
        "x_tr = torch.tensor(X_1[train_idx], dtype=torch.long)\n",
        "y_tr = torch.tensor(T_1[train_idx], dtype=torch.float32)\n",
        "train = TensorDataset(x_tr, y_tr)\n",
        "trainloader = DataLoader(train, batch_size=128)\n",
        "\n",
        "x_valid = torch.tensor(X_1[valid_idx], dtype=torch.long)\n",
        "y_valid = torch.tensor(T_1[valid_idx], dtype=torch.float32)\n",
        "valid = TensorDataset(x_valid, y_valid)\n",
        "validloader = DataLoader(valid, batch_size=128)\n",
        "\n",
        "x_tr2 = torch.tensor(X_2[train_idx], dtype=torch.long)\n",
        "y_tr2 = torch.tensor(T_2[train_idx], dtype=torch.float32)\n",
        "train2 = TensorDataset(x_tr2, y_tr2)\n",
        "trainloader2 = DataLoader(train2, batch_size=128)\n",
        "\n",
        "\n",
        "\n",
        "##Following is Auxiliary data set\n",
        "\n",
        "\n",
        "split_size = int(0.8 * len(X_2))\n",
        "index_list = list(range(len(X_2)))\n",
        "train_idx, valid_idx = index_list[:split_size], index_list[split_size:]\n",
        "\n",
        "\n",
        "x_tr2 = torch.tensor(X_2[train_idx], dtype=torch.long)\n",
        "y_tr2 = torch.tensor(T_2[train_idx], dtype=torch.float32)\n",
        "train2 = TensorDataset(x_tr2, y_tr2)\n",
        "trainloader2 = DataLoader(train2, batch_size=128)\n",
        "\n",
        "x_valid2 = torch.tensor(X_2[valid_idx], dtype=torch.long)\n",
        "y_valid2 = torch.tensor(T_2[valid_idx], dtype=torch.float32)\n",
        "valid2 = TensorDataset(x_valid2, y_valid2)\n",
        "validloader = DataLoader(valid2, batch_size=128)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUoVB-cHezQP",
        "colab_type": "code",
        "outputId": "d97041cc-2d06-4ffd-fafa-e2fc0af160c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "##Concatenating the tensors\n",
        "\n",
        "import torch as pytorch\n",
        "\n",
        "pytorch.set_default_tensor_type('torch.DoubleTensor')\n",
        "\n",
        "X_1=X_1.type(torch.DoubleTensor)\n",
        "T_1=T_1.type(torch.DoubleTensor)\n",
        "\n",
        "X_2=X_2.type(torch.DoubleTensor)\n",
        "T_2=T_2.type(torch.DoubleTensor)\n",
        "\n",
        "\n",
        "X=torch.cat((X_1,X_2), 0)\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "X_tr=torch.cat((x_tr,x_tr2),0)\n",
        "\n",
        "print(X_tr.shape)\n",
        "\n",
        "Y_tr=torch.cat((y_tr,y_tr2),0)  ##y_tr2 doesn't have values, we should calculate using heuristics\n",
        "\n",
        "print(\"\\n target shape =\", Y_tr.shape)\n",
        "\n",
        "X_valid=torch.cat((x_valid,x_valid2),0)\n",
        "\n",
        "Y_valid=torch.cat((y_valid,y_valid2),0)\n",
        "\n",
        "Train=TensorDataset(X_tr, Y_tr)\n",
        "TrainLoader=DataLoader(Train, batch_size=128)\n",
        "\n",
        "\n",
        "Valid=TensorDataset(X_valid, Y_valid)\n",
        "ValidLoader=DataLoader(Valid, batch_size=128)\n",
        "\n",
        "\n",
        "print(X_tr.type())\n",
        "\n",
        "X_tr=torch.tensor(X_tr, dtype=torch.double)\n",
        "\n",
        "X_valid=torch.tensor(X_valid, dtype=torch.double)\n",
        "\n",
        "print(X_tr.type(), X_valid.type())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4910, 3])\n",
            "torch.Size([3927, 3])\n",
            "\n",
            " target shape = torch.Size([3927, 1])\n",
            "torch.LongTensor\n",
            "torch.DoubleTensor torch.DoubleTensor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNrDpjdhdkFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 50\n",
        "n_iters = 3000\n",
        "epochs = n_iters / (len(X_1) / batch_size)\n",
        "epochs2= n_iters / (len(X_2) / batch_size)\n",
        "#epochs= n_iters/((len(X_1)+len(X_2))/batch_size)\n",
        "#input_dim = 34\n",
        "input_dim=3\n",
        "output_dim = 1\n",
        "lr_rate = 0.001\n",
        "\n",
        "class LogisticRegression1(torch.nn.Module):\n",
        "    def __init__(self, input_dim=3):\n",
        "        super(LogisticRegression1, self).__init__()\n",
        "        self.linear = torch.nn.Linear(input_dim,1)\n",
        "        self.sigmoid=nn.Sigmoid()\n",
        "        #self.linear = torch.nn.Linear(2*input_dim, output_dim)\n",
        "        #raise NotImplementedError()\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = self.linear(x)\n",
        "        #outputs = torch.sigmoid(outputs)\n",
        "        #outputs=self.sigmoid(outputs)\n",
        "        return outputs\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWlm4L50dqOY",
        "colab_type": "code",
        "outputId": "faeb79e7-b1a0-457e-cd04-308eaa532eb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "from skorch import NeuralNetClassifier\n",
        "\n",
        "T=torch.cat((T_1,T_2), 0)\n",
        "T=torch.tensor(T, dtype=torch.long)\n",
        "\n",
        "\n",
        "net = NeuralNetClassifier(\n",
        "    LogisticRegression1,\n",
        "    criterion=torch.nn.BCEWithLogitsLoss(),\n",
        "    max_epochs=10,\n",
        "    lr=0.1,\n",
        "    # Shuffle training data on each epoch\n",
        "    iterator_train__shuffle=True,\n",
        ")\n",
        "\n",
        "#net.fit(X, y)\n",
        "#y_proba = net.predict_proba(X)\n",
        "\n",
        "net.fit(X, T)\n",
        "y_proba = net.predict_proba(X)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "model = LogisticRegression(input_dim)\n",
        "\n",
        "#criterion = torch.nn.CrossEntropyLoss() # computes softmax and then the cross entropy\n",
        "\n",
        "criterion= torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)\n",
        "\n",
        "print(\"\\n epochs = \", epochs)\n",
        "\n",
        "print(\"\\n initialized_weights = \\n\")\n",
        "for param in model.parameters():\n",
        "  print(param.data,\"Hi\\n\")\n",
        "'''"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-7feb0459b903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#y_proba = net.predict_proba(X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0my_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skorch/classifier.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# this is actually a pylint bug:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# https://github.com/PyCQA/pylint/issues/1085\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNeuralNetClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skorch/net.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \"\"\"\n\u001b[1;32m    849\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarm_start\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialized_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skorch/net.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_virtual_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skorch/net.py\u001b[0m in \u001b[0;36minitialize_criterion\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;34m\"\"\"Initializes the criterion.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0mcriterion_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_params_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'criterion'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcriterion_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() missing 2 required positional arguments: 'input' and 'target'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmrpoufygWX0",
        "colab_type": "code",
        "outputId": "101a3650-a8af-4519-9690-dcca3ef1d5ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(T.type())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.DoubleTensor\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}