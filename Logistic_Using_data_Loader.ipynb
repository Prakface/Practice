{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic_Using_data_Loader.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prakface/Practice/blob/master/Logistic_Using_data_Loader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moKJDiY-4b5-",
        "colab_type": "code",
        "outputId": "80be92fd-d8ed-41ff-89b1-cb336d669286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "url='https://raw.githubusercontent.com/Prakface/Practice/master/One_mon_present_full.csv'\n",
        "\n",
        "url2='https://raw.githubusercontent.com/Prakface/Practice/master/Final_one_month_prev_features.csv'\n",
        "\n",
        "data = pd.read_csv(url) \n",
        "print(\"Data Shape:\", data.shape) \n",
        "\n",
        "#data=pd.read_csv(url)\n",
        "\n",
        "df=pd.DataFrame(data)\n",
        "print(data.head()) \n",
        "\n",
        "\n",
        "data_modified= data.dropna()\n",
        "\n",
        "data_modified.to_csv(\"modifiedData.csv\", index=False)\n",
        "\n",
        "\n",
        "df2=pd.read_csv(\"modifiedData.csv\")\n",
        "\n",
        "print(df2[0:6])\n",
        "\n",
        "print(df2['result'])\n",
        "\n",
        "df_main=df2[df2.columns[~df2.columns.isin(['text', 'user_name'])]]\n",
        "\n",
        "print(df_main.columns)\n",
        "\n",
        "print(len(df_main.columns))\n",
        "\n",
        "  \n",
        "\n",
        "X=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]] #removing result attribute as it is class label, hence we get 34 attributes\n",
        "X=X.iloc[:,1:len(X.columns)].values   #removing the unnamed attribute\n",
        "\n",
        "x=df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id','result'])]]\n",
        "x=x.iloc[:,1:len(x.columns)].values # removing unnamed attribute at first column\n",
        "y=df_main.loc[:, ['result']].values\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(type(X), type(y), type(x), type(y))\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "print(x.shape)\n",
        "\n",
        "\n",
        "\n",
        "Total_data=pd.DataFrame(X,y)\n",
        "print(Total_data.columns)\n",
        "print(len(Total_data))\n",
        "X = torch.from_numpy(X)\n",
        "T = torch.from_numpy(y)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Shape: (1908, 40)\n",
            "  Unnamed: 0 cat1  cat10  ...      tweet_id  url      user_name\n",
            "0          0    0      0  ...  8.323790e+17  0.0  THEJEROMEOWEN\n",
            "1          1    0      0  ...  8.323786e+17  0.0       Acejinjo\n",
            "2          2    0      0  ...  8.323780e+17  0.0     RabRakha21\n",
            "3          3    0      0  ...  8.323777e+17  0.0       RS_Aloha\n",
            "4          4    0      0  ...  8.323767e+17  0.0  preciselyizzy\n",
            "\n",
            "[5 rows x 40 columns]\n",
            "   Unnamed: 0  cat1  cat10  ...      tweet_id  url        user_name\n",
            "0           0     0      0  ...  8.323790e+17  0.0    THEJEROMEOWEN\n",
            "1           1     0      0  ...  8.323786e+17  0.0         Acejinjo\n",
            "2           2     0      0  ...  8.323780e+17  0.0       RabRakha21\n",
            "3           3     0      0  ...  8.323777e+17  0.0         RS_Aloha\n",
            "4           4     0      0  ...  8.323767e+17  0.0    preciselyizzy\n",
            "5           5     0      0  ...  8.323759e+17  0.0  thefireistarted\n",
            "\n",
            "[6 rows x 40 columns]\n",
            "0       1.0\n",
            "1       1.0\n",
            "2       1.0\n",
            "3       1.0\n",
            "4       1.0\n",
            "5       1.0\n",
            "6       1.0\n",
            "7       1.0\n",
            "8       1.0\n",
            "9       1.0\n",
            "10      1.0\n",
            "11      1.0\n",
            "12      1.0\n",
            "13      1.0\n",
            "14      1.0\n",
            "15      1.0\n",
            "16      1.0\n",
            "17      1.0\n",
            "18      1.0\n",
            "19      1.0\n",
            "20      1.0\n",
            "21      1.0\n",
            "22      1.0\n",
            "23      1.0\n",
            "24      1.0\n",
            "25      1.0\n",
            "26      1.0\n",
            "27      1.0\n",
            "28      1.0\n",
            "29      1.0\n",
            "       ... \n",
            "1876    0.0\n",
            "1877    0.0\n",
            "1878    0.0\n",
            "1879    0.0\n",
            "1880    0.0\n",
            "1881    0.0\n",
            "1882    0.0\n",
            "1883    0.0\n",
            "1884    0.0\n",
            "1885    0.0\n",
            "1886    0.0\n",
            "1887    0.0\n",
            "1888    0.0\n",
            "1889    0.0\n",
            "1890    0.0\n",
            "1891    0.0\n",
            "1892    0.0\n",
            "1893    0.0\n",
            "1894    0.0\n",
            "1895    0.0\n",
            "1896    0.0\n",
            "1897    0.0\n",
            "1898    0.0\n",
            "1899    0.0\n",
            "1900    0.0\n",
            "1901    0.0\n",
            "1902    0.0\n",
            "1903    0.0\n",
            "1904    0.0\n",
            "1905    0.0\n",
            "Name: result, Length: 1906, dtype: float64\n",
            "Index(['Unnamed: 0', 'cat1', 'cat10', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6',\n",
            "       'cat7', 'cat8', 'cat9', 'favorite_count', 'hour', 'image', 'level',\n",
            "       'nadj', 'nadv', 'nemoji', 'nlevel', 'nword', 'orginal', 'padj', 'padv',\n",
            "       'pemoji', 'plevel', 'pnoun', 'punc1', 'punc2', 'punc3', 'pword',\n",
            "       'question', 'result', 'retweets_count', 'sarcasm', 'sentiment', 'time',\n",
            "       'tweet_id', 'url'],\n",
            "      dtype='object')\n",
            "38\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(1906, 34)\n",
            "(1906, 1)\n",
            "(1906, 34)\n",
            "RangeIndex(start=0, stop=34, step=1)\n",
            "1906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2bAz2KS4paq",
        "colab_type": "code",
        "outputId": "984b5ae1-e040-48cc-af9e-edb10be53b07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "#full_dataset=X\n",
        "#print(type(df_main))\n",
        "#print(df_main.columns)\n",
        "\n",
        "TotalData1=df_main\n",
        "print(type(TotalData1))\n",
        "TotalData1= df_main[df_main.columns[~df_main.columns.isin(['time', 'tweet_id'])]]\n",
        "TotalData1= TotalData1.iloc[:,1:]   #removing the unnamed attribute\n",
        "\n",
        "print(TotalData1.columns)\n",
        "print(len(TotalData1.columns))\n",
        "\n",
        "#df_total=pd.DataFrame(data=temp[1:,0:])\n",
        "\n",
        "#print(type(df_total))\n",
        "\n",
        "#print(df_total.columns)\n",
        "TotalData1['class_label']=y\n",
        "\n",
        "print(TotalData1.columns)\n",
        "full_dataset=TotalData1\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "type(train_dataset)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index(['cat1', 'cat10', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8',\n",
            "       'cat9', 'favorite_count', 'hour', 'image', 'level', 'nadj', 'nadv',\n",
            "       'nemoji', 'nlevel', 'nword', 'orginal', 'padj', 'padv', 'pemoji',\n",
            "       'plevel', 'pnoun', 'punc1', 'punc2', 'punc3', 'pword', 'question',\n",
            "       'result', 'retweets_count', 'sarcasm', 'sentiment', 'url'],\n",
            "      dtype='object')\n",
            "35\n",
            "Index(['cat1', 'cat10', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8',\n",
            "       'cat9', 'favorite_count', 'hour', 'image', 'level', 'nadj', 'nadv',\n",
            "       'nemoji', 'nlevel', 'nword', 'orginal', 'padj', 'padv', 'pemoji',\n",
            "       'plevel', 'pnoun', 'punc1', 'punc2', 'punc3', 'pword', 'question',\n",
            "       'result', 'retweets_count', 'sarcasm', 'sentiment', 'url',\n",
            "       'class_label'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataset.Subset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LM8FgIOS1bFz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "a0f42dc0-0a80-452c-89d5-cf67a2359159"
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.nn.functional as F\n",
        "\n",
        "## create training and validation split \n",
        "split_size = int(0.8 * len(Total_data))\n",
        "index_list = list(range(len(Total_data)))\n",
        "train_idx, valid_idx = index_list[:split_size], index_list[split_size:]\n",
        "\n",
        "\n",
        "x_tr = torch.tensor(X[train_idx], dtype=torch.long)\n",
        "y_tr = torch.tensor(T[train_idx], dtype=torch.float32)\n",
        "train = TensorDataset(x_tr, y_tr)\n",
        "trainloader = DataLoader(train, batch_size=128)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "assZLGq74DK9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "496ecf4b-dab0-4a3f-b6cb-39a7835b955d"
      },
      "source": [
        "x_valid = torch.tensor(X[valid_idx], dtype=torch.long)\n",
        "y_valid = torch.tensor(T[valid_idx], dtype=torch.float32)\n",
        "valid = TensorDataset(x_valid, y_valid)\n",
        "validloader = DataLoader(valid, batch_size=128)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfs9wbc-4TCx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "52750325-549f-4412-92dc-8417dd27e7ab"
      },
      "source": [
        "batch_size = 50\n",
        "n_iters = 3000\n",
        "epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "input_dim = 34\n",
        "output_dim = 2\n",
        "lr_rate = 0.001\n",
        "\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "test_transform = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "\n",
        "print(type(trainloader))\n",
        "\n",
        "print(len(trainloader))\n",
        "print(len(validloader))\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.utils.data.dataloader.DataLoader'>\n",
            "12\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUaKUXy45Puh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticRegression(torch.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = self.linear(x)\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrpmB1f95QFd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "5eb24351-bacd-4ca8-e041-5c1eb44a8ec4"
      },
      "source": [
        "model = LogisticRegression(input_dim, output_dim)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss() # computes softmax and then the cross entropy\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)\n",
        "\n",
        "##Training the data\n",
        "iterations = 0\n",
        "for epoch in range(int(epochs)):\n",
        "    for i, (data_X, labels) in enumerate(trainloader):\n",
        "        data_X = Variable(data_X.view(-1,34))\n",
        "        labels = Variable(labels)\n",
        "        labels=torch.tensor(labels, dtype=torch.long)\n",
        "        #print(labels.__class__)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data_X.float())\n",
        "        labels = labels.squeeze_()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        iterations+=1\n",
        "        if iterations%100==0:\n",
        "            # calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for data_X, labels in validloader:\n",
        "                data_X = Variable(data_X.view(-1, 34))\n",
        "                labels=torch.tensor(labels, dtype=torch.long)\n",
        "                outputs = model(data_X.float())\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total+= labels.size(0)\n",
        "                # for gpu, bring the predicted and labels back to cpu fro python operations to work\n",
        "                pr=predicted.numpy()\n",
        "                lb=labels.numpy()\n",
        "                for i in range(len(pr)):\n",
        "                  if(pr[i]==lb[i]):\n",
        "                    correct = correct+ 1\n",
        "                    \n",
        "                #correct+= (predicted == labels).sum()\n",
        "            accuracy = 100 * correct/total\n",
        "            print(\"Iteration: {}. Loss: {}.Correct:{}. total:{}. Accuracy: {}.\".format(iterations, loss.item(), correct, total,  accuracy))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100. Loss: 0.7753080725669861.Correct:116. total:382. Accuracy: 30.36649214659686.\n",
            "Iteration: 200. Loss: 1.0453687906265259.Correct:86. total:382. Accuracy: 22.513089005235603.\n",
            "Iteration: 300. Loss: 0.6785711646080017.Correct:357. total:382. Accuracy: 93.45549738219896.\n",
            "Iteration: 400. Loss: 0.6820691227912903.Correct:103. total:382. Accuracy: 26.963350785340314.\n",
            "Iteration: 500. Loss: 1.0025379657745361.Correct:80. total:382. Accuracy: 20.94240837696335.\n",
            "Iteration: 600. Loss: 0.6698188781738281.Correct:334. total:382. Accuracy: 87.43455497382199.\n",
            "Iteration: 700. Loss: 0.6242191791534424.Correct:94. total:382. Accuracy: 24.607329842931936.\n",
            "Iteration: 800. Loss: 0.9740904569625854.Correct:72. total:382. Accuracy: 18.848167539267017.\n",
            "Iteration: 900. Loss: 0.6730247139930725.Correct:312. total:382. Accuracy: 81.67539267015707.\n",
            "Iteration: 1000. Loss: 0.5876772403717041.Correct:96. total:382. Accuracy: 25.130890052356023.\n",
            "Iteration: 1100. Loss: 0.9559619426727295.Correct:74. total:382. Accuracy: 19.3717277486911.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5oGhrGe5QUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnhH5bBg4qms",
        "colab_type": "code",
        "outputId": "5ee6a87b-f5ab-4949-a27d-ebebf09645bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "#The following is for building train and test data and corresponding data loaders..\n",
        "\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "'''\n",
        "full_dataset=TotalData1\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(train_size, test_size,len(train_dataset), len(test_dataset))\n",
        "'''\n",
        "\n",
        "batch_size = 50\n",
        "n_iters = 3000\n",
        "epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "input_dim = 34\n",
        "output_dim = 2\n",
        "lr_rate = 0.001\n",
        "\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "test_transform = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "\n",
        "#train_data=CustomDataset(train_dataset, transform=train_transform)\n",
        "#test_data=CustomDataset(test_dataset, transform=test_transform)\n",
        "\n",
        "#train_data=torch.tensor(train_dataset)\n",
        "#test_data=torch.tensor(test_dataset)\n",
        "x_tr = torch.tensor(x_train[train_idx], dtype=torch.long)\n",
        "y_tr = torch.tensor(y_train[train_idx], dtype=torch.float32)\n",
        "train = TensorDataset(x_tr, y_tr)\n",
        "trainloader = DataLoader(train, batch_size=128)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True) \n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)\n",
        "print(type(train_loader))\n",
        "\n",
        "print(len(train_loader))\n",
        "print(len(test_loader))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1524 382 1524 382\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e91098811afa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#test_data=CustomDataset(test_dataset, transform=test_transform)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not determine the shape of object type 'Subset'"
          ]
        }
      ]
    }
  ]
}