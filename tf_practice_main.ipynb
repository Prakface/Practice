{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_practice_main.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prakface/Practice/blob/master/tf_practice_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WlkgU--EfVK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d47a3104-ad80-4b12-98ab-93fab5fda420"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "url='https://raw.githubusercontent.com/Prakface/Practice/master/initialFeatures.csv'\n",
        "\n",
        "data=pd.read_csv(url)\n",
        "\n",
        "df=pd.DataFrame(data)\n",
        "\n",
        "data_modified= data.dropna()\n",
        "\n",
        "data_modified.to_csv(\"modifiedData.csv\", index=False)\n",
        "\n",
        "df2=pd.read_csv(\"modifiedData.csv\")\n",
        "\n",
        "print(df2[0:6])\n",
        "\n",
        "print(len(df2.iloc[0,:]))\n",
        "print(df2.iloc[0:5,0:29 ])\n",
        "\n",
        "print(df2.iloc[0:5,28])\n",
        "\n",
        "\n",
        "print(df2.iloc[2500:3200,28])\n",
        "\n",
        "df3=df2.iloc[2500:3200,28]\n",
        "\n",
        "count1=0\n",
        "for i in range(len(df3)):\n",
        "  if df3.iloc[i]==1:\n",
        "    count1 = count1 +1\n",
        "    \n",
        "\n",
        "print(count1)\n",
        "    "
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   image  url  question  original  ...  retweets_count  hour     level  result\n",
            "0    0.0  1.0       0.0       1.0  ...             0.0  11.0 -0.040000     0.0\n",
            "1    0.0  1.0       0.0       1.0  ...             0.0  10.0 -0.047619     0.0\n",
            "2    0.0  1.0       0.0       1.0  ...             0.0  10.0  0.000000     0.0\n",
            "3    1.0  0.0       0.0       1.0  ...             0.0  10.0  0.000000     0.0\n",
            "4    0.0  1.0       0.0       1.0  ...             0.0  10.0 -0.040000     0.0\n",
            "5    0.0  0.0       0.0       0.0  ...            54.0  10.0  0.000000     0.0\n",
            "\n",
            "[6 rows x 29 columns]\n",
            "29\n",
            "   image  url  question  original  ...  retweets_count  hour     level  result\n",
            "0    0.0  1.0       0.0       1.0  ...             0.0  11.0 -0.040000     0.0\n",
            "1    0.0  1.0       0.0       1.0  ...             0.0  10.0 -0.047619     0.0\n",
            "2    0.0  1.0       0.0       1.0  ...             0.0  10.0  0.000000     0.0\n",
            "3    1.0  0.0       0.0       1.0  ...             0.0  10.0  0.000000     0.0\n",
            "4    0.0  1.0       0.0       1.0  ...             0.0  10.0 -0.040000     0.0\n",
            "\n",
            "[5 rows x 29 columns]\n",
            "0    0.0\n",
            "1    0.0\n",
            "2    0.0\n",
            "3    0.0\n",
            "4    0.0\n",
            "Name: result, dtype: float64\n",
            "2500    0.0\n",
            "2501    0.0\n",
            "2502    0.0\n",
            "2503    0.0\n",
            "2504    0.0\n",
            "2505    0.0\n",
            "2506    0.0\n",
            "2507    0.0\n",
            "2508    0.0\n",
            "2509    0.0\n",
            "2510    0.0\n",
            "2511    0.0\n",
            "2512    0.0\n",
            "2513    0.0\n",
            "2514    0.0\n",
            "2515    0.0\n",
            "2516    0.0\n",
            "2517    0.0\n",
            "2518    0.0\n",
            "2519    0.0\n",
            "2520    0.0\n",
            "2521    0.0\n",
            "2522    0.0\n",
            "2523    0.0\n",
            "2524    0.0\n",
            "2525    0.0\n",
            "2526    0.0\n",
            "2527    0.0\n",
            "2528    0.0\n",
            "2529    0.0\n",
            "       ... \n",
            "3170    1.0\n",
            "3171    1.0\n",
            "3172    1.0\n",
            "3173    1.0\n",
            "3174    1.0\n",
            "3175    1.0\n",
            "3176    1.0\n",
            "3177    1.0\n",
            "3178    1.0\n",
            "3179    1.0\n",
            "3180    1.0\n",
            "3181    1.0\n",
            "3182    1.0\n",
            "3183    1.0\n",
            "3184    1.0\n",
            "3185    1.0\n",
            "3186    1.0\n",
            "3187    1.0\n",
            "3188    1.0\n",
            "3189    1.0\n",
            "3190    1.0\n",
            "3191    1.0\n",
            "3192    1.0\n",
            "3193    1.0\n",
            "3194    1.0\n",
            "3195    1.0\n",
            "3196    1.0\n",
            "3197    1.0\n",
            "3198    1.0\n",
            "3199    1.0\n",
            "Name: result, Length: 700, dtype: float64\n",
            "345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmI7azpOWkIf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "98f0e5dd-f9b9-464a-a77f-b7398111da58"
      },
      "source": [
        "count1=0\n",
        "\n",
        "\n",
        "#print(df3.iloc[300:400])\n",
        "\n",
        "print(df3.iloc[300])     \n",
        "  \n",
        "  \n",
        "print(len(df3))\n",
        "\n",
        "for i in range(len(df3)):\n",
        "  if df3.iloc[i]==1:\n",
        "    count1 = count1 +1  \n",
        "\n",
        "print(count1)\n",
        "    "
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "700\n",
            "345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDkuI_6dJf0p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c0cca80a-7ed7-47b2-87e2-a1bbb514575c"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# Importing the dataset\n",
        "#dataset = pd.read_csv('Social_Network_Ads.csv')\n",
        "dataset=df2\n",
        "\n",
        "\n",
        "df_t=dataset.iloc[lambda x: x.index % 2 != 0]\n",
        "\n",
        "au_df_t=dataset.iloc[lambda k: k.index % 2 == 0]\n",
        "\n",
        "#X = dataset.iloc[:, 0:29].values #all coulumns excpet the last 29th column\n",
        "#y = dataset.iloc[:,28 ].values  # the last 29th column (0 to 28) , hence last column is 28\n",
        "\n",
        "X = df_t.iloc[:, 0:29].values #all coulumns excpet the last 29th column\n",
        "y = df_t.iloc[:,28 ].values  # the last 29th column (0 to 28) , hence last column is 28\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 0)\n",
        "\n",
        "\n",
        "au_X = au_df_t.iloc[:, 0:29].values #all coulumns excpet the last 29th column\n",
        "au_y = au_df_t.iloc[:,28].values  # the last 29th column (0 to 28) , hence last column is 28\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "au_X_train, au_X_test, au_y_train, au_y_test = train_test_split(au_X, au_y, test_size = 0.30, random_state = 0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(len(X), len(y), len(au_X),len(au_y))\n",
        "\n",
        "\n",
        "print(len(X_train), len(y_train), len(au_X_train),len(au_y_train))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2937 2937 2938 2938\n",
            "2055 2055 2056 2056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNuAOvEFrclk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_t1=pd.DataFrame(X_train)\n",
        "X_t2=pd.DataFrame(X_test)\n",
        "\n",
        "y_t1=pd.DataFrame(y_train)\n",
        "y_t2=pd.DataFrame(y_test)\n",
        "\n",
        "\n",
        "au_X_t1=pd.DataFrame(au_X_train)\n",
        "au_X_t2=pd.DataFrame(au_X_test)\n",
        "\n",
        "au_y_t1=pd.DataFrame(au_y_train)\n",
        "au_y_t2=pd.DataFrame(au_y_test)\n",
        "\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "au_X_train = sc.transform(au_X_train)\n",
        "au_X_test = sc.transform(au_X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhhhkTG8NC84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#original of the above\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#au_X_train = X_train[140:280, :]\n",
        "#au_X_test = X_test[0:60, :]\n",
        "\n",
        "\n",
        "X_t1=pd.DataFrame(X_train)\n",
        "X_t2=pd.DataFrame(X_test)\n",
        "\n",
        "y_t1=pd.DataFrame(y_train)\n",
        "y_t2=pd.DataFrame(y_test)\n",
        "\n",
        "au_X_train = X_t1[lambda x: x.index % 2 == 0]\n",
        "au_X_test = X_t2[lambda x: x.index % 2 == 0]\n",
        "\n",
        "au_y_train = y_t1[lambda x: x.index % 2 == 0]\n",
        "au_y_test = y_t2[lambda x: x.index % 2 == 0]\n",
        "\n",
        "#X_test = X_test[60:120, :]\n",
        "#y_test = y_test[60:120]\n",
        "#y_test1 = y_test[0:60]\n",
        "\n",
        "#X_train = X_train[0:140, :]\n",
        "#y_train1 = y_train[0:140]\n",
        "\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "au_X_train = sc.transform(au_X_train)\n",
        "au_X_test = sc.transform(au_X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ8xxOKWr24m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fd4a80ba-c623-42c9-bcf7-df510e9a65ec"
      },
      "source": [
        "X_t1.shape"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2055, 29)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLezptRLryoh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "780e168b-d403-4c25-869a-55f017e88f89"
      },
      "source": [
        "A = tf.Variable(tf.random_normal(shape=[2055, 29]))\n",
        "b = tf.Variable(tf.random_normal(shape=[2055, 1]))\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "data = tf.placeholder(dtype=tf.float32, shape=[None, 2055])\n",
        "target = tf.placeholder(dtype=tf.float32, shape=[None, 1])\n",
        "\n",
        "mod = tf.matmul(data, A) + b\n",
        "\n",
        "for i in range(len(X_t1)):\n",
        "    loss = ((y_train[i] * tf.log(tf.sigmoid(tf.transpose(A)*X_train[i]))) + ((1 - y_train[i]) * tf.log(1 - tf.sigmoid(tf.transpose(A)*X_train[i])))\n",
        "            + (y_train[i] * tf.log(tf.sigmoid(tf.transpose(A)*au_X_train[i]))) + ((1 - y_train[i]) * tf.log(1 - tf.sigmoid(tf.transpose(A)*au_X_train[i]))))\n",
        "\n",
        "loss = loss/len(X_t1)\n",
        "\n",
        "X_train = np.concatenate((X_train, au_X_train), axis = 0)\n",
        "\n",
        "learning_rate = .005\n",
        "batch_size = 30\n",
        "iter_num = 1500\n",
        "\n",
        "# Define the optimizer\n",
        "opt = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "\n",
        "# Define the goal\n",
        "goal = opt.minimize(loss)\n",
        "\n",
        "# Define the accuracy\n",
        "# The default threshold is 0.5, rounded off directly\n",
        "prediction = tf.round(tf.sigmoid(mod))\n",
        "# Bool into float32 type\n",
        "correct = tf.cast(tf.equal(prediction, target), dtype=tf.float32)\n",
        "# Average\n",
        "accuracy = tf.reduce_mean(correct)\n",
        "# End of the definition of the model framework\n",
        "\n",
        "# Start training model\n",
        "# Define the variable that stores the result\n",
        "loss_trace = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1864\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1865\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 2055 and 29 for 'mul_2' (op: 'Mul') with input shapes: [29,2055], [29].",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-59acf949ab49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_t1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     loss = ((y_train[i] * tf.log(tf.sigmoid(tf.transpose(A)*X_train[i]))) + ((1 - y_train[i]) * tf.log(1 - tf.sigmoid(tf.transpose(A)*X_train[i])))\n\u001b[0;32m---> 14\u001b[0;31m             + (y_train[i] * tf.log(tf.sigmoid(tf.transpose(A)*au_X_train[i]))) + ((1 - y_train[i]) * tf.log(1 - tf.sigmoid(tf.transpose(A)*au_X_train[i]))))\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_t1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    895\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbinary_op_wrapper_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1178\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Case: Dense * Sparse.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6488\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6489\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 6490\u001b[0;31m         \"Mul\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m   6491\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6492\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3614\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3615\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3616\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3617\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3618\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2025\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   2026\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 2027\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   2028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 2055 and 29 for 'mul_2' (op: 'Mul') with input shapes: [29,2055], [29]."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWs2lKuNtNHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training model\n",
        "for epoch in range(iter_num):\n",
        "    # Generate random batch index\n",
        "    batch_index = np.random.choice(len(X_train), size=batch_size)\n",
        "    batch_train_X = X_train[batch_index]\n",
        "    batch_train_y = np.matrix(y_train[batch_index]).T\n",
        "    sess.run(goal, feed_dict={data: batch_train_X, target: batch_train_y})\n",
        "    temp_loss = sess.run(loss, feed_dict={data: batch_train_X, target: batch_train_y})\n",
        "    # convert into a matrix, and the shape of the placeholder to correspond\n",
        "    temp_train_acc = sess.run(accuracy, feed_dict={data: X_train, target: np.matrix(y_train).T})\n",
        "    temp_test_acc = sess.run(accuracy, feed_dict={data: X_test, target: np.matrix(y_test).T})\n",
        "    temp_test_acc1 = sess.run(accuracy, feed_dict={data: au_X_test, target: np.matrix(y_test1).T})\n",
        "\n",
        "    # recode the result\n",
        "    loss_trace.append(temp_loss)\n",
        "    train_acc.append(temp_train_acc)\n",
        "    test_acc.append(temp_test_acc)\n",
        "    # output\n",
        "    if (epoch + 1) % 300 == 0:\n",
        "        print(epoch + 1, temp_loss, temp_train_acc, temp_test_acc, temp_test_acc1)\n",
        "\n",
        "\n",
        "plt.plot(train_acc, 'b-', label='train accuracy')\n",
        "plt.plot(test_acc, 'k-', label='test accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Train and Test Accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(loss_trace)\n",
        "plt.title('Cross Entropy Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2tUb6Iwi_E_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e29875e4-d800-4913-94f2-3d519f9f9425"
      },
      "source": [
        "len(X_t2)\n",
        "\n",
        "#len(y_t1)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1763"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkDQ-U-Ci6Tt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = tf.Variable(tf.random_normal(shape=[2, 1]))\n",
        "b = tf.Variable(tf.random_normal(shape=[1, 1]))\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "data = tf.placeholder(dtype=tf.float32, shape=[None, 2])\n",
        "target = tf.placeholder(dtype=tf.float32, shape=[None, 1])\n",
        "\n",
        "mod = tf.matmul(data, A) + b\n",
        "\n",
        "for i in range(len(X_t1)):\n",
        "    loss = ((y_train1[i] * tf.log(tf.sigmoid(tf.transpose(A)*X_train[i]))) + ((1 - y_train1[i]) * tf.log(1 - tf.sigmoid(tf.transpose(A)*X_train[i])))\n",
        "            + (y_train1[i] * tf.log(tf.sigmoid(tf.transpose(A)*au_X_train[i]))) + ((1 - y_train1[i]) * tf.log(1 - tf.sigmoid(tf.transpose(A)*au_X_train[i]))))\n",
        "\n",
        "loss = loss/140\n",
        "\n",
        "X_train = np.concatenate((X_train, au_X_train), axis = 0)\n",
        "\n",
        "learning_rate = .005\n",
        "batch_size = 30\n",
        "iter_num = 1500\n",
        "\n",
        "# Define the optimizer\n",
        "opt = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "\n",
        "# Define the goal\n",
        "goal = opt.minimize(loss)\n",
        "\n",
        "# Define the accuracy\n",
        "# The default threshold is 0.5, rounded off directly\n",
        "prediction = tf.round(tf.sigmoid(mod))\n",
        "# Bool into float32 type\n",
        "correct = tf.cast(tf.equal(prediction, target), dtype=tf.float32)\n",
        "# Average\n",
        "accuracy = tf.reduce_mean(correct)\n",
        "# End of the definition of the model framework\n",
        "\n",
        "# Start training model\n",
        "# Define the variable that stores the result\n",
        "loss_trace = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "# training model\n",
        "for epoch in range(iter_num):\n",
        "    # Generate random batch index\n",
        "    batch_index = np.random.choice(len(X_train), size=batch_size)\n",
        "    batch_train_X = X_train[batch_index]\n",
        "    batch_train_y = np.matrix(y_train[batch_index]).T\n",
        "    sess.run(goal, feed_dict={data: batch_train_X, target: batch_train_y})\n",
        "    temp_loss = sess.run(loss, feed_dict={data: batch_train_X, target: batch_train_y})\n",
        "    # convert into a matrix, and the shape of the placeholder to correspond\n",
        "    temp_train_acc = sess.run(accuracy, feed_dict={data: X_train, target: np.matrix(y_train).T})\n",
        "    temp_test_acc = sess.run(accuracy, feed_dict={data: X_test, target: np.matrix(y_test).T})\n",
        "    temp_test_acc1 = sess.run(accuracy, feed_dict={data: au_X_test, target: np.matrix(y_test1).T})\n",
        "\n",
        "    # recode the result\n",
        "    loss_trace.append(temp_loss)\n",
        "    train_acc.append(temp_train_acc)\n",
        "    test_acc.append(temp_test_acc)\n",
        "    # output\n",
        "    if (epoch + 1) % 300 == 0:\n",
        "        print(epoch + 1, temp_loss, temp_train_acc, temp_test_acc, temp_test_acc1)\n",
        "\n",
        "\n",
        "plt.plot(train_acc, 'b-', label='train accuracy')\n",
        "plt.plot(test_acc, 'k-', label='test accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Train and Test Accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(loss_trace)\n",
        "plt.title('Cross Entropy Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}