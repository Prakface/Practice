{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_practice_main.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prakface/Practice/blob/master/tf_practice_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WlkgU--EfVK",
        "colab_type": "code",
        "outputId": "8d1a9b53-4741-4ecf-a9d3-9b4a921674ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "url='https://raw.githubusercontent.com/Prakface/Practice/master/initialFeatures.csv'\n",
        "\n",
        "data=pd.read_csv(url)\n",
        "\n",
        "df=pd.DataFrame(data)\n",
        "\n",
        "data_modified= data.dropna()\n",
        "\n",
        "data_modified.to_csv(\"modifiedData.csv\", index=False)\n",
        "\n",
        "df2=pd.read_csv(\"modifiedData.csv\")\n",
        "\n",
        "print(df2[0:6])\n",
        "\n",
        "print(len(df2.iloc[0,:]))\n",
        "print(df2.iloc[0:5,0:29 ])\n",
        "\n",
        "print(df2.iloc[0:5,28])\n",
        "\n",
        "\n",
        "print(df2.iloc[2500:3200,28])\n",
        "\n",
        "df3=df2.iloc[2500:3200,28]\n",
        "\n",
        "count1=0\n",
        "for i in range(len(df3)):\n",
        "  if df3.iloc[i]==1:\n",
        "    count1 = count1 +1\n",
        "    \n",
        "\n",
        "print(count1)\n",
        "    "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   image  url  question  original  ...  retweets_count  hour     level  result\n",
            "0    0.0  1.0       0.0       1.0  ...             0.0  11.0 -0.040000     0.0\n",
            "1    0.0  1.0       0.0       1.0  ...             0.0  10.0 -0.047619     0.0\n",
            "2    0.0  1.0       0.0       1.0  ...             0.0  10.0  0.000000     0.0\n",
            "3    1.0  0.0       0.0       1.0  ...             0.0  10.0  0.000000     0.0\n",
            "4    0.0  1.0       0.0       1.0  ...             0.0  10.0 -0.040000     0.0\n",
            "5    0.0  0.0       0.0       0.0  ...            54.0  10.0  0.000000     0.0\n",
            "\n",
            "[6 rows x 29 columns]\n",
            "29\n",
            "   image  url  question  original  ...  retweets_count  hour     level  result\n",
            "0    0.0  1.0       0.0       1.0  ...             0.0  11.0 -0.040000     0.0\n",
            "1    0.0  1.0       0.0       1.0  ...             0.0  10.0 -0.047619     0.0\n",
            "2    0.0  1.0       0.0       1.0  ...             0.0  10.0  0.000000     0.0\n",
            "3    1.0  0.0       0.0       1.0  ...             0.0  10.0  0.000000     0.0\n",
            "4    0.0  1.0       0.0       1.0  ...             0.0  10.0 -0.040000     0.0\n",
            "\n",
            "[5 rows x 29 columns]\n",
            "0    0.0\n",
            "1    0.0\n",
            "2    0.0\n",
            "3    0.0\n",
            "4    0.0\n",
            "Name: result, dtype: float64\n",
            "2500    0.0\n",
            "2501    0.0\n",
            "2502    0.0\n",
            "2503    0.0\n",
            "2504    0.0\n",
            "2505    0.0\n",
            "2506    0.0\n",
            "2507    0.0\n",
            "2508    0.0\n",
            "2509    0.0\n",
            "2510    0.0\n",
            "2511    0.0\n",
            "2512    0.0\n",
            "2513    0.0\n",
            "2514    0.0\n",
            "2515    0.0\n",
            "2516    0.0\n",
            "2517    0.0\n",
            "2518    0.0\n",
            "2519    0.0\n",
            "2520    0.0\n",
            "2521    0.0\n",
            "2522    0.0\n",
            "2523    0.0\n",
            "2524    0.0\n",
            "2525    0.0\n",
            "2526    0.0\n",
            "2527    0.0\n",
            "2528    0.0\n",
            "2529    0.0\n",
            "       ... \n",
            "3170    1.0\n",
            "3171    1.0\n",
            "3172    1.0\n",
            "3173    1.0\n",
            "3174    1.0\n",
            "3175    1.0\n",
            "3176    1.0\n",
            "3177    1.0\n",
            "3178    1.0\n",
            "3179    1.0\n",
            "3180    1.0\n",
            "3181    1.0\n",
            "3182    1.0\n",
            "3183    1.0\n",
            "3184    1.0\n",
            "3185    1.0\n",
            "3186    1.0\n",
            "3187    1.0\n",
            "3188    1.0\n",
            "3189    1.0\n",
            "3190    1.0\n",
            "3191    1.0\n",
            "3192    1.0\n",
            "3193    1.0\n",
            "3194    1.0\n",
            "3195    1.0\n",
            "3196    1.0\n",
            "3197    1.0\n",
            "3198    1.0\n",
            "3199    1.0\n",
            "Name: result, Length: 700, dtype: float64\n",
            "345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmI7azpOWkIf",
        "colab_type": "code",
        "outputId": "8f21b06d-e18b-4392-f9f3-9ef34a6dcbbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "count1=0\n",
        "\n",
        "\n",
        "#print(df3.iloc[300:400])\n",
        "\n",
        "print(df3.iloc[300])     \n",
        "  \n",
        "  \n",
        "print(len(df3))\n",
        "\n",
        "for i in range(len(df3)):\n",
        "  if df3.iloc[i]==1:\n",
        "    count1 = count1 +1  \n",
        "\n",
        "print(count1)\n",
        "    "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "700\n",
            "345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDkuI_6dJf0p",
        "colab_type": "code",
        "outputId": "86d29bdc-7d76-4ea6-94f7-b09d04bd37f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# Importing the dataset\n",
        "#dataset = pd.read_csv('Social_Network_Ads.csv')\n",
        "dataset=df2\n",
        "\n",
        "\n",
        "df_t=dataset.iloc[lambda x: x.index % 2 != 0]\n",
        "\n",
        "au_df_t=dataset.iloc[lambda k: k.index % 2 == 0]\n",
        "\n",
        "#X = dataset.iloc[:, 0:29].values #all coulumns excpet the last 29th column\n",
        "#y = dataset.iloc[:,28 ].values  # the last 29th column (0 to 28) , hence last column is 28\n",
        "\n",
        "X = df_t.iloc[:, 0:28].values #all coulumns excpet the last 29th column\n",
        "y = df_t.iloc[:,28 ].values  # the last 29th column (0 to 28) , hence last column is 28\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 0)\n",
        "\n",
        "\n",
        "au_X = au_df_t.iloc[:, 0:28].values #all coulumns excpet the last 29th column\n",
        "au_y = au_df_t.iloc[:,28].values  # the last 29th column (0 to 28) , hence last column is 28\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "au_X_train, au_X_test, au_y_train, au_y_test = train_test_split(au_X, au_y, test_size = 0.30, random_state = 0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(len(X), len(y), len(au_X),len(au_y))\n",
        "\n",
        "\n",
        "print(len(X_train), len(y_train), len(au_X_train),len(au_y_train))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2937 2937 2938 2938\n",
            "2055 2055 2056 2056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNuAOvEFrclk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "X_t1=pd.DataFrame(X_train)\n",
        "X_t2=pd.DataFrame(X_test)\n",
        "\n",
        "y_t1=pd.DataFrame(y_train)\n",
        "y_t2=pd.DataFrame(y_test)\n",
        "\n",
        "\n",
        "au_X_t1=pd.DataFrame(au_X_train)\n",
        "au_X_t2=pd.DataFrame(au_X_test)\n",
        "\n",
        "au_y_t1=pd.DataFrame(au_y_train)\n",
        "au_y_t2=pd.DataFrame(au_y_test)\n",
        "\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "au_X_train = sc.transform(au_X_train)\n",
        "au_X_test = sc.transform(au_X_test)\n",
        "\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_t1)\n",
        "X_test = sc.transform(X_t2)\n",
        "au_X_train = sc.transform(au_X_t1)\n",
        "au_X_test = sc.transform(au_X_t2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5MejLgV7_c0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "64cda073-3b53-4280-d1f2-ac38cbe799f4"
      },
      "source": [
        "len(X_train)\n",
        "\n",
        "type(X_t1)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhhhkTG8NC84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#original of the above\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#au_X_train = X_train[140:280, :]\n",
        "#au_X_test = X_test[0:60, :]\n",
        "\n",
        "\n",
        "X_t1=pd.DataFrame(X_train)\n",
        "X_t2=pd.DataFrame(X_test)\n",
        "\n",
        "y_t1=pd.DataFrame(y_train)\n",
        "y_t2=pd.DataFrame(y_test)\n",
        "\n",
        "au_X_train = X_t1[lambda x: x.index % 2 == 0]\n",
        "au_X_test = X_t2[lambda x: x.index % 2 == 0]\n",
        "\n",
        "au_y_train = y_t1[lambda x: x.index % 2 == 0]\n",
        "au_y_test = y_t2[lambda x: x.index % 2 == 0]\n",
        "\n",
        "#X_test = X_test[60:120, :]\n",
        "#y_test = y_test[60:120]\n",
        "#y_test1 = y_test[0:60]\n",
        "\n",
        "#X_train = X_train[0:140, :]\n",
        "#y_train1 = y_train[0:140]\n",
        "\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "au_X_train = sc.transform(au_X_train)\n",
        "au_X_test = sc.transform(au_X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ8xxOKWr24m",
        "colab_type": "code",
        "outputId": "5bd0a587-1025-4706-ba37-feea1ce4fb39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_t1.shape\n",
        "\n",
        "len(X_t1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2055"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLezptRLryoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = tf.Variable(tf.random_normal(shape=[28, 1]))\n",
        "b = tf.Variable(tf.random_normal(shape=[1, 1]))\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "data = tf.placeholder(dtype=tf.float32, shape=[None, 28])\n",
        "target = tf.placeholder(dtype=tf.float32, shape=[None, 1])\n",
        "\n",
        "mod = tf.matmul(data, A) + b\n",
        "\n",
        "for i in range(len(X_t1)):\n",
        "    loss = ((y_train[i] * tf.log(tf.sigmoid(tf.transpose(A)*X_train[i]))) + ((1 - y_train[i]) * tf.log(1 - tf.sigmoid(tf.transpose(A)*X_train[i])))\n",
        "            + (y_train[i] * tf.log(tf.sigmoid(tf.transpose(A)*au_X_train[i]))) + ((1 - y_train[i]) * tf.log(1 - tf.sigmoid(tf.transpose(A)*au_X_train[i]))))\n",
        "\n",
        "loss = loss/len(X_t1)\n",
        "\n",
        "#X_train = np.concatenate((X_train, au_X_train), axis = 0)\n",
        "\n",
        "learning_rate = .005\n",
        "batch_size = 30\n",
        "iter_num = 1500\n",
        "\n",
        "# Define the optimizer\n",
        "opt = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "\n",
        "# Define the goal\n",
        "goal = opt.minimize(loss)\n",
        "\n",
        "# Define the accuracy\n",
        "# The default threshold is 0.5, rounded off directly\n",
        "prediction = tf.round(tf.sigmoid(mod))\n",
        "# Bool into float32 type\n",
        "correct = tf.cast(tf.equal(prediction, target), dtype=tf.float32)\n",
        "# Average\n",
        "accuracy = tf.reduce_mean(correct)\n",
        "# End of the definition of the model framework\n",
        "\n",
        "# Start training model\n",
        "# Define the variable that stores the result\n",
        "loss_trace = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW_0DP4smAgK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "812afb81-daaa-4c0a-cbd3-df151783b6a5"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "b= tf.Variable(tf.zeros([1]))\n",
        "print(b)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable_3:0' shape=(1,) dtype=float32_ref>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWs2lKuNtNHC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "outputId": "94f0d251-90a1-4a6f-cb6c-6e2dfdea6ac1"
      },
      "source": [
        "# training model\n",
        "for epoch in range(iter_num):\n",
        "    # Generate random batch index\n",
        "    #print(len(X_train))\n",
        "    batch_index = np.random.choice(len(X_train), size=batch_size)\n",
        "    #print(batch_index)\n",
        "    batch_train_X = X_train[batch_index]\n",
        "    batch_train_y = np.matrix(y_train[batch_index]).T\n",
        "    #batch_train_y = y_train[batch_index]\n",
        "    sess.run(goal, feed_dict={data: batch_train_X, target: batch_train_y})\n",
        "    temp_loss = sess.run(loss, feed_dict={data: batch_train_X, target: batch_train_y})\n",
        "    # convert into a matrix, and the shape of the placeholder to correspond\n",
        "    temp_train_acc = sess.run(accuracy, feed_dict={data: X_train, target: np.matrix(y_train).T})\n",
        "    temp_test_acc = sess.run(accuracy, feed_dict={data: X_test, target: np.matrix(y_test).T})\n",
        "    temp_test_acc1 = sess.run(accuracy, feed_dict={data: au_X_test, target: np.matrix(y_test).T})\n",
        "\n",
        "    # recode the result\n",
        "    loss_trace.append(temp_loss)\n",
        "    train_acc.append(temp_train_acc)\n",
        "    test_acc.append(temp_test_acc)\n",
        "    # output\n",
        "    if (epoch + 1) % 300 == 0:\n",
        "        print(epoch + 1, temp_loss, temp_train_acc, temp_test_acc, temp_test_acc1)\n",
        "\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300 [[-0.00069306 -0.00088505 -0.00068875 -0.00049431 -0.00085481 -0.00188047\n",
            "  -0.00097858 -0.0004569  -0.00066167 -0.0006677  -0.00070395 -0.00097514\n",
            "  -0.0006746  -0.00090492 -0.00041043 -0.00058534 -0.00058811 -0.00065722\n",
            "  -0.00096172 -0.0006419  -0.00077766 -0.0007112  -0.00070791 -0.0010007\n",
            "  -0.00062948 -0.00063879 -0.00074959 -0.00090821]] 0.5625304 0.569161 0.5283447\n",
            "600 [[-0.00069307 -0.00088579 -0.00068877 -0.00049441 -0.00085483 -0.00189109\n",
            "  -0.00097962 -0.0004569  -0.00066167 -0.0006677  -0.00070396 -0.00097523\n",
            "  -0.0006746  -0.00090498 -0.00041046 -0.00058541 -0.00058818 -0.00065722\n",
            "  -0.00096176 -0.00064191 -0.00077768 -0.00071121 -0.00070794 -0.001001\n",
            "  -0.00062948 -0.0006388  -0.00074964 -0.00090835]] 0.5625304 0.569161 0.5283447\n",
            "900 [[-0.00069307 -0.00088652 -0.0006888  -0.00049452 -0.00085486 -0.00190173\n",
            "  -0.00098066 -0.0004569  -0.00066167 -0.00066771 -0.00070397 -0.00097531\n",
            "  -0.0006746  -0.00090503 -0.00041049 -0.00058548 -0.00058825 -0.00065722\n",
            "  -0.0009618  -0.00064193 -0.0007777  -0.00071123 -0.00070796 -0.0010013\n",
            "  -0.00062948 -0.0006388  -0.0007497  -0.00090849]] 0.563017 0.569161 0.5272109\n",
            "1200 [[-0.00069308 -0.00088725 -0.00068883 -0.00049462 -0.00085488 -0.00191241\n",
            "  -0.00098171 -0.0004569  -0.00066168 -0.00066771 -0.00070398 -0.0009754\n",
            "  -0.0006746  -0.00090509 -0.00041052 -0.00058555 -0.00058832 -0.00065722\n",
            "  -0.00096185 -0.00064194 -0.00077772 -0.00071124 -0.00070799 -0.00100161\n",
            "  -0.00062948 -0.0006388  -0.00074975 -0.00090863]] 0.563017 0.5680272 0.5272109\n",
            "1500 [[-0.00069308 -0.00088798 -0.00068886 -0.00049473 -0.0008549  -0.0019231\n",
            "  -0.00098275 -0.0004569  -0.00066168 -0.00066771 -0.000704   -0.00097548\n",
            "  -0.0006746  -0.00090515 -0.00041055 -0.00058562 -0.00058839 -0.00065722\n",
            "  -0.00096189 -0.00064195 -0.00077775 -0.00071125 -0.00070801 -0.00100191\n",
            "  -0.00062948 -0.0006388  -0.00074981 -0.00090878]] 0.563017 0.5680272 0.5272109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3N5Xz3ZtSbn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "outputId": "9a590364-ee06-4a43-85a9-9e48058ee03b"
      },
      "source": [
        "plt.plot(train_acc, 'b-', label='train accuracy')\n",
        "plt.plot(test_acc, 'k-', label='test accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Train and Test Accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(loss_trace)\n",
        "plt.title('Cross Entropy Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmYVdWd7//3BwpEVCbFbiOYwkRF\npmIo0DhFQZSYDs7ROEIHSZugnaT1iok3MXZ8fknM4DUxsdVGwXgFgxMqRgrFmNw4UCAOgAoiNoUT\nsxAFreL7++PsKg9lDYc6tTlV1Of1POdh77XX3vu7zinqW2utffZWRGBmZtZU7QodgJmZtW5OJGZm\nlhcnEjMzy4sTiZmZ5cWJxMzM8uJEYmZmeXEisVZDUntJWyQd1AJi+ZukcYWOw6wlcCKx1CS/9Ktf\n2yV9lLV+/s4eLyKqImLviPifNOJtDpJuz2rjx5I+yVp/OI/jTpL05xzrzpS0TVL3pp7PbGc4kVhq\nkl/6e0fE3sD/AF/LKru7dn1JRbs+yuYVEROy2vwL4O6sNn8t7fNL6gF8DdgCnJv2+Wqdu9V/ftY0\nTiRWMJJ+KmmGpHskbQYukPQlSc9K2ijpHUk3SeqQ1C+SFJKKk/U/Jtsfk7RZ0jOS+tRzrnbJX+rv\nJsd+StLhWdsbPJakMZJek7RJ0v8BlEe7vyzp+SSOBZK+lLXt3yS9lcTwhqQzJA0HfgWcmPRsKho4\n/LnAm0n9i2udt4Okn0h6U9IHSQw9k21DkvdkQ/K+fzcpnylpctYx/kXSq1nrayV9X9ISYH1S9hNJ\nK5M2vCzpK1n1Jemy5L3cLOklSf2SfabWineKpOt3+g22XS8i/PIr9RewEjixVtlPgY/J/AXdDtgT\nGA4cARQBBwOvA5OS+kVAAMXJ+h+BtUAp0AGYAfyxnvO3A8YB+wCdgN8B5Vnb6z0WsD+Zv/BPT7Zd\nCVQC4xpp80+BO2uVHQysA0YmMY0F3ge6Aj3J/DI+OKl7INA3WZ4E/DmH9/k54EdAMbAdOCxr20+A\n8iSGdsCw5Lz7JjH9G9AxKRue7DMTmJx1jH8BXs1aXws8CxwA7JmUnQv8M9AeGA9sAnok28YDK4AS\nMsm4b9LOLwAfZB1jz2S/wxprs1+Ff7lHYoX2t4h4OCK2R8RHETE/Ip6LiMqIWAHcCny5gf1nRkR5\nRHwC3A0MrqtScvw7I2JzRGwFrgWGSdorh2P9C7AoIh5Itv0KWNPE9o4H7o2IJ5OYZgHLgBPJ/OIX\n0F/SHhGxOiJebehg2ST1BUYA/zciVgLPABdlVZkAXBURK5JzL4iITcAZwJKIuCUiPo6ITRExfyfa\n9OuIeCciPgKIiOkR8W5k5rTuIPNeDcmK4fqIeDEyXk3a+QbwInBaUu9U4LWIeG0n4rACcSKxQluV\nvSKpr6RHkyGoD4DrgP0a2P/drOUPgb3rqpRc8fULSSuS4y5PNmUfu75jfS47zojYDjQ0vNSQzwPj\nkmGtjZI2kklYn4uIdWSGo74HvCfpIUlf2IljXww8HxHVbbsbuDAZ1mtPptfwRh379a6nPFe1P8OJ\nyZBWdfuK+fR9buhcU4ELkuULgLvyiMl2IScSK7Tat5/+L+AV4IsR0YXMME2T5yOyXAScQmZIqSvw\nxaQ8l2O/Q+YXYGYHqR3Qq4lxrAJuiYhuWa+9IuK3ABExKyJGkhnueZvMEBx89n3aQRLTBcDAJAm/\nC/xnEvcJEVGVtKOuxLSqnnKAfwCds9b/uY46NbFJ6gf8GvgmmeGsbmSGNavf54bOdS9wrKT+ZD6n\n6fXUsxbGicRamn3IjI3/I5kM/1YzHncbmbmAzsDOTOI+AgyWdGoy8f89MvMZTXEn8A1JJyQ9hT0l\nnSjpnyT1lnSKpD2BrWR+iW9P9nsPOEj1Xxk1KolpcNarP/AQnw5v3Q78f5KKk3MPldQVuB/ol/Qk\nOkrqKqk02WcR8LWkrBeZuZqG7J3EvAZoJ2kSmR5JtduBH0galEy895V0IEBEfAA8CtwDzI2Ipg4f\n2i7mRGItzX+QGaLZTKZ3MqOZjnsHmb/w3wYWA3/PdceIeA84B7iBzOTyQWQmtXdaRCwDziYzEb+O\nzF/rl5H5i70I+AGZpLGWTDK4PNl1NrAaWCPprToOfTEwIyJeT+Yn3o2Id4GbgDMl7Z2ccw7wF2Aj\n8HugYzKkNppMj2YNsBQ4KjnubcBbZHoSs4D/20j7ngf+G3iBzHv9OTLJqNqdwG+B+8hMrs8AumRt\nnwoMxMNarYoi/GArM2sZkqGxvwP/nFwUYa2AeyRm1iIkFwR8D5jmJNK6+JuoZlZwkvYn80XKZcDJ\nBQ7HdpKHtszMLC8e2jIzs7y0iaGt/fbbL4qLiwsdhplZq7JgwYK1EdHope5tIpEUFxdTXl5e6DDM\nzFqVei41/wwPbZmZWV6cSMzMLC9OJGZmlhcnEjMzy4sTiZmZ5cWJxMzM8uJEYmZmeWkT3yNpqj/+\n8Y+8/vrrhQ7DzJrRyJEjOf744wsdxm7FiaQB06dPZ/bs2YUOw8yaSURQVlbGM888U+hQditOJA14\n5JFHCh2CmTWjU045hTVr/ODF5pbqHImkMZJek7Rc0uQ6to+TtEbSouQ1IWvbQZLmSFoqaYmk4qR8\npKSFkl6RNLWBR4+ame2gXbt2+I7nzS+1RJI8pOZm4CtAPzLPqe5XR9UZETE4ed2eVT4NuCEiDgdG\nAO9LakfmUZznRsQAMo8AvTitNpjZ7kUS27dvL3QYu500eyQjgOURsSIiPgamA6fmsmOScIoiogwg\nIrZExIfAvsDHEVE9A14GnNn8oZvZ7sg9knSkmUgOBFZlrVckZbWdKeklSTMl9U7KDgU2Srpf0guS\nbkh6OGuBIkmlSb2zgN51HBNJEyWVSyr3mKiZgXskaSn090geBoojYhCZ3sXUpLwIOBa4AhgOHAyM\ni8yfEucCv5H0PLAZqKrrwBFxa0SURkRpz56N3k7fzNoA90jSkWYiWc2OvYVeSVmNiFgXEduS1duB\nYclyBbAoGRarBB4Ehib7PBMRx0bECOBpwF/0MLOcuEeSjjQTyXzgEEl9JHUk05OYlV1B0gFZq2OB\npVn7dpNU3ZUYCSxJ9tk/+XcP4CrgltRaYGa7FfdI0pHapbMRUSlpEvA40B6YEhGLJV0HlEfELOBy\nSWOBSmA9MC7Zt0rSFcATkgQsAG5LDn2lpH8hkwT/EBFPptUGM9u9uEeSjlS/gxERs4HZtcp+lLV8\nNXB1PfuWAYPqKL8SuLJ5IzWztqBdu3ZOJCko9GS7mdkuI8lDWylwIjGzNsM9knQ4kZhZm+HJ9nQ4\nkZhZm+HJ9nQ4kZhZm+EeSTqcSMyszXCPJB1OJGbWZrhHkg4nEjNrM9wjSYcTiZm1Ge6RpMOJxMza\nDPdI0uFEYmZthr+QmA4nEjNrM3yLlHQ4kZhZm+EeSTqcSMyszfBkezqcSMyszfBkezqcSMyszXCP\nJB1OJGbWZrhHkg4nEjNrM9wjSYcTiZm1Ge6RpMOJxMzaDPdI0uFEYmZthnsk6Ug1kUgaI+k1Scsl\nTa5j+zhJayQtSl4TsrYdJGmOpKWSlkgqTspHSVqY1P+bpC+m2QYz2334C4npKErrwJLaAzcDo4EK\nYL6kWRGxpFbVGRExqY5DTAOuj4gySXsD1Z/+H4BTI2KppG8D1wDjUmmEme1WJFFZWclXv/rVQoey\ny9xyyy307t071XOklkiAEcDyiFgBIGk6cCpQO5F8hqR+QFFElAFExJaszQF0SZa7Am83Z9Bmtvsa\nNWoUc+fO5f333y90KLtMVVVV6udIM5EcCKzKWq8Ajqij3pmSjgNeB74XEauAQ4GNku4H+gBzgckR\nUQVMAGZL+gj4ADiyrpNLmghMBDjooIOap0Vm1qqNHDmS5557rtBh7HYKPdn+MFAcEYOAMmBqUl4E\nHAtcAQwHDubT4avvAadERC/gDuDXdR04Im6NiNKIKO3Zs2d6LTAza+PSTCSrgeyBuV5JWY2IWBcR\n25LV24FhyXIFsCgiVkREJfAgMFRST6AkIqr/pJgBHJVWA8zMrHFpJpL5wCGS+kjqCJwLzMquIOmA\nrNWxwNKsfbsliQNgJJm5lQ1AV0mHJuWjs/YxM7MCSG2OJCIqJU0CHgfaA1MiYrGk64DyiJgFXC5p\nLFAJrCcZvoqIKklXAE9IErAAuC055iXAfZK2k0ks/5pWG8zMrHFqC9/yLC0tjfLy8kKHYWbWqkha\nEBGljdUr9GS7mZm1ck4kZmaWFycSMzPLixOJmZnlxYnEzMzy4kRiZmZ5cSIxM7O8OJGYmVlenEjM\nzCwvTiRmZpYXJxIzM8uLE4mZmeXFicTMzPLiRGJmZnlxIjEzs7w4kZiZWV6cSMzMLC9OJGZmlhcn\nEjMzy4sTiZmZ5cWJxMzM8pJqIpE0RtJrkpZLmlzH9nGS1khalLwmZG07SNIcSUslLZFUnJT/Nav+\n25IeTLMNZmbWsKK0DiypPXAzMBqoAOZLmhURS2pVnRERk+o4xDTg+ogok7Q3sB0gIo7NOsd9wEOp\nNMDMzHKSZo9kBLA8IlZExMfAdODUXHaU1A8oiogygIjYEhEf1qrTBRgJuEdiZlZAaSaSA4FVWesV\nSVltZ0p6SdJMSb2TskOBjZLul/SCpBuSHk6204AnIuKDuk4uaaKkcknla9asybctZmZWj0JPtj8M\nFEfEIKAMmJqUFwHHAlcAw4GDgXG19v0GcE99B46IWyOiNCJKe/bs2dxxm5lZIs1EshronbXeKymr\nERHrImJbsno7MCxZrgAWJcNilWSGr4ZW7ydpPzJDZ4+mFLuZmeUozUQyHzhEUh9JHYFzgVnZFSQd\nkLU6FliatW83SdVdiZFA9iT9WcAjEbE1lcjNzCxnqV21FRGVkiYBjwPtgSkRsVjSdUB5RMwCLpc0\nFqgE1pMMX0VElaQrgCckCVgA3JZ1+HOBn6UVu5mZ5U4RUegYUldaWhrl5eWFDsPMrFWRtCAiShur\nV+jJdjMza+WcSMzMLC9OJGZmlhcnEjMzy4sTiZmZ5cWJxMzM8uJEYmZmeXEiMTOzvOSUSJK78H5V\nkhOPmZntINfE8HvgPGCZpJ9JOizFmMzMrBXJKZFExNyIOJ/MHXhXAnMl/V3SeEkd0gzQzMxatpyH\nqiTtS+amihOAF4D/QyaxlKUSmZmZtQo53f1X0gPAYcBdwNci4p1k0wxJvhuimX3GJ598QkVFBVu3\n+mkPLV2nTp3o1asXHTo0bYAp19vI3xQR8+rakMudIc2s7amoqGCfffahuLiYzNMgrCWKCNatW0dF\nRQV9+vRp0jFyHdrqJ6lb9Yqk7pK+3aQzmlmbsHXrVvbdd18nkRZOEvvuu29ePcdcE8klEbGxeiUi\nNgCXNPmsZtYmOIm0Dvl+TrkmkvbKOpOk9kDHvM5sZpaijRs38vvf/75J+55yyils3Lix8YoG5J5I\n/kxmYn2UpFHAPUmZmVmL1FAiqaysbHDf2bNn061btwbrFEJEsH379kKH8Rm5JpKrgHnApcnrCeB/\npRWUmVm+Jk+ezBtvvMHgwYO58soreeqppzj22GMZO3Ys/fr1A+C0005j2LBh9O/fn1tvvbVm3+Li\nYtauXcvKlSs5/PDDueSSS+jfvz8nnXQSH3300WfO9fDDD3PEEUcwZMgQTjzxRN577z0AtmzZwvjx\n4xk4cCCDBg3ivvvuA+DPf/4zQ4cOpaSkhFGjRgFw7bXX8stf/rLmmAMGDGDlypWsXLmSww47jIsu\nuogBAwawatUqLr30UkpLS+nfvz8//vGPa/aZP38+Rx11FCUlJYwYMYLNmzdz3HHHsWjRopo6xxxz\nDC+++GIzvtM5XrUVEduBPyQvM7Od8t3vQtbvsmYxeDDceGP923/2s5/xyiuv1PwSfeqpp1i4cCGv\nvPJKzdVJU6ZMoUePHnz00UcMHz6cM888k3333XeH4yxbtox77rmH2267ja9//evcd999XHDBBTvU\nOeaYY3j22WeRxO23384vfvELfvWrX/Gf//mfdO3alZdffhmADRs2sGbNGi655BKefvpp+vTpw/r1\n6xtt67Jly5g6dSpHHnkkANdffz09evSgqqqKUaNG8dJLL9G3b1/OOeccZsyYwfDhw/nggw/Yc889\n+eY3v8mdd97JjTfeyOuvv87WrVspKSnJ+X3ORa732jpE0kxJSyStqH7lsN8YSa9JWi5pch3bx0la\nI2lR8pqQte0gSXMkLU3OW5yUS9L1kl5Ptl2ee3PNrC0bMWLEDpe43nTTTZSUlHDkkUeyatUqli1b\n9pl9+vTpw+DBgwEYNmwYK1eu/EydiooKTj75ZAYOHMgNN9zA4sWLAZg7dy7f+c53aup1796dZ599\nluOOO64mjh49ejQa9+c///maJAJw7733MnToUIYMGcLixYtZsmQJr732GgcccADDhw8HoEuXLhQV\nFXH22WfzyCOP8MknnzBlyhTGjRvX+Bu1k3L9HskdwI+B3wAnAONpJAklE/I3A6OBCmC+pFkRsaRW\n1RkRMamOQ0wDro+IMkl7A9UDg+OA3kDfiNguaf8c22BmBdJQz2FX2muvvWqWn3rqKebOncszzzxD\n586dOf744+u8BHaPPfaoWW7fvn2dQ1uXXXYZ3//+9xk7dixPPfUU11577U7HVlRUtMP8R3Ys2XG/\n+eab/PKXv2T+/Pl0796dcePGNXjpbufOnRk9ejQPPfQQ9957LwsWLNjp2BqT6xzJnhHxBKCIeCsi\nrgW+2sg+I4DlEbEiIj4GpgOn5nIySf2AoogoA4iILRHxYbL5UuC6ZLiNiHg/xzaYWRuyzz77sHnz\n5nq3b9q0ie7du9O5c2deffVVnn322Safa9OmTRx44IEATJ06taZ89OjR3HzzzTXrGzZs4Mgjj+Tp\np5/mzTffBKgZ2iouLmbhwoUALFy4sGZ7bR988AF77bUXXbt25b333uOxxx4D4LDDDuOdd95h/vz5\nAGzevLnmooIJEyZw+eWXM3z4cLp3797kdtYn10SyLbmF/DJJkySdDuzdyD4HAquy1iuSstrOlPRS\nMnTWOyk7FNiY3L7+BUk3JD0cgC8A50gql/SYpEPqOrmkiUmd8jVr1uTYTDPbXey7774cffTRDBgw\ngCuvvPIz28eMGUNlZSWHH344kydP3mHoaGdde+21nH322QwbNoz99tuvpvyaa65hw4YNDBgwgJKS\nEubNm0fPnj259dZbOeOMMygpKeGcc84B4Mwzz2T9+vX079+f3/3udxx66KF1nqukpIQhQ4bQt29f\nzjvvPI4++mgAOnbsyIwZM7jssssoKSlh9OjRNT2VYcOG0aVLF8aPH9/kNjYoIhp9AcPJJI5eZIa5\n7gOObGSfs4Dbs9YvBH5Xq86+wB7J8reAJ7P23QQcTGb47T7gm8m2LcB/JMtnAH9tLP5hw4aFme1a\nS5YsKXQIlli9enUccsghUVVVVW+duj4voDxyyBGN9kiSnsA5kRleqoiI8RFxZkQ01g9cTWYuo1qv\npCw7ia2LiG3J6u3AsGS5AlgUmWGxSuBBMncart52f7L8ADCosTaYmbVV06ZN44gjjuD666+nXbt0\nnk3Y6FEjogo4pgnHng8cIqmPpI7AucCs7AqSDshaHQsszdq3m6SeyfpIoHqS/kEyE/4AXwZeb0Js\nZmZtwkUXXcSqVas4++yzUztHrldtvSBpFvAn4B/VhRFxf307RESlpEnA40B7YEpELJZ0HZnu0izg\nckljgUpgPZkrsoiIKklXAE8kt2ZZANyWHPpnwN2SvkdmmGsCZmZWMLkmkk7AOjI9g2rBp0NMdYqI\n2cDsWmU/ylq+Gri6nn3LqGPYKjI3j2zsijEzM9tFcv1me0pT/WZm1trl+oTEO8j0QHYQEf/a7BGZ\nmVmrkusU/iPAo8nrCaALmfkJM7MWKZ/byAPceOONfPjhh41XtNwSSUTcl/W6G/g64EfsmlmLtTsk\nksZud99SNPWi4kMA3+PKzFqs2reRB7jhhhsYPnw4gwYNqrn9+j/+8Q+++tWvUlJSwoABA5gxYwY3\n3XQTb7/9NieccAInnHDCZ4593XXXMXz4cAYMGMDEiROrv2DN8uXLOfHEEykpKWHo0KG88cYbAPz8\n5z9n4MCBlJSUMHly5v61xx9/POXl5QCsXbuW4uJiAO68807Gjh3LyJEjGTVqFFu2bGHUqFEMHTqU\ngQMH8tBDD9XEMW3aNAYNGkRJSQkXXnghmzdvpk+fPnzyySdA5nYq2etpyXWOZDM7zpG8S+YZJWZm\njfrud7+7wzMxmsPgwYO5sYG7Qda+jfycOXNYtmwZzz//PBHB2LFjefrpp1mzZg2f+9znePTRR4HM\nfbO6du3Kr3/9a+bNm7fDLU+qTZo0iR/9KHMB6oUXXsgjjzzC1772Nc4//3wmT57M6aefztatW9m+\nfTuPPfYYDz30EM899xydO3fO6bbxCxcu5KWXXqJHjx5UVlbywAMP0KVLF9auXcuRRx7J2LFjWbJk\nCT/96U/5+9//zn777cf69evZZ599OP7443n00Uc57bTTmD59OmeccQYdOnRoylucs1yHtvaJiC5Z\nr0Mj4r5UIzMza0Zz5sxhzpw5DBkyhKFDh/Lqq6+ybNkyBg4cSFlZGVdddRV//etf6dq1a6PHmjdv\nHkcccQQDBw7kySefZPHixWzevJnVq1dz+umnA9CpUyc6d+7M3LlzGT9+PJ07dwZyu2386NGja+pF\nBD/4wQ8YNGgQJ554IqtXr+a9997jySef5Oyzz65JdNX1J0yYwB133AHAHXfckd79tbLk2iM5ncx9\nsDYl692A4yPiwTSDM7PdQ0M9h10lIrj66qv51re+9ZltCxcuZPbs2VxzzTWMGjWqprdRl61bt/Lt\nb3+b8vJyevfuzbXXXtvgbdzrk33b+Nr7Z982/u6772bNmjUsWLCADh06UFxc3OD5jj76aFauXMlT\nTz1FVVUVAwYM2OnYdlaucyQ/rk4iUPOlwB83UN/MrKBq30b+5JNPZsqUKWzZkrngdPXq1bz//vu8\n/fbbdO7cmQsuuIArr7yy5lbu9d2GvvqX+H777ceWLVuYOXNmTf1evXrx4IOZv6+3bdvGhx9+yOjR\no7njjjtqJu6zbxtf/WyQ6mPUZdOmTey///506NCBefPm8dZbbwEwcuRI/vSnP7Fu3bodjguZ26Kc\nd955u6Q3Arknkrrq5fqteDOzXa72beRPOukkzjvvPL70pS8xcOBAzjrrLDZv3szLL7/MiBEjGDx4\nMD/5yU+45pprAJg4cSJjxoz5zGR7t27duOSSSxgwYAAnn3xyzRMJAe666y5uuukmBg0axFFHHcW7\n777LmDFjGDt2LKWlpQwePLjmuexXXHEFf/jDHxgyZAhr166ttx3nn38+5eXlDBw4kGnTptG3b18A\n+vfvzw9/+EO+/OUvU1JSwve///0d9tmwYQPf+MY3mu39bIiqrzZosJI0BdhI5omHAN8BekTEuPRC\naz6lpaVRfXWEme0aS5cu5fDDDy90GG3SzJkzeeihh7jrrrty3qeuz0vSgoho9KseufYqLgP+NzCD\nzNVbZWSSiZmZtSCXXXYZjz32GLNnz268cjPJ9V5b/wAmpxyLmZnl6be//e0uP2dOcySSypIrtarX\nu0t6PL2wzMystch1sn2/5EotACJiA/5mu5k1Ipc5WCu8fD+nXBPJdkkHVa9IKqaOuwGbmVXr1KkT\n69atczJp4SKCdevW0alTpyYfI9fJ9h8Cf5P0F0DAscDEJp/VzHZ7vXr1oqKigjVr1hQ6FGtEp06d\n6NWrV5P3z3Wy/c+SSskkjxfIPDf9oyaf1cx2ex06dKBPnz6FDsN2gVxvkTIB+HegF7AIOBJ4hh0f\nvWtmZm1QrnMk/w4MB96KiBOAIWS+oGhmZm1crolka0RsBZC0R0S8ChyWXlhmZtZa5JpIKpLvkTwI\nlEl6CHirsZ0kjZH0mqTlkj7zhUZJ4yStkbQoeU3I2naQpDmSlkpaklwphqQ7Jb2Ztc/gHNtgZmYp\nyHWy/fRk8VpJ84CuwJ8b2kdSezL35hoNVADzJc2KiCW1qs6IiEl1HGIacH1ElEnaG9iete3KiKj/\ndplmZrbL7PQdfCPiLzlWHQEsj4gVAJKmA6cCtRPJZ0jqBxRFRFlyzi07G6eZme0aTX1mey4OBFZl\nrVckZbWdKeklSTMl9U7KDgU2Srpf0guSbkh6ONWuT/b5jaQ96jq5pImSyiWV+zp2M7P0pJlIcvEw\nUBwRg8jcUXhqUl5E5kuPV5C5WuxgYFyy7Wqgb1Leg3qeHR8Rt0ZEaUSU9uzZM7UGmJm1dWkmktVA\n76z1XklZjYhYFxHbktXbgWHJcgWwKCJWREQlmUn+ock+70TGNuAOMkNoZmZWIGkmkvnAIZL6SOoI\nnAvMyq4g6YCs1bHA0qx9u0mq7kqMJJlbqd5HkoDTgFdSa4GZmTUqtcflRkSlpEnA40B7YEpELJZ0\nHVAeEbOAyyWNBSqB9STDVxFRJekK4IkkYSwAbksOfXeSYETmW/b/llYbzMyscTk9are186N2zcx2\nXq6P2i30ZLuZmbVyTiRmZpYXJxIzM8uLE4mZmeXFicTMzPLiRGJmZnlxIjEzs7w4kZiZWV6cSMzM\nLC9OJGZmlhcnEjMzy4sTiZmZ5cWJxMzM8uJEYmZmeXEiMTOzvDiRmJlZXpxIzMwsL04kZmaWFycS\nMzPLixOJmZnlxYnEzMzykmoikTRG0muSlkuaXMf2cZLWSFqUvCZkbTtI0hxJSyUtkVRca9+bJG1J\nM34zM2tcUVoHltQeuBkYDVQA8yXNiogltarOiIhJdRxiGnB9RJRJ2hvYnnXsUqB7SqGbmdlOSLNH\nMgJYHhErIuJjYDpwai47SuoHFEVEGUBEbImID5Nt7YEbgP+VTthmZrYz0kwkBwKrstYrkrLazpT0\nkqSZknonZYcCGyXdL+kFSTckCQRgEjArIt5p6OSSJkoql1S+Zs2afNtiZmb1KPRk+8NAcUQMAsqA\nqUl5EXAscAUwHDgYGCfpc8DZwG8bO3BE3BoRpRFR2rNnz1SCNzOzdBPJaqB31nqvpKxGRKyLiG3J\n6u3AsGS5AliUDItVAg8CQ4GaXT3pAAALUElEQVQhwBeB5ZJWAp0lLU+vCWZm1pg0E8l84BBJfSR1\nBM4FZmVXkHRA1upYYGnWvt0kVXclRgJLIuLRiPjniCiOiGLgw4j4YoptMDOzRqR21VZEVEqaBDwO\ntAemRMRiSdcB5RExC7hc0ligElgPjEv2rZJ0BfCEJAELgNvSitXMzJpOEVHoGFJXWloa5eXlhQ7D\nzKxVkbQgIkobq1foyXYzM2vlnEjMzCwvTiRmZpYXJxIzM8uLE4mZmeXFicTMzPLiRGJmZnlxIjEz\ns7w4kZiZWV6cSMzMLC9OJGZmlhcnEjMzy4sTiZmZ5cWJxMzM8uJEYmZmeXEiMTOzvDiRmJlZXpxI\nzMwsL04kZmaWFycSMzPLixOJmZnlJdVEImmMpNckLZc0uY7t4yStkbQoeU3I2naQpDmSlkpaIqk4\nKf9vSS9KeknSTEl7p9kGMzNrWFFaB5bUHrgZGA1UAPMlzYqIJbWqzoiISXUcYhpwfUSUJclie1L+\nvYj4IDnHr4FJwM/SaMPTT8M776RxZGtLTjgB9t+/0FE0bNs2eOyxzL/VOnaEMWNgzz0LF1ddNm6E\nsjLYvr3xugZf+Qp06ZLuOVJLJMAIYHlErACQNB04FaidSD5DUj+gKCLKACJiS/W2rCQiYE8gmj/0\njJ//HGbPTuvo1lZcein8/veFjqJhs2bB17/+2fI774SLL97l4TToN7+B664rdBStx9KlrTuRHAis\nylqvAI6oo96Zko4DXifT21gFHApslHQ/0AeYC0yOiCoASXcAp5BJSv9R18klTQQmAhx00EFNasAt\nt8CWLY3XM6vP6NGt42eoOsayMjjwQFi/Ho45pmXGvmVLppe0YEGhI2kd+vRJ/xxpJpJcPAzcExHb\nJH0LmAqMJBPXscAQ4H+AGcA44L8BImJ8MnT2W+Ac4I7aB46IW4FbAUpLS5vUa+nduyl7mX1qzz2h\nqqrQUTSuOsa+faFXr0wiyS5vSaqqMsNuhx9e6EisWpqT7auB7F/FvZKyGhGxLiKqR2VvB4YlyxXA\noohYERGVwIPA0Fr7VgHTgTNTiN2sWRQVQWVloaNoXHWMRUU7/tsSY6+s/DQ+axnSTCTzgUMk9ZHU\nETgXmJVdQdIBWatjgaVZ+3aT1DNZHwksUcYXk32V7PNqim0wy0v79i3zr/raqmNs337Hf1tiIqmq\n+jQ+axlSy+sRUSlpEvA40B6YEhGLJV0HlEfELOBySWOBSmA9meErIqJK0hXAE0nCWADcBgiYKqlL\nsvwicGlabTDLV2vvkbTEJOgeScuT6scREbOB2bXKfpS1fDVwdT37lgGD6th0dHPGaJYm90ian3sk\nLY+/2W6WotbaI6n+Rd0Sk6B7JC2PE4lZitq3b12JpDqBSNCuXcuMvbLSPZKWxonELEVFRS3zr/ra\nqmPM/ku/pfamqqrcI2lpnEjMUtRSfxnXVh1ju6zfCC01CXpoq+VxIjFLUWuabG/fPjOkVa2lDst5\nsr3lcSIxS1Fr6pHU/iu/pcbuHknL40RilqLW1iPJ1lJjd4+k5XFeN0tRURG88gr071/oSBr27ruf\n/eVcVAT33AN/+UthYqrPypVQUlLoKCybE4lZii65BDp0KHQUjevXD0pLdyy76ir4f/+vMPE0pF8/\nOOOMQkdh2RSR2uM8WozS0tIoLy8vdBhmZq2KpAURUdpYPc+RmJlZXpxIzMwsL04kZmaWFycSMzPL\nixOJmZnlxYnEzMzy4kRiZmZ5cSIxM7O8tIkvJEpaA7zVxN33A9Y2YziF5La0PLtLO8Btaanyacvn\nI6JnY5XaRCLJh6TyXL7Z2Rq4LS3P7tIOcFtaql3RFg9tmZlZXpxIzMwsL04kjbu10AE0I7el5dld\n2gFuS0uVels8R2JmZnlxj8TMzPLiRGJmZnlxImmApDGSXpO0XNLkQsfTGEkrJb0saZGk8qSsh6Qy\nScuSf7sn5ZJ0U9K2lyQNLXDsUyS9L+mVrLKdjl3SxUn9ZZIubkFtuVbS6uSzWSTplKxtVydteU3S\nyVnlBf35k9Rb0jxJSyQtlvTvSXmr+1waaEtr/Fw6SXpe0otJW36SlPeR9FwS1wxJHZPyPZL15cn2\n4sbauNMiwq86XkB74A3gYKAj8CLQr9BxNRLzSmC/WmW/ACYny5OBnyfLpwCPAQKOBJ4rcOzHAUOB\nV5oaO9ADWJH82z1Z7t5C2nItcEUddfslP1t7AH2Sn7n2LeHnDzgAGJos7wO8nsTb6j6XBtrSGj8X\nAXsnyx2A55L3+17g3KT8FuDSZPnbwC3J8rnAjIba2JSY3COp3whgeUSsiIiPgenAqQWOqSlOBaYm\ny1OB07LKp0XGs0A3SQcUIkCAiHgaWF+reGdjPxkoi4j1EbEBKAPGpB/9juppS31OBaZHxLaIeBNY\nTuZnr+A/fxHxTkQsTJY3A0uBA2mFn0sDbalPS/5cIiK2JKsdklcAI4GZSXntz6X685oJjJIk6m/j\nTnMiqd+BwKqs9Qoa/sFrCQKYI2mBpIlJ2T9FxDvJ8rvAPyXLraF9Oxt7S2/TpGTIZ0r1cBCtpC3J\ncMgQMn/9turPpVZboBV+LpLaS1oEvE8mMb8BbIyIyjriqok52b4J2JdmbIsTye7lmIgYCnwF+I6k\n47I3RqY/2yqv927NsSf+AHwBGAy8A/yqsOHkTtLewH3AdyPig+xtre1zqaMtrfJziYiqiBgM9CLT\ni+hbyHicSOq3Guidtd4rKWuxImJ18u/7wANkfsDeqx6ySv59P6neGtq3s7G32DZFxHvJf/7twG18\nOoTQotsiqQOZX7x3R8T9SXGr/Fzqaktr/VyqRcRGYB7wJTJDiUV1xFUTc7K9K7COZmyLE0n95gOH\nJFdCdCQzSTWrwDHVS9JekvapXgZOAl4hE3P1VTIXAw8ly7OAi5IrbY4ENmUNV7QUOxv748BJkron\nQxQnJWUFV2v+6XQynw1k2nJucmVNH+AQ4HlawM9fMo7+38DSiPh11qZW97nU15ZW+rn0lNQtWd4T\nGE1mzmcecFZSrfbnUv15nQU8mfQk62vjztuVVxu0theZq1BeJzP++MNCx9NIrAeTuQLjRWBxdbxk\nxkKfAJYBc4EeSbmAm5O2vQyUFjj+e8gMLXxCZqz2m02JHfhXMpOGy4HxLagtdyWxvpT8Bz4gq/4P\nk7a8Bnylpfz8AceQGbZ6CViUvE5pjZ9LA21pjZ/LIOCFJOZXgB8l5QeTSQTLgT8BeyTlnZL15cn2\ngxtr486+fIsUMzPLi4e2zMwsL04kZmaWFycSMzPLixOJmZnlxYnEzMzy4kRi1sJJOl7SI4WOw6w+\nTiRmZpYXJxKzZiLpguQ5EYsk/VdyY70tkn6TPDfiCUk9k7qDJT2b3CzwAX36TI8vSpqbPGtioaQv\nJIffW9JMSa9Kujv5prZZi+BEYtYMJB0OnAMcHZmb6VUB5wN7AeUR0R/4C/DjZJdpwFURMYjMN6ur\ny+8Gbo6IEuAoMt+Qh8zdar9L5hkSBwNHp94osxwVNV7FzHIwChgGzE86C3uSuZnhdmBGUuePwP2S\nugLdIuIvSflU4E/JvdIOjIgHACJiK0ByvOcjoiJZXwQUA39Lv1lmjXMiMWseAqZGxNU7FEr/u1a9\npt6TaFvWchX+v2stiIe2zJrHE8BZkvaHmueaf57M/7HqO7KeB/wtIjYBGyQdm5RfCPwlMk/uq5B0\nWnKMPSR13qWtMGsC/1Vj1gwiYomka8g8obIdmTv/fgf4BzAi2fY+mXkUyNzW+5YkUawAxiflFwL/\nJem65Bhn78JmmDWJ7/5rliJJWyJi70LHYZYmD22ZmVle3CMxM7O8uEdiZmZ5cSIxM7O8OJGYmVle\nnEjMzCwvTiRmZpaX/x8ynHjpK2dZhAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-84500ee9b590>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cross Entropy Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2809\u001b[0m     return gca().plot(\n\u001b[1;32m   2810\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2811\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n\u001b[0;32m--> 234\u001b[0;31m                              \"shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y can be no greater than 2-D, but have shapes (3000,) and (3000, 1, 28)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYfAlqQmDL0lNGHxJauJ/Acz2XLpusNoKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2tUb6Iwi_E_",
        "colab_type": "code",
        "outputId": "e29875e4-d800-4913-94f2-3d519f9f9425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(X_t2)\n",
        "\n",
        "#len(y_t1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1763"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkDQ-U-Ci6Tt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = tf.Variable(tf.random_normal(shape=[2, 1]))\n",
        "b = tf.Variable(tf.random_normal(shape=[1, 1]))\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "data = tf.placeholder(dtype=tf.float32, shape=[None, 2])\n",
        "target = tf.placeholder(dtype=tf.float32, shape=[None, 1])\n",
        "\n",
        "mod = tf.matmul(data, A) + b\n",
        "\n",
        "for i in range(len(X_t1)):\n",
        "    loss = ((y_train1[i] * tf.log(tf.sigmoid(tf.transpose(A)*X_train[i]))) + ((1 - y_train1[i]) * tf.log(1 - tf.sigmoid(tf.transpose(A)*X_train[i])))\n",
        "            + (y_train1[i] * tf.log(tf.sigmoid(tf.transpose(A)*au_X_train[i]))) + ((1 - y_train1[i]) * tf.log(1 - tf.sigmoid(tf.transpose(A)*au_X_train[i]))))\n",
        "\n",
        "loss = loss/140\n",
        "\n",
        "X_train = np.concatenate((X_train, au_X_train), axis = 0)\n",
        "\n",
        "learning_rate = .005\n",
        "batch_size = 30\n",
        "iter_num = 1500\n",
        "\n",
        "# Define the optimizer\n",
        "opt = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "\n",
        "# Define the goal\n",
        "goal = opt.minimize(loss)\n",
        "\n",
        "# Define the accuracy\n",
        "# The default threshold is 0.5, rounded off directly\n",
        "prediction = tf.round(tf.sigmoid(mod))\n",
        "# Bool into float32 type\n",
        "correct = tf.cast(tf.equal(prediction, target), dtype=tf.float32)\n",
        "# Average\n",
        "accuracy = tf.reduce_mean(correct)\n",
        "# End of the definition of the model framework\n",
        "\n",
        "# Start training model\n",
        "# Define the variable that stores the result\n",
        "loss_trace = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "# training model\n",
        "for epoch in range(iter_num):\n",
        "    # Generate random batch index\n",
        "    batch_index = np.random.choice(len(X_train), size=batch_size)\n",
        "    batch_train_X = X_train[batch_index]\n",
        "    batch_train_y = np.matrix(y_train[batch_index]).T\n",
        "    sess.run(goal, feed_dict={data: batch_train_X, target: batch_train_y})\n",
        "    temp_loss = sess.run(loss, feed_dict={data: batch_train_X, target: batch_train_y})\n",
        "    # convert into a matrix, and the shape of the placeholder to correspond\n",
        "    temp_train_acc = sess.run(accuracy, feed_dict={data: X_train, target: np.matrix(y_train).T})\n",
        "    temp_test_acc = sess.run(accuracy, feed_dict={data: X_test, target: np.matrix(y_test).T})\n",
        "    temp_test_acc1 = sess.run(accuracy, feed_dict={data: au_X_test, target: np.matrix(y_test1).T})\n",
        "\n",
        "    # recode the result\n",
        "    loss_trace.append(temp_loss)\n",
        "    train_acc.append(temp_train_acc)\n",
        "    test_acc.append(temp_test_acc)\n",
        "    # output\n",
        "    if (epoch + 1) % 300 == 0:\n",
        "        print(epoch + 1, temp_loss, temp_train_acc, temp_test_acc, temp_test_acc1)\n",
        "\n",
        "\n",
        "plt.plot(train_acc, 'b-', label='train accuracy')\n",
        "plt.plot(test_acc, 'k-', label='test accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Train and Test Accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(loss_trace)\n",
        "plt.title('Cross Entropy Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}