{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ApplyingExisting1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prakface/Practice/blob/master/ApplyingExisting1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jbgod4KteJd",
        "colab_type": "code",
        "outputId": "919edf79-3cbf-41bd-dae1-d0d03967313c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1105
        }
      },
      "source": [
        "#Logistic Regression\n",
        "\n",
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Importing the dataset\n",
        "url='https://raw.githubusercontent.com/Prakface/Practice/master/initialFeatures.csv'\n",
        "\n",
        "data=pd.read_csv(url)\n",
        "\n",
        "\n",
        "print(data.isnull())\n",
        "\n",
        "#the follwoing line is used to remove null valued rows, but the index of rows still corresponds to old one , loses serial order\n",
        "data_modified= data.dropna()   \n",
        "\n",
        "\n",
        "#print(data_modified)\n",
        "\n",
        "\n",
        "#to arrange rows in serial order which are left in file, storeback modified data frame to a csv file and again read this new csv file into a data frame\n",
        "\n",
        "\n",
        "\n",
        "data_modified.to_csv(\"modifiedData.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "df2=pd.read_csv(\"modifiedData.csv\")\n",
        "\n",
        "#df2\n",
        "\n",
        "\n",
        "dataset = df2.drop(\"level\", axis = 1)\n",
        "data_X = dataset.iloc[:, 0:27].values\n",
        "data_y = dataset.iloc[:, 27].values\n",
        "from sklearn.utils import shuffle\n",
        "dataset = shuffle(dataset, random_state=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       image    url  question  original  ...  retweets_count   hour  level  result\n",
            "0      False  False     False     False  ...           False  False  False   False\n",
            "1       True   True      True      True  ...            True   True   True    True\n",
            "2      False  False     False     False  ...           False  False  False   False\n",
            "3       True   True      True      True  ...            True   True   True    True\n",
            "4      False  False     False     False  ...           False  False  False   False\n",
            "5       True   True      True      True  ...            True   True   True    True\n",
            "6      False  False     False     False  ...           False  False  False   False\n",
            "7       True   True      True      True  ...            True   True   True    True\n",
            "8      False  False     False     False  ...           False  False  False   False\n",
            "9       True   True      True      True  ...            True   True   True    True\n",
            "10     False  False     False     False  ...           False  False  False   False\n",
            "11      True   True      True      True  ...            True   True   True    True\n",
            "12     False  False     False     False  ...           False  False  False   False\n",
            "13      True   True      True      True  ...            True   True   True    True\n",
            "14     False  False     False     False  ...           False  False  False   False\n",
            "15      True   True      True      True  ...            True   True   True    True\n",
            "16     False  False     False     False  ...           False  False  False   False\n",
            "17      True   True      True      True  ...            True   True   True    True\n",
            "18     False  False     False     False  ...           False  False  False   False\n",
            "19      True   True      True      True  ...            True   True   True    True\n",
            "20     False  False     False     False  ...           False  False  False   False\n",
            "21      True   True      True      True  ...            True   True   True    True\n",
            "22     False  False     False     False  ...           False  False  False   False\n",
            "23      True   True      True      True  ...            True   True   True    True\n",
            "24     False  False     False     False  ...           False  False  False   False\n",
            "25      True   True      True      True  ...            True   True   True    True\n",
            "26     False  False     False     False  ...           False  False  False   False\n",
            "27      True   True      True      True  ...            True   True   True    True\n",
            "28     False  False     False     False  ...           False  False  False   False\n",
            "29      True   True      True      True  ...            True   True   True    True\n",
            "...      ...    ...       ...       ...  ...             ...    ...    ...     ...\n",
            "11719   True   True      True      True  ...            True   True   True    True\n",
            "11720  False  False     False     False  ...           False  False  False   False\n",
            "11721   True   True      True      True  ...            True   True   True    True\n",
            "11722  False  False     False     False  ...           False  False  False   False\n",
            "11723   True   True      True      True  ...            True   True   True    True\n",
            "11724  False  False     False     False  ...           False  False  False   False\n",
            "11725   True   True      True      True  ...            True   True   True    True\n",
            "11726  False  False     False     False  ...           False  False  False   False\n",
            "11727   True   True      True      True  ...            True   True   True    True\n",
            "11728  False  False     False     False  ...           False  False  False   False\n",
            "11729   True   True      True      True  ...            True   True   True    True\n",
            "11730  False  False     False     False  ...           False  False  False   False\n",
            "11731   True   True      True      True  ...            True   True   True    True\n",
            "11732  False  False     False     False  ...           False  False  False   False\n",
            "11733   True   True      True      True  ...            True   True   True    True\n",
            "11734  False  False     False     False  ...           False  False  False   False\n",
            "11735   True   True      True      True  ...            True   True   True    True\n",
            "11736  False  False     False     False  ...           False  False  False   False\n",
            "11737   True   True      True      True  ...            True   True   True    True\n",
            "11738  False  False     False     False  ...           False  False  False   False\n",
            "11739   True   True      True      True  ...            True   True   True    True\n",
            "11740  False  False     False     False  ...           False  False  False   False\n",
            "11741   True   True      True      True  ...            True   True   True    True\n",
            "11742  False  False     False     False  ...           False  False  False   False\n",
            "11743   True   True      True      True  ...            True   True   True    True\n",
            "11744  False  False     False     False  ...           False  False  False   False\n",
            "11745   True   True      True      True  ...            True   True   True    True\n",
            "11746  False  False     False     False  ...           False  False  False   False\n",
            "11747   True   True      True      True  ...            True   True   True    True\n",
            "11748  False  False     False     False  ...           False  False  False   False\n",
            "\n",
            "[11749 rows x 29 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjM0Y3he51yD",
        "colab_type": "code",
        "outputId": "becfcd94-2030-442f-a952-722b3aa5d5ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size = 0.35, random_state = 0)\n",
        "\n",
        "# Feature Scaling\n",
        "'''from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)'''\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from sklearn.preprocessing import StandardScaler\\nsc = StandardScaler()\\nX_train = sc.fit_transform(X_train)\\nX_test = sc.transform(X_test)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9faNzCy52t_",
        "colab_type": "code",
        "outputId": "ffab2df2-65b8-423a-86b8-c9e443c29a9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "#For kernel SVM\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "print(\"\\n for svm with rbf kernel \\n \")\n",
        "clf = SVC(kernel = 'rbf', gamma=0.1)\n",
        "#clf.fit(X_train, y_train)\n",
        "\n",
        "#clf2 = SVC(kernel='linear', C=1, random_state=0)\n",
        "\n",
        "# cross_validate without scoring parameter computes accuracy for each fold\n",
        "scores = cross_val_score(clf, data_X, data_y,cv=5)\n",
        "#sorted(scores.keys())\n",
        "print(\"\\n accuracy scores = \", scores)\n",
        "\n",
        "#for finding F1 measure at each fold, use scoring marameter in cross_validate\n",
        "scores = cross_val_score(clf, data_X, data_y, scoring='f1_macro',cv=10)\n",
        "\n",
        "print(\"F1 measure values  = \", scores)\n",
        "\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "# Predicting the Test set results\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cm)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " for svm with rbf kernel \n",
            " \n",
            "\n",
            " accuracy scores =  [0.58212766 0.64680851 0.78553191 0.64851064 0.6       ]\n",
            "F1 measure values  =  [0.54009794 0.59472466 0.58013145 0.68516129 0.7967248  0.8044294\n",
            " 0.62853278 0.57716644 0.62895855 0.51426712]\n",
            "[[587 406]\n",
            " [203 861]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q25BTjOGM4QN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import recall_score\n",
        "scoring = ['precision_macro', 'recall_macro']\n",
        "clf = SVC(kernel='linear', C=1, random_state=0)\n",
        "scores = cross_validate(clf, data_X, data_y, scoring=scoring,cv=5)\n",
        "sorted(scores.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5mYyeTLIvFa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "18a43515-7b42-4ef4-ba16-da1b1085be9d"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "print('\\n for svm with linear  kernel \\n')\n",
        "clf = SVC(kernel='linear',degree=2, C=1, random_state=0)\n",
        "\n",
        "# cross_validate without scoring parameter computes accuracy for each fold\n",
        "scores = cross_val_score(clf, data_X, data_y,cv=5)\n",
        "sorted(scores.keys())\n",
        "print(\"\\n accuracy scores = \", scores)\n",
        "\n",
        "#for finding F1 measure at each fold, use scoring marameter in cross_validate\n",
        "scores = cross_val_score(clf, data_X, data_y, scoring='f1_macro',cv=5)\n",
        "sorted(scores.keys())\n",
        "\n",
        "print(\"F1 measure values  = \", scores)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " for svm with linear  kernel \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD-OKF8t5_P6",
        "colab_type": "code",
        "outputId": "b9442da9-b7dd-438a-968a-5147b6025be4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "#For random logistic regression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import recall_score\n",
        "scoring = ['accuracy', 'f1_macro', 'precision_macro', 'recall_macro']\n",
        "\n",
        "\n",
        "clf = LogisticRegression(random_state = 0)\n",
        "\n",
        "scores = cross_validate(clf, data_X, data_y, scoring=scoring,cv=5)\n",
        "\n",
        "print(sorted(scores.keys()))\n",
        "print(scores)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cm)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['fit_time', 'score_time', 'test_accuracy', 'test_f1_macro', 'test_precision_macro', 'test_recall_macro']\n",
            "{'fit_time': array([0.0479126 , 0.06289649, 0.05467796, 0.05020976, 0.06265092]), 'score_time': array([0.00675511, 0.00613666, 0.00608897, 0.00621486, 0.0061245 ]), 'test_accuracy': array([0.59829787, 0.65361702, 0.76085106, 0.68510638, 0.61617021]), 'test_f1_macro': array([0.59001609, 0.65032549, 0.75931065, 0.68451203, 0.60115261]), 'test_precision_macro': array([0.6013516 , 0.65557128, 0.77315541, 0.68491944, 0.62765957]), 'test_recall_macro': array([0.59477534, 0.65140598, 0.76370026, 0.68442723, 0.61120261])}\n",
            "[[633 360]\n",
            " [319 745]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gqiqKII6ETy",
        "colab_type": "code",
        "outputId": "aab00da3-9af1-46cf-dc19-7019a7c9a322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "#For random forest classification\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "scoring = ['accuracy', 'f1_macro', 'precision_macro', 'recall_macro']\n",
        "\n",
        "scores = cross_validate(clf, data_X, data_y, scoring=scoring,cv=5)\n",
        "\n",
        "print(sorted(scores.keys()))\n",
        "print(scores)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cm)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['fit_time', 'score_time', 'test_accuracy', 'test_f1_macro', 'test_precision_macro', 'test_recall_macro']\n",
            "{'fit_time': array([0.69493699, 0.69797015, 0.748034  , 0.71075368, 0.69443488]), 'score_time': array([0.14346957, 0.13667679, 0.12841725, 0.13517809, 0.13986397]), 'test_accuracy': array([0.64085106, 0.66723404, 0.78297872, 0.7012766 , 0.65191489]), 'test_f1_macro': array([0.63212164, 0.66439877, 0.78244864, 0.70126881, 0.64373905]), 'test_precision_macro': array([0.64856678, 0.66914996, 0.78941332, 0.70159196, 0.6601572 ]), 'test_recall_macro': array([0.63702723, 0.66517728, 0.78498423, 0.70168665, 0.64817156])}\n",
            "[[645 348]\n",
            " [253 811]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07O5IRNG6JUG",
        "colab_type": "code",
        "outputId": "a739995a-5e59-4c76-907d-2878e697d36c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "# Visualising the Training set results\n",
        "'''from matplotlib.colors import ListedColormap\n",
        "X_set, y_set = X_train, y_train\n",
        "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
        "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
        "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
        "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
        "plt.xlim(X1.min(), X1.max())\n",
        "plt.ylim(X2.min(), X2.max())\n",
        "for i, j in enumerate(np.unique(y_set)):\n",
        "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
        "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
        "plt.title('Logistic Regression (Training set)')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Estimated Salary')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Visualising the Test set results\n",
        "from matplotlib.colors import ListedColormap\n",
        "X_set, y_set = X_test, y_test\n",
        "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
        "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
        "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
        "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
        "plt.xlim(X1.min(), X1.max())\n",
        "plt.ylim(X2.min(), X2.max())\n",
        "for i, j in enumerate(np.unique(y_set)):\n",
        "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
        "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
        "plt.title('Logistic Regression (Test set)')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Estimated Salary')\n",
        "plt.legend()\n",
        "plt.show()'''\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-e7f6f23fd469>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n\u001b[1;32m      4\u001b[0m                      np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n\u001b[0;32m----> 5\u001b[0;31m plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n\u001b[0m\u001b[1;32m      6\u001b[0m              alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \"\"\"\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    357\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    400\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 27 and input n_features is 2 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ilp7PjnU70lK",
        "colab_type": "code",
        "outputId": "54671522-cd39-4d36-8a10-047352b0a967",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn import datasets\n",
        "\n",
        "iris=datasets.load_iris()\n",
        "\n",
        "scoring = ['precision_macro', 'recall_macro']\n",
        "clf = svm.SVC(kernel='linear', C=1, random_state=0)\n",
        "scores = cross_validate(clf, iris.data, iris.target, scoring=scoring,cv=5)\n",
        "sorted(scores.keys())\n",
        "#['fit_time', 'score_time', 'test_precision_macro', 'test_recall_macro']\n",
        "\n",
        "print(scores['test_recall_macro'])\n",
        "\n",
        "scores['test_recall_macro']\n",
        "\n",
        "\n",
        "print(scores['test_precision_macro'])\n",
        "scores['test_precision_macro']\n",
        "\n",
        "\n",
        "print(scores['score_time'])\n",
        "scores['score_time']\n",
        "\n",
        "\n",
        "print(scores.keys())\n",
        "\n",
        "\n",
        "\n",
        "#print(iris)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.96666667 1.         0.96666667 0.96666667 1.        ]\n",
            "[0.96969697 1.         0.96969697 0.96969697 1.        ]\n",
            "[0.00862432 0.00144005 0.00157189 0.00169373 0.00168037]\n",
            "dict_keys(['fit_time', 'score_time', 'test_precision_macro', 'test_recall_macro'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_chQZXtLefY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2[]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}